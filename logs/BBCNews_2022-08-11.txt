[2022-08-11 20:24:43] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:24:43] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:24:43] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:24:43] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:24:43] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:24:43] - INFO: ### device = cpu
[2022-08-11 20:24:43] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:24:43] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:24:43] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:24:43] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:24:43] - INFO: ### batch_size = 10
[2022-08-11 20:24:43] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:24:43] - INFO: ### epochs = 5
[2022-08-11 20:24:43] - INFO: ### nums_labels = 5
[2022-08-11 20:24:43] - INFO: ### return_dict = True
[2022-08-11 20:24:43] - INFO: ### output_hidden_states = False
[2022-08-11 20:24:43] - INFO: ### output_attentions = False
[2022-08-11 20:24:43] - INFO: ### torchscript = False
[2022-08-11 20:24:43] - INFO: ### torch_dtype = None
[2022-08-11 20:24:43] - INFO: ### use_bfloat16 = False
[2022-08-11 20:24:43] - INFO: ### pruned_heads = {}
[2022-08-11 20:24:43] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:24:43] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:24:43] - INFO: ### is_decoder = False
[2022-08-11 20:24:43] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:24:43] - INFO: ### add_cross_attention = False
[2022-08-11 20:24:43] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:24:43] - INFO: ### max_length = 20
[2022-08-11 20:24:43] - INFO: ### min_length = 0
[2022-08-11 20:24:43] - INFO: ### do_sample = False
[2022-08-11 20:24:43] - INFO: ### early_stopping = False
[2022-08-11 20:24:43] - INFO: ### num_beams = 1
[2022-08-11 20:24:43] - INFO: ### num_beam_groups = 1
[2022-08-11 20:24:43] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:24:43] - INFO: ### temperature = 1.0
[2022-08-11 20:24:43] - INFO: ### top_k = 50
[2022-08-11 20:24:43] - INFO: ### top_p = 1.0
[2022-08-11 20:24:43] - INFO: ### typical_p = 1.0
[2022-08-11 20:24:43] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:24:43] - INFO: ### length_penalty = 1.0
[2022-08-11 20:24:43] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:24:43] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:24:43] - INFO: ### bad_words_ids = None
[2022-08-11 20:24:43] - INFO: ### num_return_sequences = 1
[2022-08-11 20:24:43] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:24:43] - INFO: ### output_scores = False
[2022-08-11 20:24:43] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:24:43] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:24:43] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:24:43] - INFO: ### remove_invalid_values = False
[2022-08-11 20:24:43] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:24:43] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:24:43] - INFO: ### finetuning_task = None
[2022-08-11 20:24:43] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:24:43] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:24:43] - INFO: ### tokenizer_class = None
[2022-08-11 20:24:43] - INFO: ### prefix = None
[2022-08-11 20:24:43] - INFO: ### bos_token_id = None
[2022-08-11 20:24:43] - INFO: ### pad_token_id = 0
[2022-08-11 20:24:43] - INFO: ### eos_token_id = None
[2022-08-11 20:24:43] - INFO: ### sep_token_id = None
[2022-08-11 20:24:43] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:24:43] - INFO: ### task_specific_params = None
[2022-08-11 20:24:43] - INFO: ### problem_type = None
[2022-08-11 20:24:43] - INFO: ### _name_or_path = 
[2022-08-11 20:24:43] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:24:43] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:24:43] - INFO: ### model_type = bert
[2022-08-11 20:24:43] - INFO: ### vocab_size = 30522
[2022-08-11 20:24:43] - INFO: ### hidden_size = 768
[2022-08-11 20:24:43] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:24:43] - INFO: ### num_attention_heads = 12
[2022-08-11 20:24:43] - INFO: ### hidden_act = gelu
[2022-08-11 20:24:43] - INFO: ### intermediate_size = 3072
[2022-08-11 20:24:43] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:24:43] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:24:43] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:24:43] - INFO: ### type_vocab_size = 2
[2022-08-11 20:24:43] - INFO: ### initializer_range = 0.02
[2022-08-11 20:24:43] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:24:43] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:24:43] - INFO: ### use_cache = True
[2022-08-11 20:24:43] - INFO: ### classifier_dropout = None
[2022-08-11 20:31:45] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:31:45] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:31:45] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:31:45] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:31:45] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:31:45] - INFO: ### device = cpu
[2022-08-11 20:31:45] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:31:45] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:31:45] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:31:45] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:31:45] - INFO: ### batch_size = 10
[2022-08-11 20:31:45] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:31:45] - INFO: ### epochs = 5
[2022-08-11 20:31:45] - INFO: ### nums_labels = 5
[2022-08-11 20:31:45] - INFO: ### return_dict = True
[2022-08-11 20:31:45] - INFO: ### output_hidden_states = False
[2022-08-11 20:31:45] - INFO: ### output_attentions = False
[2022-08-11 20:31:45] - INFO: ### torchscript = False
[2022-08-11 20:31:45] - INFO: ### torch_dtype = None
[2022-08-11 20:31:45] - INFO: ### use_bfloat16 = False
[2022-08-11 20:31:45] - INFO: ### pruned_heads = {}
[2022-08-11 20:31:45] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:31:45] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:31:45] - INFO: ### is_decoder = False
[2022-08-11 20:31:45] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:31:45] - INFO: ### add_cross_attention = False
[2022-08-11 20:31:45] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:31:45] - INFO: ### max_length = 20
[2022-08-11 20:31:45] - INFO: ### min_length = 0
[2022-08-11 20:31:45] - INFO: ### do_sample = False
[2022-08-11 20:31:45] - INFO: ### early_stopping = False
[2022-08-11 20:31:45] - INFO: ### num_beams = 1
[2022-08-11 20:31:45] - INFO: ### num_beam_groups = 1
[2022-08-11 20:31:45] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:31:45] - INFO: ### temperature = 1.0
[2022-08-11 20:31:45] - INFO: ### top_k = 50
[2022-08-11 20:31:45] - INFO: ### top_p = 1.0
[2022-08-11 20:31:45] - INFO: ### typical_p = 1.0
[2022-08-11 20:31:45] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:31:45] - INFO: ### length_penalty = 1.0
[2022-08-11 20:31:45] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:31:45] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:31:45] - INFO: ### bad_words_ids = None
[2022-08-11 20:31:45] - INFO: ### num_return_sequences = 1
[2022-08-11 20:31:45] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:31:45] - INFO: ### output_scores = False
[2022-08-11 20:31:45] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:31:45] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:31:45] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:31:45] - INFO: ### remove_invalid_values = False
[2022-08-11 20:31:45] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:31:45] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:31:45] - INFO: ### finetuning_task = None
[2022-08-11 20:31:45] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:31:45] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:31:45] - INFO: ### tokenizer_class = None
[2022-08-11 20:31:45] - INFO: ### prefix = None
[2022-08-11 20:31:45] - INFO: ### bos_token_id = None
[2022-08-11 20:31:45] - INFO: ### pad_token_id = 0
[2022-08-11 20:31:45] - INFO: ### eos_token_id = None
[2022-08-11 20:31:45] - INFO: ### sep_token_id = None
[2022-08-11 20:31:45] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:31:45] - INFO: ### task_specific_params = None
[2022-08-11 20:31:45] - INFO: ### problem_type = None
[2022-08-11 20:31:45] - INFO: ### _name_or_path = 
[2022-08-11 20:31:45] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:31:45] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:31:45] - INFO: ### model_type = bert
[2022-08-11 20:31:45] - INFO: ### vocab_size = 30522
[2022-08-11 20:31:45] - INFO: ### hidden_size = 768
[2022-08-11 20:31:45] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:31:45] - INFO: ### num_attention_heads = 12
[2022-08-11 20:31:45] - INFO: ### hidden_act = gelu
[2022-08-11 20:31:45] - INFO: ### intermediate_size = 3072
[2022-08-11 20:31:45] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:31:45] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:31:45] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:31:45] - INFO: ### type_vocab_size = 2
[2022-08-11 20:31:45] - INFO: ### initializer_range = 0.02
[2022-08-11 20:31:45] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:31:45] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:31:45] - INFO: ### use_cache = True
[2022-08-11 20:31:45] - INFO: ### classifier_dropout = None
[2022-08-11 20:32:46] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:32:46] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:32:46] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:32:46] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:32:46] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:32:46] - INFO: ### device = cpu
[2022-08-11 20:32:46] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:32:46] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:32:46] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:32:46] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:32:46] - INFO: ### batch_size = 10
[2022-08-11 20:32:46] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:32:46] - INFO: ### epochs = 5
[2022-08-11 20:32:46] - INFO: ### nums_labels = 5
[2022-08-11 20:32:46] - INFO: ### return_dict = True
[2022-08-11 20:32:46] - INFO: ### output_hidden_states = False
[2022-08-11 20:32:46] - INFO: ### output_attentions = False
[2022-08-11 20:32:46] - INFO: ### torchscript = False
[2022-08-11 20:32:46] - INFO: ### torch_dtype = None
[2022-08-11 20:32:46] - INFO: ### use_bfloat16 = False
[2022-08-11 20:32:46] - INFO: ### pruned_heads = {}
[2022-08-11 20:32:46] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:32:46] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:32:46] - INFO: ### is_decoder = False
[2022-08-11 20:32:46] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:32:46] - INFO: ### add_cross_attention = False
[2022-08-11 20:32:46] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:32:46] - INFO: ### max_length = 20
[2022-08-11 20:32:46] - INFO: ### min_length = 0
[2022-08-11 20:32:46] - INFO: ### do_sample = False
[2022-08-11 20:32:46] - INFO: ### early_stopping = False
[2022-08-11 20:32:46] - INFO: ### num_beams = 1
[2022-08-11 20:32:46] - INFO: ### num_beam_groups = 1
[2022-08-11 20:32:46] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:32:46] - INFO: ### temperature = 1.0
[2022-08-11 20:32:46] - INFO: ### top_k = 50
[2022-08-11 20:32:46] - INFO: ### top_p = 1.0
[2022-08-11 20:32:46] - INFO: ### typical_p = 1.0
[2022-08-11 20:32:46] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:32:46] - INFO: ### length_penalty = 1.0
[2022-08-11 20:32:46] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:32:46] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:32:46] - INFO: ### bad_words_ids = None
[2022-08-11 20:32:46] - INFO: ### num_return_sequences = 1
[2022-08-11 20:32:46] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:32:46] - INFO: ### output_scores = False
[2022-08-11 20:32:46] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:32:46] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:32:46] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:32:46] - INFO: ### remove_invalid_values = False
[2022-08-11 20:32:46] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:32:46] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:32:46] - INFO: ### finetuning_task = None
[2022-08-11 20:32:46] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:32:46] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:32:46] - INFO: ### tokenizer_class = None
[2022-08-11 20:32:46] - INFO: ### prefix = None
[2022-08-11 20:32:46] - INFO: ### bos_token_id = None
[2022-08-11 20:32:46] - INFO: ### pad_token_id = 0
[2022-08-11 20:32:46] - INFO: ### eos_token_id = None
[2022-08-11 20:32:46] - INFO: ### sep_token_id = None
[2022-08-11 20:32:46] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:32:46] - INFO: ### task_specific_params = None
[2022-08-11 20:32:46] - INFO: ### problem_type = None
[2022-08-11 20:32:46] - INFO: ### _name_or_path = 
[2022-08-11 20:32:46] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:32:46] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:32:46] - INFO: ### model_type = bert
[2022-08-11 20:32:46] - INFO: ### vocab_size = 30522
[2022-08-11 20:32:46] - INFO: ### hidden_size = 768
[2022-08-11 20:32:46] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:32:46] - INFO: ### num_attention_heads = 12
[2022-08-11 20:32:46] - INFO: ### hidden_act = gelu
[2022-08-11 20:32:46] - INFO: ### intermediate_size = 3072
[2022-08-11 20:32:46] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:32:46] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:32:46] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:32:46] - INFO: ### type_vocab_size = 2
[2022-08-11 20:32:46] - INFO: ### initializer_range = 0.02
[2022-08-11 20:32:46] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:32:46] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:32:46] - INFO: ### use_cache = True
[2022-08-11 20:32:46] - INFO: ### classifier_dropout = None
[2022-08-11 20:33:23] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:33:23] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:33:23] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:33:23] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:33:23] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:33:23] - INFO: ### device = cpu
[2022-08-11 20:33:23] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:33:23] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:33:23] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:33:23] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:33:23] - INFO: ### batch_size = 10
[2022-08-11 20:33:23] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:33:23] - INFO: ### epochs = 5
[2022-08-11 20:33:23] - INFO: ### nums_labels = 5
[2022-08-11 20:33:23] - INFO: ### return_dict = True
[2022-08-11 20:33:23] - INFO: ### output_hidden_states = False
[2022-08-11 20:33:23] - INFO: ### output_attentions = False
[2022-08-11 20:33:23] - INFO: ### torchscript = False
[2022-08-11 20:33:23] - INFO: ### torch_dtype = None
[2022-08-11 20:33:23] - INFO: ### use_bfloat16 = False
[2022-08-11 20:33:23] - INFO: ### pruned_heads = {}
[2022-08-11 20:33:23] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:33:23] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:33:23] - INFO: ### is_decoder = False
[2022-08-11 20:33:23] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:33:23] - INFO: ### add_cross_attention = False
[2022-08-11 20:33:23] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:33:23] - INFO: ### max_length = 20
[2022-08-11 20:33:23] - INFO: ### min_length = 0
[2022-08-11 20:33:23] - INFO: ### do_sample = False
[2022-08-11 20:33:23] - INFO: ### early_stopping = False
[2022-08-11 20:33:23] - INFO: ### num_beams = 1
[2022-08-11 20:33:23] - INFO: ### num_beam_groups = 1
[2022-08-11 20:33:23] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:33:23] - INFO: ### temperature = 1.0
[2022-08-11 20:33:23] - INFO: ### top_k = 50
[2022-08-11 20:33:23] - INFO: ### top_p = 1.0
[2022-08-11 20:33:23] - INFO: ### typical_p = 1.0
[2022-08-11 20:33:23] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:33:23] - INFO: ### length_penalty = 1.0
[2022-08-11 20:33:23] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:33:23] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:33:23] - INFO: ### bad_words_ids = None
[2022-08-11 20:33:23] - INFO: ### num_return_sequences = 1
[2022-08-11 20:33:23] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:33:23] - INFO: ### output_scores = False
[2022-08-11 20:33:23] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:33:23] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:33:23] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:33:23] - INFO: ### remove_invalid_values = False
[2022-08-11 20:33:23] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:33:23] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:33:23] - INFO: ### finetuning_task = None
[2022-08-11 20:33:23] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:33:23] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:33:23] - INFO: ### tokenizer_class = None
[2022-08-11 20:33:23] - INFO: ### prefix = None
[2022-08-11 20:33:23] - INFO: ### bos_token_id = None
[2022-08-11 20:33:23] - INFO: ### pad_token_id = 0
[2022-08-11 20:33:23] - INFO: ### eos_token_id = None
[2022-08-11 20:33:23] - INFO: ### sep_token_id = None
[2022-08-11 20:33:23] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:33:23] - INFO: ### task_specific_params = None
[2022-08-11 20:33:23] - INFO: ### problem_type = None
[2022-08-11 20:33:23] - INFO: ### _name_or_path = 
[2022-08-11 20:33:23] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:33:23] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:33:23] - INFO: ### model_type = bert
[2022-08-11 20:33:23] - INFO: ### vocab_size = 30522
[2022-08-11 20:33:23] - INFO: ### hidden_size = 768
[2022-08-11 20:33:23] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:33:23] - INFO: ### num_attention_heads = 12
[2022-08-11 20:33:23] - INFO: ### hidden_act = gelu
[2022-08-11 20:33:23] - INFO: ### intermediate_size = 3072
[2022-08-11 20:33:23] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:33:23] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:33:23] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:33:23] - INFO: ### type_vocab_size = 2
[2022-08-11 20:33:23] - INFO: ### initializer_range = 0.02
[2022-08-11 20:33:23] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:33:23] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:33:23] - INFO: ### use_cache = True
[2022-08-11 20:33:23] - INFO: ### classifier_dropout = None
[2022-08-11 20:34:46] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:34:46] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:34:46] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:34:46] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:34:46] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:34:46] - INFO: ### device = cpu
[2022-08-11 20:34:46] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:34:46] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:34:46] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:34:46] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:34:46] - INFO: ### batch_size = 10
[2022-08-11 20:34:46] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:34:46] - INFO: ### epochs = 5
[2022-08-11 20:34:46] - INFO: ### nums_labels = 5
[2022-08-11 20:34:46] - INFO: ### return_dict = True
[2022-08-11 20:34:46] - INFO: ### output_hidden_states = False
[2022-08-11 20:34:46] - INFO: ### output_attentions = False
[2022-08-11 20:34:46] - INFO: ### torchscript = False
[2022-08-11 20:34:46] - INFO: ### torch_dtype = None
[2022-08-11 20:34:46] - INFO: ### use_bfloat16 = False
[2022-08-11 20:34:46] - INFO: ### pruned_heads = {}
[2022-08-11 20:34:46] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:34:46] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:34:46] - INFO: ### is_decoder = False
[2022-08-11 20:34:46] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:34:46] - INFO: ### add_cross_attention = False
[2022-08-11 20:34:46] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:34:46] - INFO: ### max_length = 20
[2022-08-11 20:34:46] - INFO: ### min_length = 0
[2022-08-11 20:34:46] - INFO: ### do_sample = False
[2022-08-11 20:34:46] - INFO: ### early_stopping = False
[2022-08-11 20:34:46] - INFO: ### num_beams = 1
[2022-08-11 20:34:46] - INFO: ### num_beam_groups = 1
[2022-08-11 20:34:46] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:34:46] - INFO: ### temperature = 1.0
[2022-08-11 20:34:46] - INFO: ### top_k = 50
[2022-08-11 20:34:46] - INFO: ### top_p = 1.0
[2022-08-11 20:34:46] - INFO: ### typical_p = 1.0
[2022-08-11 20:34:46] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:34:46] - INFO: ### length_penalty = 1.0
[2022-08-11 20:34:46] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:34:46] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:34:46] - INFO: ### bad_words_ids = None
[2022-08-11 20:34:46] - INFO: ### num_return_sequences = 1
[2022-08-11 20:34:46] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:34:46] - INFO: ### output_scores = False
[2022-08-11 20:34:46] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:34:46] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:34:46] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:34:46] - INFO: ### remove_invalid_values = False
[2022-08-11 20:34:46] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:34:46] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:34:46] - INFO: ### finetuning_task = None
[2022-08-11 20:34:46] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:34:46] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:34:46] - INFO: ### tokenizer_class = None
[2022-08-11 20:34:46] - INFO: ### prefix = None
[2022-08-11 20:34:46] - INFO: ### bos_token_id = None
[2022-08-11 20:34:46] - INFO: ### pad_token_id = 0
[2022-08-11 20:34:46] - INFO: ### eos_token_id = None
[2022-08-11 20:34:46] - INFO: ### sep_token_id = None
[2022-08-11 20:34:46] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:34:46] - INFO: ### task_specific_params = None
[2022-08-11 20:34:46] - INFO: ### problem_type = None
[2022-08-11 20:34:46] - INFO: ### _name_or_path = 
[2022-08-11 20:34:46] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:34:46] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:34:46] - INFO: ### model_type = bert
[2022-08-11 20:34:46] - INFO: ### vocab_size = 30522
[2022-08-11 20:34:46] - INFO: ### hidden_size = 768
[2022-08-11 20:34:46] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:34:46] - INFO: ### num_attention_heads = 12
[2022-08-11 20:34:46] - INFO: ### hidden_act = gelu
[2022-08-11 20:34:46] - INFO: ### intermediate_size = 3072
[2022-08-11 20:34:46] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:34:46] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:34:46] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:34:46] - INFO: ### type_vocab_size = 2
[2022-08-11 20:34:46] - INFO: ### initializer_range = 0.02
[2022-08-11 20:34:46] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:34:46] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:34:46] - INFO: ### use_cache = True
[2022-08-11 20:34:46] - INFO: ### classifier_dropout = None
[2022-08-11 20:35:07] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:35:07] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:35:07] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:35:07] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:35:07] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:35:07] - INFO: ### device = cpu
[2022-08-11 20:35:07] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:35:07] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:35:07] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:35:07] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:35:07] - INFO: ### batch_size = 10
[2022-08-11 20:35:07] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:35:07] - INFO: ### epochs = 5
[2022-08-11 20:35:07] - INFO: ### nums_labels = 5
[2022-08-11 20:35:07] - INFO: ### return_dict = True
[2022-08-11 20:35:07] - INFO: ### output_hidden_states = False
[2022-08-11 20:35:07] - INFO: ### output_attentions = False
[2022-08-11 20:35:07] - INFO: ### torchscript = False
[2022-08-11 20:35:07] - INFO: ### torch_dtype = None
[2022-08-11 20:35:07] - INFO: ### use_bfloat16 = False
[2022-08-11 20:35:07] - INFO: ### pruned_heads = {}
[2022-08-11 20:35:07] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:35:07] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:35:07] - INFO: ### is_decoder = False
[2022-08-11 20:35:07] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:35:07] - INFO: ### add_cross_attention = False
[2022-08-11 20:35:07] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:35:07] - INFO: ### max_length = 20
[2022-08-11 20:35:07] - INFO: ### min_length = 0
[2022-08-11 20:35:07] - INFO: ### do_sample = False
[2022-08-11 20:35:07] - INFO: ### early_stopping = False
[2022-08-11 20:35:07] - INFO: ### num_beams = 1
[2022-08-11 20:35:07] - INFO: ### num_beam_groups = 1
[2022-08-11 20:35:07] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:35:07] - INFO: ### temperature = 1.0
[2022-08-11 20:35:07] - INFO: ### top_k = 50
[2022-08-11 20:35:07] - INFO: ### top_p = 1.0
[2022-08-11 20:35:07] - INFO: ### typical_p = 1.0
[2022-08-11 20:35:07] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:35:07] - INFO: ### length_penalty = 1.0
[2022-08-11 20:35:07] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:35:07] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:35:07] - INFO: ### bad_words_ids = None
[2022-08-11 20:35:07] - INFO: ### num_return_sequences = 1
[2022-08-11 20:35:07] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:35:07] - INFO: ### output_scores = False
[2022-08-11 20:35:07] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:35:07] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:35:07] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:35:07] - INFO: ### remove_invalid_values = False
[2022-08-11 20:35:07] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:35:07] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:35:07] - INFO: ### finetuning_task = None
[2022-08-11 20:35:07] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:35:07] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:35:07] - INFO: ### tokenizer_class = None
[2022-08-11 20:35:07] - INFO: ### prefix = None
[2022-08-11 20:35:07] - INFO: ### bos_token_id = None
[2022-08-11 20:35:07] - INFO: ### pad_token_id = 0
[2022-08-11 20:35:07] - INFO: ### eos_token_id = None
[2022-08-11 20:35:07] - INFO: ### sep_token_id = None
[2022-08-11 20:35:07] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:35:07] - INFO: ### task_specific_params = None
[2022-08-11 20:35:07] - INFO: ### problem_type = None
[2022-08-11 20:35:07] - INFO: ### _name_or_path = 
[2022-08-11 20:35:07] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:35:07] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:35:07] - INFO: ### model_type = bert
[2022-08-11 20:35:07] - INFO: ### vocab_size = 30522
[2022-08-11 20:35:07] - INFO: ### hidden_size = 768
[2022-08-11 20:35:07] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:35:07] - INFO: ### num_attention_heads = 12
[2022-08-11 20:35:07] - INFO: ### hidden_act = gelu
[2022-08-11 20:35:07] - INFO: ### intermediate_size = 3072
[2022-08-11 20:35:07] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:35:07] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:35:07] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:35:07] - INFO: ### type_vocab_size = 2
[2022-08-11 20:35:07] - INFO: ### initializer_range = 0.02
[2022-08-11 20:35:07] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:35:07] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:35:07] - INFO: ### use_cache = True
[2022-08-11 20:35:07] - INFO: ### classifier_dropout = None
[2022-08-11 20:54:54] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:54:54] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:54:54] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:54:54] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:54:54] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:54:54] - INFO: ### device = cpu
[2022-08-11 20:54:54] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:54:54] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:54:54] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:54:54] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:54:54] - INFO: ### batch_size = 10
[2022-08-11 20:54:54] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:54:54] - INFO: ### epochs = 5
[2022-08-11 20:54:54] - INFO: ### nums_labels = 5
[2022-08-11 20:54:54] - INFO: ### return_dict = True
[2022-08-11 20:54:54] - INFO: ### output_hidden_states = False
[2022-08-11 20:54:54] - INFO: ### output_attentions = False
[2022-08-11 20:54:54] - INFO: ### torchscript = False
[2022-08-11 20:54:54] - INFO: ### torch_dtype = None
[2022-08-11 20:54:54] - INFO: ### use_bfloat16 = False
[2022-08-11 20:54:54] - INFO: ### pruned_heads = {}
[2022-08-11 20:54:54] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:54:54] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:54:54] - INFO: ### is_decoder = False
[2022-08-11 20:54:54] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:54:54] - INFO: ### add_cross_attention = False
[2022-08-11 20:54:54] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:54:54] - INFO: ### max_length = 20
[2022-08-11 20:54:54] - INFO: ### min_length = 0
[2022-08-11 20:54:54] - INFO: ### do_sample = False
[2022-08-11 20:54:54] - INFO: ### early_stopping = False
[2022-08-11 20:54:54] - INFO: ### num_beams = 1
[2022-08-11 20:54:54] - INFO: ### num_beam_groups = 1
[2022-08-11 20:54:54] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:54:54] - INFO: ### temperature = 1.0
[2022-08-11 20:54:54] - INFO: ### top_k = 50
[2022-08-11 20:54:54] - INFO: ### top_p = 1.0
[2022-08-11 20:54:54] - INFO: ### typical_p = 1.0
[2022-08-11 20:54:54] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:54:54] - INFO: ### length_penalty = 1.0
[2022-08-11 20:54:54] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:54:54] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:54:54] - INFO: ### bad_words_ids = None
[2022-08-11 20:54:54] - INFO: ### num_return_sequences = 1
[2022-08-11 20:54:54] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:54:54] - INFO: ### output_scores = False
[2022-08-11 20:54:54] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:54:54] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:54:54] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:54:54] - INFO: ### remove_invalid_values = False
[2022-08-11 20:54:54] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:54:54] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:54:54] - INFO: ### finetuning_task = None
[2022-08-11 20:54:54] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:54:54] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:54:54] - INFO: ### tokenizer_class = None
[2022-08-11 20:54:54] - INFO: ### prefix = None
[2022-08-11 20:54:54] - INFO: ### bos_token_id = None
[2022-08-11 20:54:54] - INFO: ### pad_token_id = 0
[2022-08-11 20:54:54] - INFO: ### eos_token_id = None
[2022-08-11 20:54:54] - INFO: ### sep_token_id = None
[2022-08-11 20:54:54] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:54:54] - INFO: ### task_specific_params = None
[2022-08-11 20:54:54] - INFO: ### problem_type = None
[2022-08-11 20:54:54] - INFO: ### _name_or_path = 
[2022-08-11 20:54:54] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:54:54] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:54:54] - INFO: ### model_type = bert
[2022-08-11 20:54:54] - INFO: ### vocab_size = 30522
[2022-08-11 20:54:54] - INFO: ### hidden_size = 768
[2022-08-11 20:54:54] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:54:54] - INFO: ### num_attention_heads = 12
[2022-08-11 20:54:54] - INFO: ### hidden_act = gelu
[2022-08-11 20:54:54] - INFO: ### intermediate_size = 3072
[2022-08-11 20:54:54] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:54:54] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:54:54] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:54:54] - INFO: ### type_vocab_size = 2
[2022-08-11 20:54:54] - INFO: ### initializer_range = 0.02
[2022-08-11 20:54:54] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:54:54] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:54:54] - INFO: ### use_cache = True
[2022-08-11 20:54:54] - INFO: ### classifier_dropout = None
[2022-08-11 20:58:08] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 20:58:08] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 20:58:08] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 20:58:08] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 20:58:08] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 20:58:08] - INFO: ### device = cpu
[2022-08-11 20:58:08] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 20:58:08] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 20:58:08] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 20:58:08] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 20:58:08] - INFO: ### batch_size = 10
[2022-08-11 20:58:08] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 20:58:08] - INFO: ### epochs = 5
[2022-08-11 20:58:08] - INFO: ### nums_labels = 5
[2022-08-11 20:58:08] - INFO: ### return_dict = True
[2022-08-11 20:58:08] - INFO: ### output_hidden_states = False
[2022-08-11 20:58:08] - INFO: ### output_attentions = False
[2022-08-11 20:58:08] - INFO: ### torchscript = False
[2022-08-11 20:58:08] - INFO: ### torch_dtype = None
[2022-08-11 20:58:08] - INFO: ### use_bfloat16 = False
[2022-08-11 20:58:08] - INFO: ### pruned_heads = {}
[2022-08-11 20:58:08] - INFO: ### tie_word_embeddings = True
[2022-08-11 20:58:08] - INFO: ### is_encoder_decoder = False
[2022-08-11 20:58:08] - INFO: ### is_decoder = False
[2022-08-11 20:58:08] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 20:58:08] - INFO: ### add_cross_attention = False
[2022-08-11 20:58:08] - INFO: ### tie_encoder_decoder = False
[2022-08-11 20:58:08] - INFO: ### max_length = 20
[2022-08-11 20:58:08] - INFO: ### min_length = 0
[2022-08-11 20:58:08] - INFO: ### do_sample = False
[2022-08-11 20:58:08] - INFO: ### early_stopping = False
[2022-08-11 20:58:08] - INFO: ### num_beams = 1
[2022-08-11 20:58:08] - INFO: ### num_beam_groups = 1
[2022-08-11 20:58:08] - INFO: ### diversity_penalty = 0.0
[2022-08-11 20:58:08] - INFO: ### temperature = 1.0
[2022-08-11 20:58:08] - INFO: ### top_k = 50
[2022-08-11 20:58:08] - INFO: ### top_p = 1.0
[2022-08-11 20:58:08] - INFO: ### typical_p = 1.0
[2022-08-11 20:58:08] - INFO: ### repetition_penalty = 1.0
[2022-08-11 20:58:08] - INFO: ### length_penalty = 1.0
[2022-08-11 20:58:08] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 20:58:08] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 20:58:08] - INFO: ### bad_words_ids = None
[2022-08-11 20:58:08] - INFO: ### num_return_sequences = 1
[2022-08-11 20:58:08] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 20:58:08] - INFO: ### output_scores = False
[2022-08-11 20:58:08] - INFO: ### return_dict_in_generate = False
[2022-08-11 20:58:08] - INFO: ### forced_bos_token_id = None
[2022-08-11 20:58:08] - INFO: ### forced_eos_token_id = None
[2022-08-11 20:58:08] - INFO: ### remove_invalid_values = False
[2022-08-11 20:58:08] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 20:58:08] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 20:58:08] - INFO: ### finetuning_task = None
[2022-08-11 20:58:08] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 20:58:08] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 20:58:08] - INFO: ### tokenizer_class = None
[2022-08-11 20:58:08] - INFO: ### prefix = None
[2022-08-11 20:58:08] - INFO: ### bos_token_id = None
[2022-08-11 20:58:08] - INFO: ### pad_token_id = 0
[2022-08-11 20:58:08] - INFO: ### eos_token_id = None
[2022-08-11 20:58:08] - INFO: ### sep_token_id = None
[2022-08-11 20:58:08] - INFO: ### decoder_start_token_id = None
[2022-08-11 20:58:08] - INFO: ### task_specific_params = None
[2022-08-11 20:58:08] - INFO: ### problem_type = None
[2022-08-11 20:58:08] - INFO: ### _name_or_path = 
[2022-08-11 20:58:08] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 20:58:08] - INFO: ### gradient_checkpointing = False
[2022-08-11 20:58:08] - INFO: ### model_type = bert
[2022-08-11 20:58:08] - INFO: ### vocab_size = 30522
[2022-08-11 20:58:08] - INFO: ### hidden_size = 768
[2022-08-11 20:58:08] - INFO: ### num_hidden_layers = 12
[2022-08-11 20:58:08] - INFO: ### num_attention_heads = 12
[2022-08-11 20:58:08] - INFO: ### hidden_act = gelu
[2022-08-11 20:58:08] - INFO: ### intermediate_size = 3072
[2022-08-11 20:58:08] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 20:58:08] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 20:58:08] - INFO: ### max_position_embeddings = 512
[2022-08-11 20:58:08] - INFO: ### type_vocab_size = 2
[2022-08-11 20:58:08] - INFO: ### initializer_range = 0.02
[2022-08-11 20:58:08] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 20:58:08] - INFO: ### position_embedding_type = absolute
[2022-08-11 20:58:08] - INFO: ### use_cache = True
[2022-08-11 20:58:08] - INFO: ### classifier_dropout = None
[2022-08-11 21:01:09] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:01:09] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:01:09] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:01:09] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:01:09] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:01:09] - INFO: ### device = cpu
[2022-08-11 21:01:09] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:01:09] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:01:09] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:01:09] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:01:09] - INFO: ### batch_size = 10
[2022-08-11 21:01:09] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:01:09] - INFO: ### epochs = 5
[2022-08-11 21:01:09] - INFO: ### nums_labels = 5
[2022-08-11 21:01:09] - INFO: ### return_dict = True
[2022-08-11 21:01:09] - INFO: ### output_hidden_states = False
[2022-08-11 21:01:09] - INFO: ### output_attentions = False
[2022-08-11 21:01:09] - INFO: ### torchscript = False
[2022-08-11 21:01:09] - INFO: ### torch_dtype = None
[2022-08-11 21:01:09] - INFO: ### use_bfloat16 = False
[2022-08-11 21:01:09] - INFO: ### pruned_heads = {}
[2022-08-11 21:01:09] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:01:09] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:01:09] - INFO: ### is_decoder = False
[2022-08-11 21:01:09] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:01:09] - INFO: ### add_cross_attention = False
[2022-08-11 21:01:09] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:01:09] - INFO: ### max_length = 20
[2022-08-11 21:01:09] - INFO: ### min_length = 0
[2022-08-11 21:01:09] - INFO: ### do_sample = False
[2022-08-11 21:01:09] - INFO: ### early_stopping = False
[2022-08-11 21:01:09] - INFO: ### num_beams = 1
[2022-08-11 21:01:09] - INFO: ### num_beam_groups = 1
[2022-08-11 21:01:09] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:01:09] - INFO: ### temperature = 1.0
[2022-08-11 21:01:09] - INFO: ### top_k = 50
[2022-08-11 21:01:09] - INFO: ### top_p = 1.0
[2022-08-11 21:01:09] - INFO: ### typical_p = 1.0
[2022-08-11 21:01:09] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:01:09] - INFO: ### length_penalty = 1.0
[2022-08-11 21:01:09] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:01:09] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:01:09] - INFO: ### bad_words_ids = None
[2022-08-11 21:01:09] - INFO: ### num_return_sequences = 1
[2022-08-11 21:01:09] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:01:09] - INFO: ### output_scores = False
[2022-08-11 21:01:09] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:01:09] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:01:09] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:01:09] - INFO: ### remove_invalid_values = False
[2022-08-11 21:01:09] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:01:09] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:01:09] - INFO: ### finetuning_task = None
[2022-08-11 21:01:09] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:01:09] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:01:09] - INFO: ### tokenizer_class = None
[2022-08-11 21:01:09] - INFO: ### prefix = None
[2022-08-11 21:01:09] - INFO: ### bos_token_id = None
[2022-08-11 21:01:09] - INFO: ### pad_token_id = 0
[2022-08-11 21:01:09] - INFO: ### eos_token_id = None
[2022-08-11 21:01:09] - INFO: ### sep_token_id = None
[2022-08-11 21:01:09] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:01:09] - INFO: ### task_specific_params = None
[2022-08-11 21:01:09] - INFO: ### problem_type = None
[2022-08-11 21:01:09] - INFO: ### _name_or_path = 
[2022-08-11 21:01:09] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:01:09] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:01:09] - INFO: ### model_type = bert
[2022-08-11 21:01:09] - INFO: ### vocab_size = 30522
[2022-08-11 21:01:09] - INFO: ### hidden_size = 768
[2022-08-11 21:01:09] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:01:09] - INFO: ### num_attention_heads = 12
[2022-08-11 21:01:09] - INFO: ### hidden_act = gelu
[2022-08-11 21:01:09] - INFO: ### intermediate_size = 3072
[2022-08-11 21:01:09] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:01:09] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:01:09] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:01:09] - INFO: ### type_vocab_size = 2
[2022-08-11 21:01:09] - INFO: ### initializer_range = 0.02
[2022-08-11 21:01:09] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:01:09] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:01:09] - INFO: ### use_cache = True
[2022-08-11 21:01:09] - INFO: ### classifier_dropout = None
[2022-08-11 21:04:02] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:04:02] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:04:02] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:04:02] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:04:02] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:04:02] - INFO: ### device = cpu
[2022-08-11 21:04:02] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:04:02] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:04:02] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:04:02] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:04:02] - INFO: ### batch_size = 10
[2022-08-11 21:04:02] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:04:02] - INFO: ### epochs = 5
[2022-08-11 21:04:02] - INFO: ### nums_labels = 5
[2022-08-11 21:04:02] - INFO: ### return_dict = True
[2022-08-11 21:04:02] - INFO: ### output_hidden_states = False
[2022-08-11 21:04:02] - INFO: ### output_attentions = False
[2022-08-11 21:04:02] - INFO: ### torchscript = False
[2022-08-11 21:04:02] - INFO: ### torch_dtype = None
[2022-08-11 21:04:02] - INFO: ### use_bfloat16 = False
[2022-08-11 21:04:02] - INFO: ### pruned_heads = {}
[2022-08-11 21:04:02] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:04:02] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:04:02] - INFO: ### is_decoder = False
[2022-08-11 21:04:02] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:04:02] - INFO: ### add_cross_attention = False
[2022-08-11 21:04:02] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:04:02] - INFO: ### max_length = 20
[2022-08-11 21:04:02] - INFO: ### min_length = 0
[2022-08-11 21:04:02] - INFO: ### do_sample = False
[2022-08-11 21:04:02] - INFO: ### early_stopping = False
[2022-08-11 21:04:02] - INFO: ### num_beams = 1
[2022-08-11 21:04:02] - INFO: ### num_beam_groups = 1
[2022-08-11 21:04:02] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:04:02] - INFO: ### temperature = 1.0
[2022-08-11 21:04:02] - INFO: ### top_k = 50
[2022-08-11 21:04:02] - INFO: ### top_p = 1.0
[2022-08-11 21:04:02] - INFO: ### typical_p = 1.0
[2022-08-11 21:04:02] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:04:02] - INFO: ### length_penalty = 1.0
[2022-08-11 21:04:02] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:04:02] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:04:02] - INFO: ### bad_words_ids = None
[2022-08-11 21:04:02] - INFO: ### num_return_sequences = 1
[2022-08-11 21:04:02] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:04:02] - INFO: ### output_scores = False
[2022-08-11 21:04:02] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:04:02] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:04:02] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:04:02] - INFO: ### remove_invalid_values = False
[2022-08-11 21:04:02] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:04:02] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:04:02] - INFO: ### finetuning_task = None
[2022-08-11 21:04:02] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:04:02] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:04:02] - INFO: ### tokenizer_class = None
[2022-08-11 21:04:02] - INFO: ### prefix = None
[2022-08-11 21:04:02] - INFO: ### bos_token_id = None
[2022-08-11 21:04:02] - INFO: ### pad_token_id = 0
[2022-08-11 21:04:02] - INFO: ### eos_token_id = None
[2022-08-11 21:04:02] - INFO: ### sep_token_id = None
[2022-08-11 21:04:02] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:04:02] - INFO: ### task_specific_params = None
[2022-08-11 21:04:02] - INFO: ### problem_type = None
[2022-08-11 21:04:02] - INFO: ### _name_or_path = 
[2022-08-11 21:04:02] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:04:02] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:04:02] - INFO: ### model_type = bert
[2022-08-11 21:04:02] - INFO: ### vocab_size = 30522
[2022-08-11 21:04:02] - INFO: ### hidden_size = 768
[2022-08-11 21:04:02] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:04:02] - INFO: ### num_attention_heads = 12
[2022-08-11 21:04:02] - INFO: ### hidden_act = gelu
[2022-08-11 21:04:02] - INFO: ### intermediate_size = 3072
[2022-08-11 21:04:02] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:04:02] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:04:02] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:04:02] - INFO: ### type_vocab_size = 2
[2022-08-11 21:04:02] - INFO: ### initializer_range = 0.02
[2022-08-11 21:04:02] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:04:02] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:04:02] - INFO: ### use_cache = True
[2022-08-11 21:04:02] - INFO: ### classifier_dropout = None
[2022-08-11 21:04:52] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:04:52] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:04:52] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:04:52] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:04:52] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:04:52] - INFO: ### device = cpu
[2022-08-11 21:04:52] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:04:52] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:04:52] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:04:52] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:04:52] - INFO: ### batch_size = 10
[2022-08-11 21:04:52] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:04:52] - INFO: ### epochs = 5
[2022-08-11 21:04:52] - INFO: ### nums_labels = 5
[2022-08-11 21:04:52] - INFO: ### return_dict = True
[2022-08-11 21:04:52] - INFO: ### output_hidden_states = False
[2022-08-11 21:04:52] - INFO: ### output_attentions = False
[2022-08-11 21:04:52] - INFO: ### torchscript = False
[2022-08-11 21:04:52] - INFO: ### torch_dtype = None
[2022-08-11 21:04:52] - INFO: ### use_bfloat16 = False
[2022-08-11 21:04:52] - INFO: ### pruned_heads = {}
[2022-08-11 21:04:52] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:04:52] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:04:52] - INFO: ### is_decoder = False
[2022-08-11 21:04:52] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:04:52] - INFO: ### add_cross_attention = False
[2022-08-11 21:04:52] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:04:52] - INFO: ### max_length = 20
[2022-08-11 21:04:52] - INFO: ### min_length = 0
[2022-08-11 21:04:52] - INFO: ### do_sample = False
[2022-08-11 21:04:52] - INFO: ### early_stopping = False
[2022-08-11 21:04:52] - INFO: ### num_beams = 1
[2022-08-11 21:04:52] - INFO: ### num_beam_groups = 1
[2022-08-11 21:04:52] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:04:52] - INFO: ### temperature = 1.0
[2022-08-11 21:04:52] - INFO: ### top_k = 50
[2022-08-11 21:04:52] - INFO: ### top_p = 1.0
[2022-08-11 21:04:52] - INFO: ### typical_p = 1.0
[2022-08-11 21:04:52] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:04:52] - INFO: ### length_penalty = 1.0
[2022-08-11 21:04:52] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:04:52] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:04:52] - INFO: ### bad_words_ids = None
[2022-08-11 21:04:52] - INFO: ### num_return_sequences = 1
[2022-08-11 21:04:52] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:04:52] - INFO: ### output_scores = False
[2022-08-11 21:04:52] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:04:52] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:04:52] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:04:52] - INFO: ### remove_invalid_values = False
[2022-08-11 21:04:52] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:04:52] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:04:52] - INFO: ### finetuning_task = None
[2022-08-11 21:04:52] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:04:52] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:04:52] - INFO: ### tokenizer_class = None
[2022-08-11 21:04:52] - INFO: ### prefix = None
[2022-08-11 21:04:52] - INFO: ### bos_token_id = None
[2022-08-11 21:04:52] - INFO: ### pad_token_id = 0
[2022-08-11 21:04:52] - INFO: ### eos_token_id = None
[2022-08-11 21:04:52] - INFO: ### sep_token_id = None
[2022-08-11 21:04:52] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:04:52] - INFO: ### task_specific_params = None
[2022-08-11 21:04:52] - INFO: ### problem_type = None
[2022-08-11 21:04:52] - INFO: ### _name_or_path = 
[2022-08-11 21:04:52] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:04:52] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:04:52] - INFO: ### model_type = bert
[2022-08-11 21:04:52] - INFO: ### vocab_size = 30522
[2022-08-11 21:04:52] - INFO: ### hidden_size = 768
[2022-08-11 21:04:52] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:04:52] - INFO: ### num_attention_heads = 12
[2022-08-11 21:04:52] - INFO: ### hidden_act = gelu
[2022-08-11 21:04:52] - INFO: ### intermediate_size = 3072
[2022-08-11 21:04:52] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:04:52] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:04:52] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:04:52] - INFO: ### type_vocab_size = 2
[2022-08-11 21:04:52] - INFO: ### initializer_range = 0.02
[2022-08-11 21:04:52] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:04:52] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:04:52] - INFO: ### use_cache = True
[2022-08-11 21:04:52] - INFO: ### classifier_dropout = None
[2022-08-11 21:20:03] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:20:03] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:20:03] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:20:03] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:20:03] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:20:03] - INFO: ### device = cpu
[2022-08-11 21:20:03] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:20:03] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:20:03] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:20:03] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:20:03] - INFO: ### batch_size = 10
[2022-08-11 21:20:03] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:20:03] - INFO: ### epochs = 5
[2022-08-11 21:20:03] - INFO: ### nums_labels = 5
[2022-08-11 21:20:03] - INFO: ### return_dict = True
[2022-08-11 21:20:03] - INFO: ### output_hidden_states = False
[2022-08-11 21:20:03] - INFO: ### output_attentions = False
[2022-08-11 21:20:03] - INFO: ### torchscript = False
[2022-08-11 21:20:03] - INFO: ### torch_dtype = None
[2022-08-11 21:20:03] - INFO: ### use_bfloat16 = False
[2022-08-11 21:20:03] - INFO: ### pruned_heads = {}
[2022-08-11 21:20:03] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:20:03] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:20:03] - INFO: ### is_decoder = False
[2022-08-11 21:20:03] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:20:03] - INFO: ### add_cross_attention = False
[2022-08-11 21:20:03] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:20:03] - INFO: ### max_length = 20
[2022-08-11 21:20:03] - INFO: ### min_length = 0
[2022-08-11 21:20:03] - INFO: ### do_sample = False
[2022-08-11 21:20:03] - INFO: ### early_stopping = False
[2022-08-11 21:20:03] - INFO: ### num_beams = 1
[2022-08-11 21:20:03] - INFO: ### num_beam_groups = 1
[2022-08-11 21:20:03] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:20:03] - INFO: ### temperature = 1.0
[2022-08-11 21:20:03] - INFO: ### top_k = 50
[2022-08-11 21:20:03] - INFO: ### top_p = 1.0
[2022-08-11 21:20:03] - INFO: ### typical_p = 1.0
[2022-08-11 21:20:03] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:20:03] - INFO: ### length_penalty = 1.0
[2022-08-11 21:20:03] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:20:03] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:20:03] - INFO: ### bad_words_ids = None
[2022-08-11 21:20:03] - INFO: ### num_return_sequences = 1
[2022-08-11 21:20:03] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:20:03] - INFO: ### output_scores = False
[2022-08-11 21:20:03] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:20:03] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:20:03] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:20:03] - INFO: ### remove_invalid_values = False
[2022-08-11 21:20:03] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:20:03] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:20:03] - INFO: ### finetuning_task = None
[2022-08-11 21:20:03] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:20:03] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:20:03] - INFO: ### tokenizer_class = None
[2022-08-11 21:20:03] - INFO: ### prefix = None
[2022-08-11 21:20:03] - INFO: ### bos_token_id = None
[2022-08-11 21:20:03] - INFO: ### pad_token_id = 0
[2022-08-11 21:20:03] - INFO: ### eos_token_id = None
[2022-08-11 21:20:03] - INFO: ### sep_token_id = None
[2022-08-11 21:20:03] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:20:03] - INFO: ### task_specific_params = None
[2022-08-11 21:20:03] - INFO: ### problem_type = None
[2022-08-11 21:20:03] - INFO: ### _name_or_path = 
[2022-08-11 21:20:03] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:20:03] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:20:03] - INFO: ### model_type = bert
[2022-08-11 21:20:03] - INFO: ### vocab_size = 30522
[2022-08-11 21:20:03] - INFO: ### hidden_size = 768
[2022-08-11 21:20:03] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:20:03] - INFO: ### num_attention_heads = 12
[2022-08-11 21:20:03] - INFO: ### hidden_act = gelu
[2022-08-11 21:20:03] - INFO: ### intermediate_size = 3072
[2022-08-11 21:20:03] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:20:03] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:20:03] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:20:03] - INFO: ### type_vocab_size = 2
[2022-08-11 21:20:03] - INFO: ### initializer_range = 0.02
[2022-08-11 21:20:03] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:20:03] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:20:03] - INFO: ### use_cache = True
[2022-08-11 21:20:03] - INFO: ### classifier_dropout = None
[2022-08-11 21:36:31] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:36:31] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:36:31] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:36:31] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:36:31] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:36:31] - INFO: ### device = cpu
[2022-08-11 21:36:31] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:36:31] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:36:31] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:36:31] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:36:31] - INFO: ### batch_size = 10
[2022-08-11 21:36:31] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:36:31] - INFO: ### epochs = 5
[2022-08-11 21:36:31] - INFO: ### nums_labels = 5
[2022-08-11 21:36:31] - INFO: ### return_dict = True
[2022-08-11 21:36:31] - INFO: ### output_hidden_states = False
[2022-08-11 21:36:31] - INFO: ### output_attentions = False
[2022-08-11 21:36:31] - INFO: ### torchscript = False
[2022-08-11 21:36:31] - INFO: ### torch_dtype = None
[2022-08-11 21:36:31] - INFO: ### use_bfloat16 = False
[2022-08-11 21:36:31] - INFO: ### pruned_heads = {}
[2022-08-11 21:36:31] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:36:31] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:36:31] - INFO: ### is_decoder = False
[2022-08-11 21:36:31] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:36:31] - INFO: ### add_cross_attention = False
[2022-08-11 21:36:31] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:36:31] - INFO: ### max_length = 20
[2022-08-11 21:36:31] - INFO: ### min_length = 0
[2022-08-11 21:36:31] - INFO: ### do_sample = False
[2022-08-11 21:36:31] - INFO: ### early_stopping = False
[2022-08-11 21:36:31] - INFO: ### num_beams = 1
[2022-08-11 21:36:31] - INFO: ### num_beam_groups = 1
[2022-08-11 21:36:31] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:36:31] - INFO: ### temperature = 1.0
[2022-08-11 21:36:31] - INFO: ### top_k = 50
[2022-08-11 21:36:31] - INFO: ### top_p = 1.0
[2022-08-11 21:36:31] - INFO: ### typical_p = 1.0
[2022-08-11 21:36:31] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:36:31] - INFO: ### length_penalty = 1.0
[2022-08-11 21:36:31] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:36:31] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:36:31] - INFO: ### bad_words_ids = None
[2022-08-11 21:36:31] - INFO: ### num_return_sequences = 1
[2022-08-11 21:36:31] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:36:31] - INFO: ### output_scores = False
[2022-08-11 21:36:31] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:36:31] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:36:31] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:36:31] - INFO: ### remove_invalid_values = False
[2022-08-11 21:36:31] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:36:31] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:36:31] - INFO: ### finetuning_task = None
[2022-08-11 21:36:31] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:36:31] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:36:31] - INFO: ### tokenizer_class = None
[2022-08-11 21:36:31] - INFO: ### prefix = None
[2022-08-11 21:36:31] - INFO: ### bos_token_id = None
[2022-08-11 21:36:31] - INFO: ### pad_token_id = 0
[2022-08-11 21:36:31] - INFO: ### eos_token_id = None
[2022-08-11 21:36:31] - INFO: ### sep_token_id = None
[2022-08-11 21:36:31] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:36:31] - INFO: ### task_specific_params = None
[2022-08-11 21:36:31] - INFO: ### problem_type = None
[2022-08-11 21:36:31] - INFO: ### _name_or_path = 
[2022-08-11 21:36:31] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:36:31] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:36:31] - INFO: ### model_type = bert
[2022-08-11 21:36:31] - INFO: ### vocab_size = 30522
[2022-08-11 21:36:31] - INFO: ### hidden_size = 768
[2022-08-11 21:36:31] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:36:31] - INFO: ### num_attention_heads = 12
[2022-08-11 21:36:31] - INFO: ### hidden_act = gelu
[2022-08-11 21:36:31] - INFO: ### intermediate_size = 3072
[2022-08-11 21:36:31] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:36:31] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:36:31] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:36:31] - INFO: ### type_vocab_size = 2
[2022-08-11 21:36:31] - INFO: ### initializer_range = 0.02
[2022-08-11 21:36:31] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:36:31] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:36:31] - INFO: ### use_cache = True
[2022-08-11 21:36:31] - INFO: ### classifier_dropout = None
[2022-08-11 21:40:58] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:40:58] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:40:58] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:40:58] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:40:58] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:40:58] - INFO: ### device = cpu
[2022-08-11 21:40:58] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:40:58] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:40:58] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:40:58] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:40:58] - INFO: ### batch_size = 10
[2022-08-11 21:40:58] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:40:58] - INFO: ### epochs = 5
[2022-08-11 21:40:58] - INFO: ### nums_labels = 5
[2022-08-11 21:40:58] - INFO: ### return_dict = True
[2022-08-11 21:40:58] - INFO: ### output_hidden_states = False
[2022-08-11 21:40:58] - INFO: ### output_attentions = False
[2022-08-11 21:40:58] - INFO: ### torchscript = False
[2022-08-11 21:40:58] - INFO: ### torch_dtype = None
[2022-08-11 21:40:58] - INFO: ### use_bfloat16 = False
[2022-08-11 21:40:58] - INFO: ### pruned_heads = {}
[2022-08-11 21:40:58] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:40:58] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:40:58] - INFO: ### is_decoder = False
[2022-08-11 21:40:58] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:40:58] - INFO: ### add_cross_attention = False
[2022-08-11 21:40:58] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:40:58] - INFO: ### max_length = 20
[2022-08-11 21:40:58] - INFO: ### min_length = 0
[2022-08-11 21:40:58] - INFO: ### do_sample = False
[2022-08-11 21:40:58] - INFO: ### early_stopping = False
[2022-08-11 21:40:58] - INFO: ### num_beams = 1
[2022-08-11 21:40:58] - INFO: ### num_beam_groups = 1
[2022-08-11 21:40:58] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:40:58] - INFO: ### temperature = 1.0
[2022-08-11 21:40:58] - INFO: ### top_k = 50
[2022-08-11 21:40:58] - INFO: ### top_p = 1.0
[2022-08-11 21:40:58] - INFO: ### typical_p = 1.0
[2022-08-11 21:40:58] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:40:58] - INFO: ### length_penalty = 1.0
[2022-08-11 21:40:58] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:40:58] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:40:58] - INFO: ### bad_words_ids = None
[2022-08-11 21:40:58] - INFO: ### num_return_sequences = 1
[2022-08-11 21:40:58] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:40:58] - INFO: ### output_scores = False
[2022-08-11 21:40:58] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:40:58] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:40:58] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:40:58] - INFO: ### remove_invalid_values = False
[2022-08-11 21:40:58] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:40:58] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:40:58] - INFO: ### finetuning_task = None
[2022-08-11 21:40:58] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:40:58] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:40:58] - INFO: ### tokenizer_class = None
[2022-08-11 21:40:58] - INFO: ### prefix = None
[2022-08-11 21:40:58] - INFO: ### bos_token_id = None
[2022-08-11 21:40:58] - INFO: ### pad_token_id = 0
[2022-08-11 21:40:58] - INFO: ### eos_token_id = None
[2022-08-11 21:40:58] - INFO: ### sep_token_id = None
[2022-08-11 21:40:58] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:40:58] - INFO: ### task_specific_params = None
[2022-08-11 21:40:58] - INFO: ### problem_type = None
[2022-08-11 21:40:58] - INFO: ### _name_or_path = 
[2022-08-11 21:40:58] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:40:58] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:40:58] - INFO: ### model_type = bert
[2022-08-11 21:40:58] - INFO: ### vocab_size = 30522
[2022-08-11 21:40:58] - INFO: ### hidden_size = 768
[2022-08-11 21:40:58] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:40:58] - INFO: ### num_attention_heads = 12
[2022-08-11 21:40:58] - INFO: ### hidden_act = gelu
[2022-08-11 21:40:58] - INFO: ### intermediate_size = 3072
[2022-08-11 21:40:58] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:40:58] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:40:58] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:40:58] - INFO: ### type_vocab_size = 2
[2022-08-11 21:40:58] - INFO: ### initializer_range = 0.02
[2022-08-11 21:40:58] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:40:58] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:40:58] - INFO: ### use_cache = True
[2022-08-11 21:40:58] - INFO: ### classifier_dropout = None
[2022-08-11 21:42:10] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:42:10] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:42:10] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:42:10] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:42:10] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:42:10] - INFO: ### device = cpu
[2022-08-11 21:42:10] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:42:10] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:42:10] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:42:10] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:42:10] - INFO: ### batch_size = 10
[2022-08-11 21:42:10] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:42:10] - INFO: ### epochs = 5
[2022-08-11 21:42:10] - INFO: ### nums_labels = 5
[2022-08-11 21:42:10] - INFO: ### return_dict = True
[2022-08-11 21:42:10] - INFO: ### output_hidden_states = False
[2022-08-11 21:42:10] - INFO: ### output_attentions = False
[2022-08-11 21:42:10] - INFO: ### torchscript = False
[2022-08-11 21:42:10] - INFO: ### torch_dtype = None
[2022-08-11 21:42:10] - INFO: ### use_bfloat16 = False
[2022-08-11 21:42:10] - INFO: ### pruned_heads = {}
[2022-08-11 21:42:10] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:42:10] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:42:10] - INFO: ### is_decoder = False
[2022-08-11 21:42:10] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:42:10] - INFO: ### add_cross_attention = False
[2022-08-11 21:42:10] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:42:10] - INFO: ### max_length = 20
[2022-08-11 21:42:10] - INFO: ### min_length = 0
[2022-08-11 21:42:10] - INFO: ### do_sample = False
[2022-08-11 21:42:10] - INFO: ### early_stopping = False
[2022-08-11 21:42:10] - INFO: ### num_beams = 1
[2022-08-11 21:42:10] - INFO: ### num_beam_groups = 1
[2022-08-11 21:42:10] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:42:10] - INFO: ### temperature = 1.0
[2022-08-11 21:42:10] - INFO: ### top_k = 50
[2022-08-11 21:42:10] - INFO: ### top_p = 1.0
[2022-08-11 21:42:10] - INFO: ### typical_p = 1.0
[2022-08-11 21:42:10] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:42:10] - INFO: ### length_penalty = 1.0
[2022-08-11 21:42:10] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:42:10] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:42:10] - INFO: ### bad_words_ids = None
[2022-08-11 21:42:10] - INFO: ### num_return_sequences = 1
[2022-08-11 21:42:10] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:42:10] - INFO: ### output_scores = False
[2022-08-11 21:42:10] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:42:10] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:42:10] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:42:10] - INFO: ### remove_invalid_values = False
[2022-08-11 21:42:10] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:42:10] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:42:10] - INFO: ### finetuning_task = None
[2022-08-11 21:42:10] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:42:10] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:42:10] - INFO: ### tokenizer_class = None
[2022-08-11 21:42:10] - INFO: ### prefix = None
[2022-08-11 21:42:10] - INFO: ### bos_token_id = None
[2022-08-11 21:42:10] - INFO: ### pad_token_id = 0
[2022-08-11 21:42:10] - INFO: ### eos_token_id = None
[2022-08-11 21:42:10] - INFO: ### sep_token_id = None
[2022-08-11 21:42:10] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:42:10] - INFO: ### task_specific_params = None
[2022-08-11 21:42:10] - INFO: ### problem_type = None
[2022-08-11 21:42:10] - INFO: ### _name_or_path = 
[2022-08-11 21:42:10] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:42:10] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:42:10] - INFO: ### model_type = bert
[2022-08-11 21:42:10] - INFO: ### vocab_size = 30522
[2022-08-11 21:42:10] - INFO: ### hidden_size = 768
[2022-08-11 21:42:10] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:42:10] - INFO: ### num_attention_heads = 12
[2022-08-11 21:42:10] - INFO: ### hidden_act = gelu
[2022-08-11 21:42:10] - INFO: ### intermediate_size = 3072
[2022-08-11 21:42:10] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:42:10] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:42:10] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:42:10] - INFO: ### type_vocab_size = 2
[2022-08-11 21:42:10] - INFO: ### initializer_range = 0.02
[2022-08-11 21:42:10] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:42:10] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:42:10] - INFO: ### use_cache = True
[2022-08-11 21:42:10] - INFO: ### classifier_dropout = None
[2022-08-11 21:44:08] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:44:08] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:44:08] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:44:08] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:44:08] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:44:08] - INFO: ### device = cpu
[2022-08-11 21:44:08] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:44:08] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:44:08] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:44:08] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:44:08] - INFO: ### batch_size = 10
[2022-08-11 21:44:08] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:44:08] - INFO: ### epochs = 5
[2022-08-11 21:44:08] - INFO: ### nums_labels = 5
[2022-08-11 21:44:08] - INFO: ### return_dict = True
[2022-08-11 21:44:08] - INFO: ### output_hidden_states = False
[2022-08-11 21:44:08] - INFO: ### output_attentions = False
[2022-08-11 21:44:08] - INFO: ### torchscript = False
[2022-08-11 21:44:08] - INFO: ### torch_dtype = None
[2022-08-11 21:44:08] - INFO: ### use_bfloat16 = False
[2022-08-11 21:44:08] - INFO: ### pruned_heads = {}
[2022-08-11 21:44:08] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:44:08] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:44:08] - INFO: ### is_decoder = False
[2022-08-11 21:44:08] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:44:08] - INFO: ### add_cross_attention = False
[2022-08-11 21:44:08] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:44:08] - INFO: ### max_length = 20
[2022-08-11 21:44:08] - INFO: ### min_length = 0
[2022-08-11 21:44:08] - INFO: ### do_sample = False
[2022-08-11 21:44:08] - INFO: ### early_stopping = False
[2022-08-11 21:44:08] - INFO: ### num_beams = 1
[2022-08-11 21:44:08] - INFO: ### num_beam_groups = 1
[2022-08-11 21:44:08] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:44:08] - INFO: ### temperature = 1.0
[2022-08-11 21:44:08] - INFO: ### top_k = 50
[2022-08-11 21:44:08] - INFO: ### top_p = 1.0
[2022-08-11 21:44:08] - INFO: ### typical_p = 1.0
[2022-08-11 21:44:08] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:44:08] - INFO: ### length_penalty = 1.0
[2022-08-11 21:44:08] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:44:08] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:44:08] - INFO: ### bad_words_ids = None
[2022-08-11 21:44:08] - INFO: ### num_return_sequences = 1
[2022-08-11 21:44:08] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:44:08] - INFO: ### output_scores = False
[2022-08-11 21:44:08] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:44:08] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:44:08] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:44:08] - INFO: ### remove_invalid_values = False
[2022-08-11 21:44:08] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:44:08] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:44:08] - INFO: ### finetuning_task = None
[2022-08-11 21:44:08] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:44:08] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:44:08] - INFO: ### tokenizer_class = None
[2022-08-11 21:44:08] - INFO: ### prefix = None
[2022-08-11 21:44:08] - INFO: ### bos_token_id = None
[2022-08-11 21:44:08] - INFO: ### pad_token_id = 0
[2022-08-11 21:44:08] - INFO: ### eos_token_id = None
[2022-08-11 21:44:08] - INFO: ### sep_token_id = None
[2022-08-11 21:44:08] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:44:08] - INFO: ### task_specific_params = None
[2022-08-11 21:44:08] - INFO: ### problem_type = None
[2022-08-11 21:44:08] - INFO: ### _name_or_path = 
[2022-08-11 21:44:08] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:44:08] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:44:08] - INFO: ### model_type = bert
[2022-08-11 21:44:08] - INFO: ### vocab_size = 30522
[2022-08-11 21:44:08] - INFO: ### hidden_size = 768
[2022-08-11 21:44:08] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:44:08] - INFO: ### num_attention_heads = 12
[2022-08-11 21:44:08] - INFO: ### hidden_act = gelu
[2022-08-11 21:44:08] - INFO: ### intermediate_size = 3072
[2022-08-11 21:44:08] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:44:08] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:44:08] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:44:08] - INFO: ### type_vocab_size = 2
[2022-08-11 21:44:08] - INFO: ### initializer_range = 0.02
[2022-08-11 21:44:08] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:44:08] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:44:08] - INFO: ### use_cache = True
[2022-08-11 21:44:08] - INFO: ### classifier_dropout = None
[2022-08-11 21:44:32] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:44:32] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:44:32] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:44:32] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:44:32] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:44:32] - INFO: ### device = cpu
[2022-08-11 21:44:32] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:44:32] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:44:32] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:44:32] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:44:32] - INFO: ### batch_size = 10
[2022-08-11 21:44:32] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:44:32] - INFO: ### epochs = 5
[2022-08-11 21:44:32] - INFO: ### nums_labels = 5
[2022-08-11 21:44:32] - INFO: ### return_dict = True
[2022-08-11 21:44:32] - INFO: ### output_hidden_states = False
[2022-08-11 21:44:32] - INFO: ### output_attentions = False
[2022-08-11 21:44:32] - INFO: ### torchscript = False
[2022-08-11 21:44:32] - INFO: ### torch_dtype = None
[2022-08-11 21:44:32] - INFO: ### use_bfloat16 = False
[2022-08-11 21:44:32] - INFO: ### pruned_heads = {}
[2022-08-11 21:44:32] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:44:32] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:44:32] - INFO: ### is_decoder = False
[2022-08-11 21:44:32] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:44:32] - INFO: ### add_cross_attention = False
[2022-08-11 21:44:32] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:44:32] - INFO: ### max_length = 20
[2022-08-11 21:44:32] - INFO: ### min_length = 0
[2022-08-11 21:44:32] - INFO: ### do_sample = False
[2022-08-11 21:44:32] - INFO: ### early_stopping = False
[2022-08-11 21:44:32] - INFO: ### num_beams = 1
[2022-08-11 21:44:32] - INFO: ### num_beam_groups = 1
[2022-08-11 21:44:32] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:44:32] - INFO: ### temperature = 1.0
[2022-08-11 21:44:32] - INFO: ### top_k = 50
[2022-08-11 21:44:32] - INFO: ### top_p = 1.0
[2022-08-11 21:44:32] - INFO: ### typical_p = 1.0
[2022-08-11 21:44:32] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:44:32] - INFO: ### length_penalty = 1.0
[2022-08-11 21:44:32] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:44:32] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:44:32] - INFO: ### bad_words_ids = None
[2022-08-11 21:44:32] - INFO: ### num_return_sequences = 1
[2022-08-11 21:44:32] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:44:32] - INFO: ### output_scores = False
[2022-08-11 21:44:32] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:44:32] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:44:32] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:44:32] - INFO: ### remove_invalid_values = False
[2022-08-11 21:44:32] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:44:32] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:44:32] - INFO: ### finetuning_task = None
[2022-08-11 21:44:32] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:44:32] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:44:32] - INFO: ### tokenizer_class = None
[2022-08-11 21:44:32] - INFO: ### prefix = None
[2022-08-11 21:44:32] - INFO: ### bos_token_id = None
[2022-08-11 21:44:32] - INFO: ### pad_token_id = 0
[2022-08-11 21:44:32] - INFO: ### eos_token_id = None
[2022-08-11 21:44:32] - INFO: ### sep_token_id = None
[2022-08-11 21:44:32] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:44:32] - INFO: ### task_specific_params = None
[2022-08-11 21:44:32] - INFO: ### problem_type = None
[2022-08-11 21:44:32] - INFO: ### _name_or_path = 
[2022-08-11 21:44:32] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:44:32] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:44:32] - INFO: ### model_type = bert
[2022-08-11 21:44:32] - INFO: ### vocab_size = 30522
[2022-08-11 21:44:32] - INFO: ### hidden_size = 768
[2022-08-11 21:44:32] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:44:32] - INFO: ### num_attention_heads = 12
[2022-08-11 21:44:32] - INFO: ### hidden_act = gelu
[2022-08-11 21:44:32] - INFO: ### intermediate_size = 3072
[2022-08-11 21:44:32] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:44:32] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:44:32] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:44:32] - INFO: ### type_vocab_size = 2
[2022-08-11 21:44:32] - INFO: ### initializer_range = 0.02
[2022-08-11 21:44:32] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:44:32] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:44:32] - INFO: ### use_cache = True
[2022-08-11 21:44:32] - INFO: ### classifier_dropout = None
[2022-08-11 21:44:52] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:44:52] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:44:52] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:44:52] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:44:52] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:44:52] - INFO: ### device = cpu
[2022-08-11 21:44:52] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:44:52] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:44:52] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:44:52] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:44:52] - INFO: ### batch_size = 10
[2022-08-11 21:44:52] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:44:52] - INFO: ### epochs = 5
[2022-08-11 21:44:52] - INFO: ### nums_labels = 5
[2022-08-11 21:44:52] - INFO: ### return_dict = True
[2022-08-11 21:44:52] - INFO: ### output_hidden_states = False
[2022-08-11 21:44:52] - INFO: ### output_attentions = False
[2022-08-11 21:44:52] - INFO: ### torchscript = False
[2022-08-11 21:44:52] - INFO: ### torch_dtype = None
[2022-08-11 21:44:52] - INFO: ### use_bfloat16 = False
[2022-08-11 21:44:52] - INFO: ### pruned_heads = {}
[2022-08-11 21:44:52] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:44:52] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:44:52] - INFO: ### is_decoder = False
[2022-08-11 21:44:52] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:44:52] - INFO: ### add_cross_attention = False
[2022-08-11 21:44:52] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:44:52] - INFO: ### max_length = 20
[2022-08-11 21:44:52] - INFO: ### min_length = 0
[2022-08-11 21:44:52] - INFO: ### do_sample = False
[2022-08-11 21:44:52] - INFO: ### early_stopping = False
[2022-08-11 21:44:52] - INFO: ### num_beams = 1
[2022-08-11 21:44:52] - INFO: ### num_beam_groups = 1
[2022-08-11 21:44:52] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:44:52] - INFO: ### temperature = 1.0
[2022-08-11 21:44:52] - INFO: ### top_k = 50
[2022-08-11 21:44:52] - INFO: ### top_p = 1.0
[2022-08-11 21:44:52] - INFO: ### typical_p = 1.0
[2022-08-11 21:44:52] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:44:52] - INFO: ### length_penalty = 1.0
[2022-08-11 21:44:52] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:44:52] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:44:52] - INFO: ### bad_words_ids = None
[2022-08-11 21:44:52] - INFO: ### num_return_sequences = 1
[2022-08-11 21:44:52] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:44:52] - INFO: ### output_scores = False
[2022-08-11 21:44:52] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:44:52] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:44:52] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:44:52] - INFO: ### remove_invalid_values = False
[2022-08-11 21:44:52] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:44:52] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:44:52] - INFO: ### finetuning_task = None
[2022-08-11 21:44:52] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:44:52] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:44:52] - INFO: ### tokenizer_class = None
[2022-08-11 21:44:52] - INFO: ### prefix = None
[2022-08-11 21:44:52] - INFO: ### bos_token_id = None
[2022-08-11 21:44:52] - INFO: ### pad_token_id = 0
[2022-08-11 21:44:52] - INFO: ### eos_token_id = None
[2022-08-11 21:44:52] - INFO: ### sep_token_id = None
[2022-08-11 21:44:52] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:44:52] - INFO: ### task_specific_params = None
[2022-08-11 21:44:52] - INFO: ### problem_type = None
[2022-08-11 21:44:52] - INFO: ### _name_or_path = 
[2022-08-11 21:44:52] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:44:52] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:44:52] - INFO: ### model_type = bert
[2022-08-11 21:44:52] - INFO: ### vocab_size = 30522
[2022-08-11 21:44:52] - INFO: ### hidden_size = 768
[2022-08-11 21:44:52] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:44:52] - INFO: ### num_attention_heads = 12
[2022-08-11 21:44:52] - INFO: ### hidden_act = gelu
[2022-08-11 21:44:52] - INFO: ### intermediate_size = 3072
[2022-08-11 21:44:52] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:44:52] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:44:52] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:44:52] - INFO: ### type_vocab_size = 2
[2022-08-11 21:44:52] - INFO: ### initializer_range = 0.02
[2022-08-11 21:44:52] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:44:52] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:44:52] - INFO: ### use_cache = True
[2022-08-11 21:44:52] - INFO: ### classifier_dropout = None
[2022-08-11 21:45:11] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:45:11] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:45:11] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:45:11] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:45:11] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:45:11] - INFO: ### device = cpu
[2022-08-11 21:45:11] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:45:11] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:45:11] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:45:11] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:45:11] - INFO: ### batch_size = 10
[2022-08-11 21:45:11] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:45:11] - INFO: ### epochs = 5
[2022-08-11 21:45:11] - INFO: ### nums_labels = 5
[2022-08-11 21:45:11] - INFO: ### return_dict = True
[2022-08-11 21:45:11] - INFO: ### output_hidden_states = False
[2022-08-11 21:45:11] - INFO: ### output_attentions = False
[2022-08-11 21:45:11] - INFO: ### torchscript = False
[2022-08-11 21:45:11] - INFO: ### torch_dtype = None
[2022-08-11 21:45:11] - INFO: ### use_bfloat16 = False
[2022-08-11 21:45:11] - INFO: ### pruned_heads = {}
[2022-08-11 21:45:11] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:45:11] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:45:11] - INFO: ### is_decoder = False
[2022-08-11 21:45:11] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:45:11] - INFO: ### add_cross_attention = False
[2022-08-11 21:45:11] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:45:11] - INFO: ### max_length = 20
[2022-08-11 21:45:11] - INFO: ### min_length = 0
[2022-08-11 21:45:11] - INFO: ### do_sample = False
[2022-08-11 21:45:11] - INFO: ### early_stopping = False
[2022-08-11 21:45:11] - INFO: ### num_beams = 1
[2022-08-11 21:45:11] - INFO: ### num_beam_groups = 1
[2022-08-11 21:45:11] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:45:11] - INFO: ### temperature = 1.0
[2022-08-11 21:45:11] - INFO: ### top_k = 50
[2022-08-11 21:45:11] - INFO: ### top_p = 1.0
[2022-08-11 21:45:11] - INFO: ### typical_p = 1.0
[2022-08-11 21:45:11] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:45:11] - INFO: ### length_penalty = 1.0
[2022-08-11 21:45:11] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:45:11] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:45:11] - INFO: ### bad_words_ids = None
[2022-08-11 21:45:11] - INFO: ### num_return_sequences = 1
[2022-08-11 21:45:11] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:45:11] - INFO: ### output_scores = False
[2022-08-11 21:45:11] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:45:11] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:45:11] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:45:11] - INFO: ### remove_invalid_values = False
[2022-08-11 21:45:11] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:45:11] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:45:11] - INFO: ### finetuning_task = None
[2022-08-11 21:45:11] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:45:11] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:45:11] - INFO: ### tokenizer_class = None
[2022-08-11 21:45:11] - INFO: ### prefix = None
[2022-08-11 21:45:11] - INFO: ### bos_token_id = None
[2022-08-11 21:45:11] - INFO: ### pad_token_id = 0
[2022-08-11 21:45:11] - INFO: ### eos_token_id = None
[2022-08-11 21:45:11] - INFO: ### sep_token_id = None
[2022-08-11 21:45:11] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:45:11] - INFO: ### task_specific_params = None
[2022-08-11 21:45:11] - INFO: ### problem_type = None
[2022-08-11 21:45:11] - INFO: ### _name_or_path = 
[2022-08-11 21:45:11] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:45:11] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:45:11] - INFO: ### model_type = bert
[2022-08-11 21:45:11] - INFO: ### vocab_size = 30522
[2022-08-11 21:45:11] - INFO: ### hidden_size = 768
[2022-08-11 21:45:11] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:45:11] - INFO: ### num_attention_heads = 12
[2022-08-11 21:45:11] - INFO: ### hidden_act = gelu
[2022-08-11 21:45:11] - INFO: ### intermediate_size = 3072
[2022-08-11 21:45:11] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:45:11] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:45:11] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:45:11] - INFO: ### type_vocab_size = 2
[2022-08-11 21:45:11] - INFO: ### initializer_range = 0.02
[2022-08-11 21:45:11] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:45:11] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:45:11] - INFO: ### use_cache = True
[2022-08-11 21:45:11] - INFO: ### classifier_dropout = None
[2022-08-11 21:48:52] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:48:52] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:48:52] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:48:52] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:48:52] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:48:52] - INFO: ### device = cpu
[2022-08-11 21:48:52] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:48:52] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:48:52] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:48:52] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:48:52] - INFO: ### batch_size = 10
[2022-08-11 21:48:52] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:48:52] - INFO: ### epochs = 5
[2022-08-11 21:48:52] - INFO: ### nums_labels = 5
[2022-08-11 21:48:52] - INFO: ### return_dict = True
[2022-08-11 21:48:52] - INFO: ### output_hidden_states = False
[2022-08-11 21:48:52] - INFO: ### output_attentions = False
[2022-08-11 21:48:52] - INFO: ### torchscript = False
[2022-08-11 21:48:52] - INFO: ### torch_dtype = None
[2022-08-11 21:48:52] - INFO: ### use_bfloat16 = False
[2022-08-11 21:48:52] - INFO: ### pruned_heads = {}
[2022-08-11 21:48:52] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:48:52] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:48:52] - INFO: ### is_decoder = False
[2022-08-11 21:48:52] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:48:52] - INFO: ### add_cross_attention = False
[2022-08-11 21:48:52] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:48:52] - INFO: ### max_length = 20
[2022-08-11 21:48:52] - INFO: ### min_length = 0
[2022-08-11 21:48:52] - INFO: ### do_sample = False
[2022-08-11 21:48:52] - INFO: ### early_stopping = False
[2022-08-11 21:48:52] - INFO: ### num_beams = 1
[2022-08-11 21:48:52] - INFO: ### num_beam_groups = 1
[2022-08-11 21:48:52] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:48:52] - INFO: ### temperature = 1.0
[2022-08-11 21:48:52] - INFO: ### top_k = 50
[2022-08-11 21:48:52] - INFO: ### top_p = 1.0
[2022-08-11 21:48:52] - INFO: ### typical_p = 1.0
[2022-08-11 21:48:52] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:48:52] - INFO: ### length_penalty = 1.0
[2022-08-11 21:48:52] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:48:52] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:48:52] - INFO: ### bad_words_ids = None
[2022-08-11 21:48:52] - INFO: ### num_return_sequences = 1
[2022-08-11 21:48:52] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:48:52] - INFO: ### output_scores = False
[2022-08-11 21:48:52] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:48:52] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:48:52] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:48:52] - INFO: ### remove_invalid_values = False
[2022-08-11 21:48:52] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:48:52] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:48:52] - INFO: ### finetuning_task = None
[2022-08-11 21:48:52] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:48:52] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:48:52] - INFO: ### tokenizer_class = None
[2022-08-11 21:48:52] - INFO: ### prefix = None
[2022-08-11 21:48:52] - INFO: ### bos_token_id = None
[2022-08-11 21:48:52] - INFO: ### pad_token_id = 0
[2022-08-11 21:48:52] - INFO: ### eos_token_id = None
[2022-08-11 21:48:52] - INFO: ### sep_token_id = None
[2022-08-11 21:48:52] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:48:52] - INFO: ### task_specific_params = None
[2022-08-11 21:48:52] - INFO: ### problem_type = None
[2022-08-11 21:48:52] - INFO: ### _name_or_path = 
[2022-08-11 21:48:52] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:48:52] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:48:52] - INFO: ### model_type = bert
[2022-08-11 21:48:52] - INFO: ### vocab_size = 30522
[2022-08-11 21:48:52] - INFO: ### hidden_size = 768
[2022-08-11 21:48:52] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:48:52] - INFO: ### num_attention_heads = 12
[2022-08-11 21:48:52] - INFO: ### hidden_act = gelu
[2022-08-11 21:48:52] - INFO: ### intermediate_size = 3072
[2022-08-11 21:48:52] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:48:52] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:48:52] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:48:52] - INFO: ### type_vocab_size = 2
[2022-08-11 21:48:52] - INFO: ### initializer_range = 0.02
[2022-08-11 21:48:52] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:48:52] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:48:52] - INFO: ### use_cache = True
[2022-08-11 21:48:52] - INFO: ### classifier_dropout = None
[2022-08-11 21:49:20] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:49:20] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:49:20] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:49:20] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:49:20] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:49:20] - INFO: ### device = cpu
[2022-08-11 21:49:20] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:49:20] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:49:20] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:49:20] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:49:20] - INFO: ### batch_size = 10
[2022-08-11 21:49:20] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:49:20] - INFO: ### epochs = 5
[2022-08-11 21:49:20] - INFO: ### nums_labels = 5
[2022-08-11 21:49:20] - INFO: ### return_dict = True
[2022-08-11 21:49:20] - INFO: ### output_hidden_states = False
[2022-08-11 21:49:20] - INFO: ### output_attentions = False
[2022-08-11 21:49:20] - INFO: ### torchscript = False
[2022-08-11 21:49:20] - INFO: ### torch_dtype = None
[2022-08-11 21:49:20] - INFO: ### use_bfloat16 = False
[2022-08-11 21:49:20] - INFO: ### pruned_heads = {}
[2022-08-11 21:49:20] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:49:20] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:49:20] - INFO: ### is_decoder = False
[2022-08-11 21:49:20] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:49:20] - INFO: ### add_cross_attention = False
[2022-08-11 21:49:20] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:49:20] - INFO: ### max_length = 20
[2022-08-11 21:49:20] - INFO: ### min_length = 0
[2022-08-11 21:49:20] - INFO: ### do_sample = False
[2022-08-11 21:49:20] - INFO: ### early_stopping = False
[2022-08-11 21:49:20] - INFO: ### num_beams = 1
[2022-08-11 21:49:20] - INFO: ### num_beam_groups = 1
[2022-08-11 21:49:20] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:49:20] - INFO: ### temperature = 1.0
[2022-08-11 21:49:20] - INFO: ### top_k = 50
[2022-08-11 21:49:20] - INFO: ### top_p = 1.0
[2022-08-11 21:49:20] - INFO: ### typical_p = 1.0
[2022-08-11 21:49:20] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:49:20] - INFO: ### length_penalty = 1.0
[2022-08-11 21:49:20] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:49:20] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:49:20] - INFO: ### bad_words_ids = None
[2022-08-11 21:49:20] - INFO: ### num_return_sequences = 1
[2022-08-11 21:49:20] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:49:20] - INFO: ### output_scores = False
[2022-08-11 21:49:20] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:49:20] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:49:20] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:49:20] - INFO: ### remove_invalid_values = False
[2022-08-11 21:49:20] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:49:20] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:49:20] - INFO: ### finetuning_task = None
[2022-08-11 21:49:20] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:49:20] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:49:20] - INFO: ### tokenizer_class = None
[2022-08-11 21:49:20] - INFO: ### prefix = None
[2022-08-11 21:49:20] - INFO: ### bos_token_id = None
[2022-08-11 21:49:20] - INFO: ### pad_token_id = 0
[2022-08-11 21:49:20] - INFO: ### eos_token_id = None
[2022-08-11 21:49:20] - INFO: ### sep_token_id = None
[2022-08-11 21:49:20] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:49:20] - INFO: ### task_specific_params = None
[2022-08-11 21:49:20] - INFO: ### problem_type = None
[2022-08-11 21:49:20] - INFO: ### _name_or_path = 
[2022-08-11 21:49:20] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:49:20] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:49:20] - INFO: ### model_type = bert
[2022-08-11 21:49:20] - INFO: ### vocab_size = 30522
[2022-08-11 21:49:20] - INFO: ### hidden_size = 768
[2022-08-11 21:49:20] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:49:20] - INFO: ### num_attention_heads = 12
[2022-08-11 21:49:20] - INFO: ### hidden_act = gelu
[2022-08-11 21:49:20] - INFO: ### intermediate_size = 3072
[2022-08-11 21:49:20] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:49:20] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:49:20] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:49:20] - INFO: ### type_vocab_size = 2
[2022-08-11 21:49:20] - INFO: ### initializer_range = 0.02
[2022-08-11 21:49:20] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:49:20] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:49:20] - INFO: ### use_cache = True
[2022-08-11 21:49:20] - INFO: ### classifier_dropout = None
[2022-08-11 21:54:30] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:54:30] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:54:30] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:54:30] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:54:30] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:54:30] - INFO: ### device = cpu
[2022-08-11 21:54:30] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:54:30] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:54:30] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:54:30] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:54:30] - INFO: ### batch_size = 10
[2022-08-11 21:54:30] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:54:30] - INFO: ### epochs = 5
[2022-08-11 21:54:30] - INFO: ### nums_labels = 5
[2022-08-11 21:54:30] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:54:30] - INFO: ### return_dict = True
[2022-08-11 21:54:30] - INFO: ### output_hidden_states = False
[2022-08-11 21:54:30] - INFO: ### output_attentions = False
[2022-08-11 21:54:30] - INFO: ### torchscript = False
[2022-08-11 21:54:30] - INFO: ### torch_dtype = None
[2022-08-11 21:54:30] - INFO: ### use_bfloat16 = False
[2022-08-11 21:54:30] - INFO: ### pruned_heads = {}
[2022-08-11 21:54:30] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:54:30] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:54:30] - INFO: ### is_decoder = False
[2022-08-11 21:54:30] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:54:30] - INFO: ### add_cross_attention = False
[2022-08-11 21:54:30] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:54:30] - INFO: ### max_length = 20
[2022-08-11 21:54:30] - INFO: ### min_length = 0
[2022-08-11 21:54:30] - INFO: ### do_sample = False
[2022-08-11 21:54:30] - INFO: ### early_stopping = False
[2022-08-11 21:54:30] - INFO: ### num_beams = 1
[2022-08-11 21:54:30] - INFO: ### num_beam_groups = 1
[2022-08-11 21:54:30] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:54:30] - INFO: ### temperature = 1.0
[2022-08-11 21:54:30] - INFO: ### top_k = 50
[2022-08-11 21:54:30] - INFO: ### top_p = 1.0
[2022-08-11 21:54:30] - INFO: ### typical_p = 1.0
[2022-08-11 21:54:30] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:54:30] - INFO: ### length_penalty = 1.0
[2022-08-11 21:54:30] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:54:30] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:54:30] - INFO: ### bad_words_ids = None
[2022-08-11 21:54:30] - INFO: ### num_return_sequences = 1
[2022-08-11 21:54:30] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:54:30] - INFO: ### output_scores = False
[2022-08-11 21:54:30] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:54:30] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:54:30] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:54:30] - INFO: ### remove_invalid_values = False
[2022-08-11 21:54:30] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:54:30] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:54:30] - INFO: ### finetuning_task = None
[2022-08-11 21:54:30] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:54:30] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:54:30] - INFO: ### tokenizer_class = None
[2022-08-11 21:54:30] - INFO: ### prefix = None
[2022-08-11 21:54:30] - INFO: ### bos_token_id = None
[2022-08-11 21:54:30] - INFO: ### pad_token_id = 0
[2022-08-11 21:54:30] - INFO: ### eos_token_id = None
[2022-08-11 21:54:30] - INFO: ### sep_token_id = None
[2022-08-11 21:54:30] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:54:30] - INFO: ### task_specific_params = None
[2022-08-11 21:54:30] - INFO: ### problem_type = None
[2022-08-11 21:54:30] - INFO: ### _name_or_path = 
[2022-08-11 21:54:30] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:54:30] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:54:30] - INFO: ### model_type = bert
[2022-08-11 21:54:30] - INFO: ### vocab_size = 30522
[2022-08-11 21:54:30] - INFO: ### hidden_size = 768
[2022-08-11 21:54:30] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:54:30] - INFO: ### num_attention_heads = 12
[2022-08-11 21:54:30] - INFO: ### hidden_act = gelu
[2022-08-11 21:54:30] - INFO: ### intermediate_size = 3072
[2022-08-11 21:54:30] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:54:30] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:54:30] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:54:30] - INFO: ### type_vocab_size = 2
[2022-08-11 21:54:30] - INFO: ### initializer_range = 0.02
[2022-08-11 21:54:30] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:54:30] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:54:30] - INFO: ### use_cache = True
[2022-08-11 21:54:30] - INFO: ### classifier_dropout = None
[2022-08-11 21:55:29] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:55:29] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:55:29] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:55:29] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:55:29] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:55:29] - INFO: ### device = cpu
[2022-08-11 21:55:29] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:55:29] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:55:29] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:55:29] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:55:29] - INFO: ### batch_size = 10
[2022-08-11 21:55:29] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:55:29] - INFO: ### epochs = 5
[2022-08-11 21:55:29] - INFO: ### nums_labels = 5
[2022-08-11 21:55:29] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:55:29] - INFO: ### return_dict = True
[2022-08-11 21:55:29] - INFO: ### output_hidden_states = False
[2022-08-11 21:55:29] - INFO: ### output_attentions = False
[2022-08-11 21:55:29] - INFO: ### torchscript = False
[2022-08-11 21:55:29] - INFO: ### torch_dtype = None
[2022-08-11 21:55:29] - INFO: ### use_bfloat16 = False
[2022-08-11 21:55:29] - INFO: ### pruned_heads = {}
[2022-08-11 21:55:29] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:55:29] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:55:29] - INFO: ### is_decoder = False
[2022-08-11 21:55:29] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:55:29] - INFO: ### add_cross_attention = False
[2022-08-11 21:55:29] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:55:29] - INFO: ### max_length = 20
[2022-08-11 21:55:29] - INFO: ### min_length = 0
[2022-08-11 21:55:29] - INFO: ### do_sample = False
[2022-08-11 21:55:29] - INFO: ### early_stopping = False
[2022-08-11 21:55:29] - INFO: ### num_beams = 1
[2022-08-11 21:55:29] - INFO: ### num_beam_groups = 1
[2022-08-11 21:55:29] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:55:29] - INFO: ### temperature = 1.0
[2022-08-11 21:55:29] - INFO: ### top_k = 50
[2022-08-11 21:55:29] - INFO: ### top_p = 1.0
[2022-08-11 21:55:29] - INFO: ### typical_p = 1.0
[2022-08-11 21:55:29] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:55:29] - INFO: ### length_penalty = 1.0
[2022-08-11 21:55:29] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:55:29] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:55:29] - INFO: ### bad_words_ids = None
[2022-08-11 21:55:29] - INFO: ### num_return_sequences = 1
[2022-08-11 21:55:29] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:55:29] - INFO: ### output_scores = False
[2022-08-11 21:55:29] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:55:29] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:55:29] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:55:29] - INFO: ### remove_invalid_values = False
[2022-08-11 21:55:29] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:55:29] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:55:29] - INFO: ### finetuning_task = None
[2022-08-11 21:55:29] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:55:29] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:55:29] - INFO: ### tokenizer_class = None
[2022-08-11 21:55:29] - INFO: ### prefix = None
[2022-08-11 21:55:29] - INFO: ### bos_token_id = None
[2022-08-11 21:55:29] - INFO: ### pad_token_id = 0
[2022-08-11 21:55:29] - INFO: ### eos_token_id = None
[2022-08-11 21:55:29] - INFO: ### sep_token_id = None
[2022-08-11 21:55:29] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:55:29] - INFO: ### task_specific_params = None
[2022-08-11 21:55:29] - INFO: ### problem_type = None
[2022-08-11 21:55:29] - INFO: ### _name_or_path = 
[2022-08-11 21:55:29] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:55:29] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:55:29] - INFO: ### model_type = bert
[2022-08-11 21:55:29] - INFO: ### vocab_size = 30522
[2022-08-11 21:55:29] - INFO: ### hidden_size = 768
[2022-08-11 21:55:29] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:55:29] - INFO: ### num_attention_heads = 12
[2022-08-11 21:55:29] - INFO: ### hidden_act = gelu
[2022-08-11 21:55:29] - INFO: ### intermediate_size = 3072
[2022-08-11 21:55:29] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:55:29] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:55:29] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:55:29] - INFO: ### type_vocab_size = 2
[2022-08-11 21:55:29] - INFO: ### initializer_range = 0.02
[2022-08-11 21:55:29] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:55:29] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:55:29] - INFO: ### use_cache = True
[2022-08-11 21:55:29] - INFO: ### classifier_dropout = None
[2022-08-11 21:56:20] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:56:20] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:56:20] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:56:20] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:56:20] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:56:20] - INFO: ### device = cpu
[2022-08-11 21:56:20] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:56:20] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:56:20] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:56:20] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:56:20] - INFO: ### batch_size = 10
[2022-08-11 21:56:20] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:56:20] - INFO: ### epochs = 5
[2022-08-11 21:56:20] - INFO: ### nums_labels = 5
[2022-08-11 21:56:20] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:56:20] - INFO: ### return_dict = True
[2022-08-11 21:56:20] - INFO: ### output_hidden_states = False
[2022-08-11 21:56:20] - INFO: ### output_attentions = False
[2022-08-11 21:56:20] - INFO: ### torchscript = False
[2022-08-11 21:56:20] - INFO: ### torch_dtype = None
[2022-08-11 21:56:20] - INFO: ### use_bfloat16 = False
[2022-08-11 21:56:20] - INFO: ### pruned_heads = {}
[2022-08-11 21:56:20] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:56:20] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:56:20] - INFO: ### is_decoder = False
[2022-08-11 21:56:20] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:56:20] - INFO: ### add_cross_attention = False
[2022-08-11 21:56:20] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:56:20] - INFO: ### max_length = 20
[2022-08-11 21:56:20] - INFO: ### min_length = 0
[2022-08-11 21:56:20] - INFO: ### do_sample = False
[2022-08-11 21:56:20] - INFO: ### early_stopping = False
[2022-08-11 21:56:20] - INFO: ### num_beams = 1
[2022-08-11 21:56:20] - INFO: ### num_beam_groups = 1
[2022-08-11 21:56:20] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:56:20] - INFO: ### temperature = 1.0
[2022-08-11 21:56:20] - INFO: ### top_k = 50
[2022-08-11 21:56:20] - INFO: ### top_p = 1.0
[2022-08-11 21:56:20] - INFO: ### typical_p = 1.0
[2022-08-11 21:56:20] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:56:20] - INFO: ### length_penalty = 1.0
[2022-08-11 21:56:20] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:56:20] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:56:20] - INFO: ### bad_words_ids = None
[2022-08-11 21:56:20] - INFO: ### num_return_sequences = 1
[2022-08-11 21:56:20] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:56:20] - INFO: ### output_scores = False
[2022-08-11 21:56:20] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:56:20] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:56:20] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:56:20] - INFO: ### remove_invalid_values = False
[2022-08-11 21:56:20] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:56:20] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:56:20] - INFO: ### finetuning_task = None
[2022-08-11 21:56:20] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:56:20] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:56:20] - INFO: ### tokenizer_class = None
[2022-08-11 21:56:20] - INFO: ### prefix = None
[2022-08-11 21:56:20] - INFO: ### bos_token_id = None
[2022-08-11 21:56:20] - INFO: ### pad_token_id = 0
[2022-08-11 21:56:20] - INFO: ### eos_token_id = None
[2022-08-11 21:56:20] - INFO: ### sep_token_id = None
[2022-08-11 21:56:20] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:56:20] - INFO: ### task_specific_params = None
[2022-08-11 21:56:20] - INFO: ### problem_type = None
[2022-08-11 21:56:20] - INFO: ### _name_or_path = 
[2022-08-11 21:56:20] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:56:20] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:56:20] - INFO: ### model_type = bert
[2022-08-11 21:56:20] - INFO: ### vocab_size = 30522
[2022-08-11 21:56:20] - INFO: ### hidden_size = 768
[2022-08-11 21:56:20] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:56:20] - INFO: ### num_attention_heads = 12
[2022-08-11 21:56:20] - INFO: ### hidden_act = gelu
[2022-08-11 21:56:20] - INFO: ### intermediate_size = 3072
[2022-08-11 21:56:20] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:56:20] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:56:20] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:56:20] - INFO: ### type_vocab_size = 2
[2022-08-11 21:56:20] - INFO: ### initializer_range = 0.02
[2022-08-11 21:56:20] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:56:20] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:56:20] - INFO: ### use_cache = True
[2022-08-11 21:56:20] - INFO: ### classifier_dropout = None
[2022-08-11 21:57:04] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:57:04] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:57:04] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:57:04] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:57:04] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:57:04] - INFO: ### device = cpu
[2022-08-11 21:57:04] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:57:04] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:57:04] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:57:04] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:57:04] - INFO: ### batch_size = 10
[2022-08-11 21:57:04] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:57:04] - INFO: ### epochs = 5
[2022-08-11 21:57:04] - INFO: ### nums_labels = 5
[2022-08-11 21:57:04] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:57:04] - INFO: ### return_dict = True
[2022-08-11 21:57:04] - INFO: ### output_hidden_states = False
[2022-08-11 21:57:04] - INFO: ### output_attentions = False
[2022-08-11 21:57:04] - INFO: ### torchscript = False
[2022-08-11 21:57:04] - INFO: ### torch_dtype = None
[2022-08-11 21:57:04] - INFO: ### use_bfloat16 = False
[2022-08-11 21:57:04] - INFO: ### pruned_heads = {}
[2022-08-11 21:57:04] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:57:04] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:57:04] - INFO: ### is_decoder = False
[2022-08-11 21:57:04] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:57:04] - INFO: ### add_cross_attention = False
[2022-08-11 21:57:04] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:57:04] - INFO: ### max_length = 20
[2022-08-11 21:57:04] - INFO: ### min_length = 0
[2022-08-11 21:57:04] - INFO: ### do_sample = False
[2022-08-11 21:57:04] - INFO: ### early_stopping = False
[2022-08-11 21:57:04] - INFO: ### num_beams = 1
[2022-08-11 21:57:04] - INFO: ### num_beam_groups = 1
[2022-08-11 21:57:04] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:57:04] - INFO: ### temperature = 1.0
[2022-08-11 21:57:04] - INFO: ### top_k = 50
[2022-08-11 21:57:04] - INFO: ### top_p = 1.0
[2022-08-11 21:57:04] - INFO: ### typical_p = 1.0
[2022-08-11 21:57:04] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:57:04] - INFO: ### length_penalty = 1.0
[2022-08-11 21:57:04] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:57:04] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:57:04] - INFO: ### bad_words_ids = None
[2022-08-11 21:57:04] - INFO: ### num_return_sequences = 1
[2022-08-11 21:57:04] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:57:04] - INFO: ### output_scores = False
[2022-08-11 21:57:04] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:57:04] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:57:04] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:57:04] - INFO: ### remove_invalid_values = False
[2022-08-11 21:57:04] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:57:04] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:57:04] - INFO: ### finetuning_task = None
[2022-08-11 21:57:04] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:57:04] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:57:04] - INFO: ### tokenizer_class = None
[2022-08-11 21:57:04] - INFO: ### prefix = None
[2022-08-11 21:57:04] - INFO: ### bos_token_id = None
[2022-08-11 21:57:04] - INFO: ### pad_token_id = 0
[2022-08-11 21:57:04] - INFO: ### eos_token_id = None
[2022-08-11 21:57:04] - INFO: ### sep_token_id = None
[2022-08-11 21:57:04] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:57:04] - INFO: ### task_specific_params = None
[2022-08-11 21:57:04] - INFO: ### problem_type = None
[2022-08-11 21:57:04] - INFO: ### _name_or_path = 
[2022-08-11 21:57:04] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:57:04] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:57:04] - INFO: ### model_type = bert
[2022-08-11 21:57:04] - INFO: ### vocab_size = 30522
[2022-08-11 21:57:04] - INFO: ### hidden_size = 768
[2022-08-11 21:57:04] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:57:04] - INFO: ### num_attention_heads = 12
[2022-08-11 21:57:04] - INFO: ### hidden_act = gelu
[2022-08-11 21:57:04] - INFO: ### intermediate_size = 3072
[2022-08-11 21:57:04] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:57:04] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:57:04] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:57:04] - INFO: ### type_vocab_size = 2
[2022-08-11 21:57:04] - INFO: ### initializer_range = 0.02
[2022-08-11 21:57:04] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:57:04] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:57:04] - INFO: ### use_cache = True
[2022-08-11 21:57:04] - INFO: ### classifier_dropout = None
[2022-08-11 21:57:36] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:57:36] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:57:36] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:57:36] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:57:36] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:57:36] - INFO: ### device = cpu
[2022-08-11 21:57:36] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:57:36] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:57:36] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:57:36] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:57:36] - INFO: ### batch_size = 10
[2022-08-11 21:57:36] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:57:36] - INFO: ### epochs = 5
[2022-08-11 21:57:36] - INFO: ### nums_labels = 5
[2022-08-11 21:57:36] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:57:36] - INFO: ### return_dict = True
[2022-08-11 21:57:36] - INFO: ### output_hidden_states = False
[2022-08-11 21:57:36] - INFO: ### output_attentions = False
[2022-08-11 21:57:36] - INFO: ### torchscript = False
[2022-08-11 21:57:36] - INFO: ### torch_dtype = None
[2022-08-11 21:57:36] - INFO: ### use_bfloat16 = False
[2022-08-11 21:57:36] - INFO: ### pruned_heads = {}
[2022-08-11 21:57:36] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:57:36] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:57:36] - INFO: ### is_decoder = False
[2022-08-11 21:57:36] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:57:36] - INFO: ### add_cross_attention = False
[2022-08-11 21:57:36] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:57:36] - INFO: ### max_length = 20
[2022-08-11 21:57:36] - INFO: ### min_length = 0
[2022-08-11 21:57:36] - INFO: ### do_sample = False
[2022-08-11 21:57:36] - INFO: ### early_stopping = False
[2022-08-11 21:57:36] - INFO: ### num_beams = 1
[2022-08-11 21:57:36] - INFO: ### num_beam_groups = 1
[2022-08-11 21:57:36] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:57:36] - INFO: ### temperature = 1.0
[2022-08-11 21:57:36] - INFO: ### top_k = 50
[2022-08-11 21:57:36] - INFO: ### top_p = 1.0
[2022-08-11 21:57:36] - INFO: ### typical_p = 1.0
[2022-08-11 21:57:36] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:57:36] - INFO: ### length_penalty = 1.0
[2022-08-11 21:57:36] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:57:36] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:57:36] - INFO: ### bad_words_ids = None
[2022-08-11 21:57:36] - INFO: ### num_return_sequences = 1
[2022-08-11 21:57:36] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:57:36] - INFO: ### output_scores = False
[2022-08-11 21:57:36] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:57:36] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:57:36] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:57:36] - INFO: ### remove_invalid_values = False
[2022-08-11 21:57:36] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:57:36] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:57:36] - INFO: ### finetuning_task = None
[2022-08-11 21:57:36] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:57:36] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:57:36] - INFO: ### tokenizer_class = None
[2022-08-11 21:57:36] - INFO: ### prefix = None
[2022-08-11 21:57:36] - INFO: ### bos_token_id = None
[2022-08-11 21:57:36] - INFO: ### pad_token_id = 0
[2022-08-11 21:57:36] - INFO: ### eos_token_id = None
[2022-08-11 21:57:36] - INFO: ### sep_token_id = None
[2022-08-11 21:57:36] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:57:36] - INFO: ### task_specific_params = None
[2022-08-11 21:57:36] - INFO: ### problem_type = None
[2022-08-11 21:57:36] - INFO: ### _name_or_path = 
[2022-08-11 21:57:36] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:57:36] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:57:36] - INFO: ### model_type = bert
[2022-08-11 21:57:36] - INFO: ### vocab_size = 30522
[2022-08-11 21:57:36] - INFO: ### hidden_size = 768
[2022-08-11 21:57:36] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:57:36] - INFO: ### num_attention_heads = 12
[2022-08-11 21:57:36] - INFO: ### hidden_act = gelu
[2022-08-11 21:57:36] - INFO: ### intermediate_size = 3072
[2022-08-11 21:57:36] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:57:36] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:57:36] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:57:36] - INFO: ### type_vocab_size = 2
[2022-08-11 21:57:36] - INFO: ### initializer_range = 0.02
[2022-08-11 21:57:36] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:57:36] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:57:36] - INFO: ### use_cache = True
[2022-08-11 21:57:36] - INFO: ### classifier_dropout = None
[2022-08-11 21:59:13] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:59:13] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:59:13] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:59:13] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:59:13] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:59:13] - INFO: ### device = cpu
[2022-08-11 21:59:13] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:59:13] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:59:13] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:59:13] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:59:13] - INFO: ### batch_size = 10
[2022-08-11 21:59:13] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:59:13] - INFO: ### epochs = 5
[2022-08-11 21:59:13] - INFO: ### nums_labels = 5
[2022-08-11 21:59:13] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:59:13] - INFO: ### return_dict = True
[2022-08-11 21:59:13] - INFO: ### output_hidden_states = False
[2022-08-11 21:59:13] - INFO: ### output_attentions = False
[2022-08-11 21:59:13] - INFO: ### torchscript = False
[2022-08-11 21:59:13] - INFO: ### torch_dtype = None
[2022-08-11 21:59:13] - INFO: ### use_bfloat16 = False
[2022-08-11 21:59:13] - INFO: ### pruned_heads = {}
[2022-08-11 21:59:13] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:59:13] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:59:13] - INFO: ### is_decoder = False
[2022-08-11 21:59:13] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:59:13] - INFO: ### add_cross_attention = False
[2022-08-11 21:59:13] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:59:13] - INFO: ### max_length = 20
[2022-08-11 21:59:13] - INFO: ### min_length = 0
[2022-08-11 21:59:13] - INFO: ### do_sample = False
[2022-08-11 21:59:13] - INFO: ### early_stopping = False
[2022-08-11 21:59:13] - INFO: ### num_beams = 1
[2022-08-11 21:59:13] - INFO: ### num_beam_groups = 1
[2022-08-11 21:59:13] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:59:13] - INFO: ### temperature = 1.0
[2022-08-11 21:59:13] - INFO: ### top_k = 50
[2022-08-11 21:59:13] - INFO: ### top_p = 1.0
[2022-08-11 21:59:13] - INFO: ### typical_p = 1.0
[2022-08-11 21:59:13] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:59:13] - INFO: ### length_penalty = 1.0
[2022-08-11 21:59:13] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:59:13] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:59:13] - INFO: ### bad_words_ids = None
[2022-08-11 21:59:13] - INFO: ### num_return_sequences = 1
[2022-08-11 21:59:13] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:59:13] - INFO: ### output_scores = False
[2022-08-11 21:59:13] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:59:13] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:59:13] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:59:13] - INFO: ### remove_invalid_values = False
[2022-08-11 21:59:13] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:59:13] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:59:13] - INFO: ### finetuning_task = None
[2022-08-11 21:59:13] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:59:13] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:59:13] - INFO: ### tokenizer_class = None
[2022-08-11 21:59:13] - INFO: ### prefix = None
[2022-08-11 21:59:13] - INFO: ### bos_token_id = None
[2022-08-11 21:59:13] - INFO: ### pad_token_id = 0
[2022-08-11 21:59:13] - INFO: ### eos_token_id = None
[2022-08-11 21:59:13] - INFO: ### sep_token_id = None
[2022-08-11 21:59:13] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:59:13] - INFO: ### task_specific_params = None
[2022-08-11 21:59:13] - INFO: ### problem_type = None
[2022-08-11 21:59:13] - INFO: ### _name_or_path = 
[2022-08-11 21:59:13] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:59:13] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:59:13] - INFO: ### model_type = bert
[2022-08-11 21:59:13] - INFO: ### vocab_size = 30522
[2022-08-11 21:59:13] - INFO: ### hidden_size = 768
[2022-08-11 21:59:13] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:59:13] - INFO: ### num_attention_heads = 12
[2022-08-11 21:59:13] - INFO: ### hidden_act = gelu
[2022-08-11 21:59:13] - INFO: ### intermediate_size = 3072
[2022-08-11 21:59:13] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:59:13] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:59:13] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:59:13] - INFO: ### type_vocab_size = 2
[2022-08-11 21:59:13] - INFO: ### initializer_range = 0.02
[2022-08-11 21:59:13] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:59:13] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:59:13] - INFO: ### use_cache = True
[2022-08-11 21:59:13] - INFO: ### classifier_dropout = None
[2022-08-11 21:59:20] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:59:20] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:59:20] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:59:20] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:59:20] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:59:20] - INFO: ### device = cpu
[2022-08-11 21:59:20] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:59:20] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:59:20] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:59:20] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:59:20] - INFO: ### batch_size = 10
[2022-08-11 21:59:20] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:59:20] - INFO: ### epochs = 5
[2022-08-11 21:59:20] - INFO: ### nums_labels = 5
[2022-08-11 21:59:20] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-11 21:59:20] - INFO: ### return_dict = True
[2022-08-11 21:59:20] - INFO: ### output_hidden_states = False
[2022-08-11 21:59:20] - INFO: ### output_attentions = False
[2022-08-11 21:59:20] - INFO: ### torchscript = False
[2022-08-11 21:59:20] - INFO: ### torch_dtype = None
[2022-08-11 21:59:20] - INFO: ### use_bfloat16 = False
[2022-08-11 21:59:20] - INFO: ### pruned_heads = {}
[2022-08-11 21:59:20] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:59:20] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:59:20] - INFO: ### is_decoder = False
[2022-08-11 21:59:20] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:59:20] - INFO: ### add_cross_attention = False
[2022-08-11 21:59:20] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:59:20] - INFO: ### max_length = 20
[2022-08-11 21:59:20] - INFO: ### min_length = 0
[2022-08-11 21:59:20] - INFO: ### do_sample = False
[2022-08-11 21:59:20] - INFO: ### early_stopping = False
[2022-08-11 21:59:20] - INFO: ### num_beams = 1
[2022-08-11 21:59:20] - INFO: ### num_beam_groups = 1
[2022-08-11 21:59:20] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:59:20] - INFO: ### temperature = 1.0
[2022-08-11 21:59:20] - INFO: ### top_k = 50
[2022-08-11 21:59:20] - INFO: ### top_p = 1.0
[2022-08-11 21:59:20] - INFO: ### typical_p = 1.0
[2022-08-11 21:59:20] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:59:20] - INFO: ### length_penalty = 1.0
[2022-08-11 21:59:20] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:59:20] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:59:20] - INFO: ### bad_words_ids = None
[2022-08-11 21:59:20] - INFO: ### num_return_sequences = 1
[2022-08-11 21:59:20] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:59:20] - INFO: ### output_scores = False
[2022-08-11 21:59:20] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:59:20] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:59:20] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:59:20] - INFO: ### remove_invalid_values = False
[2022-08-11 21:59:20] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:59:20] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:59:20] - INFO: ### finetuning_task = None
[2022-08-11 21:59:20] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:59:20] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:59:20] - INFO: ### tokenizer_class = None
[2022-08-11 21:59:20] - INFO: ### prefix = None
[2022-08-11 21:59:20] - INFO: ### bos_token_id = None
[2022-08-11 21:59:20] - INFO: ### pad_token_id = 0
[2022-08-11 21:59:20] - INFO: ### eos_token_id = None
[2022-08-11 21:59:20] - INFO: ### sep_token_id = None
[2022-08-11 21:59:20] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:59:20] - INFO: ### task_specific_params = None
[2022-08-11 21:59:20] - INFO: ### problem_type = None
[2022-08-11 21:59:20] - INFO: ### _name_or_path = 
[2022-08-11 21:59:20] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:59:20] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:59:20] - INFO: ### model_type = bert
[2022-08-11 21:59:20] - INFO: ### vocab_size = 30522
[2022-08-11 21:59:20] - INFO: ### hidden_size = 768
[2022-08-11 21:59:20] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:59:20] - INFO: ### num_attention_heads = 12
[2022-08-11 21:59:20] - INFO: ### hidden_act = gelu
[2022-08-11 21:59:20] - INFO: ### intermediate_size = 3072
[2022-08-11 21:59:20] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:59:20] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:59:20] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:59:20] - INFO: ### type_vocab_size = 2
[2022-08-11 21:59:20] - INFO: ### initializer_range = 0.02
[2022-08-11 21:59:20] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:59:20] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:59:20] - INFO: ### use_cache = True
[2022-08-11 21:59:20] - INFO: ### classifier_dropout = None
[2022-08-11 21:59:46] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 21:59:46] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 21:59:46] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 21:59:46] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 21:59:46] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 21:59:46] - INFO: ### device = cpu
[2022-08-11 21:59:46] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 21:59:46] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 21:59:46] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 21:59:46] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 21:59:46] - INFO: ### batch_size = 10
[2022-08-11 21:59:46] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 21:59:46] - INFO: ### epochs = 5
[2022-08-11 21:59:46] - INFO: ### nums_labels = 5
[2022-08-11 21:59:46] - INFO: ### return_dict = True
[2022-08-11 21:59:46] - INFO: ### output_hidden_states = False
[2022-08-11 21:59:46] - INFO: ### output_attentions = False
[2022-08-11 21:59:46] - INFO: ### torchscript = False
[2022-08-11 21:59:46] - INFO: ### torch_dtype = None
[2022-08-11 21:59:46] - INFO: ### use_bfloat16 = False
[2022-08-11 21:59:46] - INFO: ### pruned_heads = {}
[2022-08-11 21:59:46] - INFO: ### tie_word_embeddings = True
[2022-08-11 21:59:46] - INFO: ### is_encoder_decoder = False
[2022-08-11 21:59:46] - INFO: ### is_decoder = False
[2022-08-11 21:59:46] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 21:59:46] - INFO: ### add_cross_attention = False
[2022-08-11 21:59:46] - INFO: ### tie_encoder_decoder = False
[2022-08-11 21:59:46] - INFO: ### max_length = 20
[2022-08-11 21:59:46] - INFO: ### min_length = 0
[2022-08-11 21:59:46] - INFO: ### do_sample = False
[2022-08-11 21:59:46] - INFO: ### early_stopping = False
[2022-08-11 21:59:46] - INFO: ### num_beams = 1
[2022-08-11 21:59:46] - INFO: ### num_beam_groups = 1
[2022-08-11 21:59:46] - INFO: ### diversity_penalty = 0.0
[2022-08-11 21:59:46] - INFO: ### temperature = 1.0
[2022-08-11 21:59:46] - INFO: ### top_k = 50
[2022-08-11 21:59:46] - INFO: ### top_p = 1.0
[2022-08-11 21:59:46] - INFO: ### typical_p = 1.0
[2022-08-11 21:59:46] - INFO: ### repetition_penalty = 1.0
[2022-08-11 21:59:46] - INFO: ### length_penalty = 1.0
[2022-08-11 21:59:46] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 21:59:46] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 21:59:46] - INFO: ### bad_words_ids = None
[2022-08-11 21:59:46] - INFO: ### num_return_sequences = 1
[2022-08-11 21:59:46] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 21:59:46] - INFO: ### output_scores = False
[2022-08-11 21:59:46] - INFO: ### return_dict_in_generate = False
[2022-08-11 21:59:46] - INFO: ### forced_bos_token_id = None
[2022-08-11 21:59:46] - INFO: ### forced_eos_token_id = None
[2022-08-11 21:59:46] - INFO: ### remove_invalid_values = False
[2022-08-11 21:59:46] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 21:59:46] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 21:59:46] - INFO: ### finetuning_task = None
[2022-08-11 21:59:46] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 21:59:46] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 21:59:46] - INFO: ### tokenizer_class = None
[2022-08-11 21:59:46] - INFO: ### prefix = None
[2022-08-11 21:59:46] - INFO: ### bos_token_id = None
[2022-08-11 21:59:46] - INFO: ### pad_token_id = 0
[2022-08-11 21:59:46] - INFO: ### eos_token_id = None
[2022-08-11 21:59:46] - INFO: ### sep_token_id = None
[2022-08-11 21:59:46] - INFO: ### decoder_start_token_id = None
[2022-08-11 21:59:46] - INFO: ### task_specific_params = None
[2022-08-11 21:59:46] - INFO: ### problem_type = None
[2022-08-11 21:59:46] - INFO: ### _name_or_path = 
[2022-08-11 21:59:46] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 21:59:46] - INFO: ### gradient_checkpointing = False
[2022-08-11 21:59:46] - INFO: ### model_type = bert
[2022-08-11 21:59:46] - INFO: ### vocab_size = 30522
[2022-08-11 21:59:46] - INFO: ### hidden_size = 768
[2022-08-11 21:59:46] - INFO: ### num_hidden_layers = 12
[2022-08-11 21:59:46] - INFO: ### num_attention_heads = 12
[2022-08-11 21:59:46] - INFO: ### hidden_act = gelu
[2022-08-11 21:59:46] - INFO: ### intermediate_size = 3072
[2022-08-11 21:59:46] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 21:59:46] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 21:59:46] - INFO: ### max_position_embeddings = 512
[2022-08-11 21:59:46] - INFO: ### type_vocab_size = 2
[2022-08-11 21:59:46] - INFO: ### initializer_range = 0.02
[2022-08-11 21:59:46] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 21:59:46] - INFO: ### position_embedding_type = absolute
[2022-08-11 21:59:46] - INFO: ### use_cache = True
[2022-08-11 21:59:46] - INFO: ### classifier_dropout = None
[2022-08-11 22:01:37] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:01:37] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:01:37] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:01:37] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:01:37] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:01:37] - INFO: ### device = cpu
[2022-08-11 22:01:37] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:01:37] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:01:37] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:01:37] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:01:37] - INFO: ### batch_size = 10
[2022-08-11 22:01:37] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:01:37] - INFO: ### epochs = 5
[2022-08-11 22:01:37] - INFO: ### nums_labels = 5
[2022-08-11 22:01:37] - INFO: ### return_dict = True
[2022-08-11 22:01:37] - INFO: ### output_hidden_states = False
[2022-08-11 22:01:37] - INFO: ### output_attentions = False
[2022-08-11 22:01:37] - INFO: ### torchscript = False
[2022-08-11 22:01:37] - INFO: ### torch_dtype = None
[2022-08-11 22:01:37] - INFO: ### use_bfloat16 = False
[2022-08-11 22:01:37] - INFO: ### pruned_heads = {}
[2022-08-11 22:01:37] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:01:37] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:01:37] - INFO: ### is_decoder = False
[2022-08-11 22:01:37] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:01:37] - INFO: ### add_cross_attention = False
[2022-08-11 22:01:37] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:01:37] - INFO: ### max_length = 20
[2022-08-11 22:01:37] - INFO: ### min_length = 0
[2022-08-11 22:01:37] - INFO: ### do_sample = False
[2022-08-11 22:01:37] - INFO: ### early_stopping = False
[2022-08-11 22:01:37] - INFO: ### num_beams = 1
[2022-08-11 22:01:37] - INFO: ### num_beam_groups = 1
[2022-08-11 22:01:37] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:01:37] - INFO: ### temperature = 1.0
[2022-08-11 22:01:37] - INFO: ### top_k = 50
[2022-08-11 22:01:37] - INFO: ### top_p = 1.0
[2022-08-11 22:01:37] - INFO: ### typical_p = 1.0
[2022-08-11 22:01:37] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:01:37] - INFO: ### length_penalty = 1.0
[2022-08-11 22:01:37] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:01:37] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:01:37] - INFO: ### bad_words_ids = None
[2022-08-11 22:01:37] - INFO: ### num_return_sequences = 1
[2022-08-11 22:01:37] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:01:37] - INFO: ### output_scores = False
[2022-08-11 22:01:37] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:01:37] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:01:37] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:01:37] - INFO: ### remove_invalid_values = False
[2022-08-11 22:01:37] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:01:37] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:01:37] - INFO: ### finetuning_task = None
[2022-08-11 22:01:37] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:01:37] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:01:37] - INFO: ### tokenizer_class = None
[2022-08-11 22:01:37] - INFO: ### prefix = None
[2022-08-11 22:01:37] - INFO: ### bos_token_id = None
[2022-08-11 22:01:37] - INFO: ### pad_token_id = 0
[2022-08-11 22:01:37] - INFO: ### eos_token_id = None
[2022-08-11 22:01:37] - INFO: ### sep_token_id = None
[2022-08-11 22:01:37] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:01:37] - INFO: ### task_specific_params = None
[2022-08-11 22:01:37] - INFO: ### problem_type = None
[2022-08-11 22:01:37] - INFO: ### _name_or_path = 
[2022-08-11 22:01:37] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:01:37] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:01:37] - INFO: ### model_type = bert
[2022-08-11 22:01:37] - INFO: ### vocab_size = 30522
[2022-08-11 22:01:37] - INFO: ### hidden_size = 768
[2022-08-11 22:01:37] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:01:37] - INFO: ### num_attention_heads = 12
[2022-08-11 22:01:37] - INFO: ### hidden_act = gelu
[2022-08-11 22:01:37] - INFO: ### intermediate_size = 3072
[2022-08-11 22:01:37] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:01:37] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:01:37] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:01:37] - INFO: ### type_vocab_size = 2
[2022-08-11 22:01:37] - INFO: ### initializer_range = 0.02
[2022-08-11 22:01:37] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:01:37] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:01:37] - INFO: ### use_cache = True
[2022-08-11 22:01:37] - INFO: ### classifier_dropout = None
[2022-08-11 22:06:43] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:06:43] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:06:43] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:06:43] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:06:43] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:06:43] - INFO: ### device = cpu
[2022-08-11 22:06:43] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:06:43] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:06:43] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:06:43] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:06:43] - INFO: ### batch_size = 10
[2022-08-11 22:06:43] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:06:43] - INFO: ### epochs = 5
[2022-08-11 22:06:43] - INFO: ### nums_labels = 5
[2022-08-11 22:06:43] - INFO: ### return_dict = True
[2022-08-11 22:06:43] - INFO: ### output_hidden_states = False
[2022-08-11 22:06:43] - INFO: ### output_attentions = False
[2022-08-11 22:06:43] - INFO: ### torchscript = False
[2022-08-11 22:06:43] - INFO: ### torch_dtype = None
[2022-08-11 22:06:43] - INFO: ### use_bfloat16 = False
[2022-08-11 22:06:43] - INFO: ### pruned_heads = {}
[2022-08-11 22:06:43] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:06:43] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:06:43] - INFO: ### is_decoder = False
[2022-08-11 22:06:43] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:06:43] - INFO: ### add_cross_attention = False
[2022-08-11 22:06:43] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:06:43] - INFO: ### max_length = 20
[2022-08-11 22:06:43] - INFO: ### min_length = 0
[2022-08-11 22:06:43] - INFO: ### do_sample = False
[2022-08-11 22:06:43] - INFO: ### early_stopping = False
[2022-08-11 22:06:43] - INFO: ### num_beams = 1
[2022-08-11 22:06:43] - INFO: ### num_beam_groups = 1
[2022-08-11 22:06:43] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:06:43] - INFO: ### temperature = 1.0
[2022-08-11 22:06:43] - INFO: ### top_k = 50
[2022-08-11 22:06:43] - INFO: ### top_p = 1.0
[2022-08-11 22:06:43] - INFO: ### typical_p = 1.0
[2022-08-11 22:06:43] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:06:43] - INFO: ### length_penalty = 1.0
[2022-08-11 22:06:43] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:06:43] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:06:43] - INFO: ### bad_words_ids = None
[2022-08-11 22:06:43] - INFO: ### num_return_sequences = 1
[2022-08-11 22:06:43] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:06:43] - INFO: ### output_scores = False
[2022-08-11 22:06:43] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:06:43] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:06:43] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:06:43] - INFO: ### remove_invalid_values = False
[2022-08-11 22:06:43] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:06:43] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:06:43] - INFO: ### finetuning_task = None
[2022-08-11 22:06:43] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:06:43] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:06:43] - INFO: ### tokenizer_class = None
[2022-08-11 22:06:43] - INFO: ### prefix = None
[2022-08-11 22:06:43] - INFO: ### bos_token_id = None
[2022-08-11 22:06:43] - INFO: ### pad_token_id = 0
[2022-08-11 22:06:43] - INFO: ### eos_token_id = None
[2022-08-11 22:06:43] - INFO: ### sep_token_id = None
[2022-08-11 22:06:43] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:06:43] - INFO: ### task_specific_params = None
[2022-08-11 22:06:43] - INFO: ### problem_type = None
[2022-08-11 22:06:43] - INFO: ### _name_or_path = 
[2022-08-11 22:06:43] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:06:43] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:06:43] - INFO: ### model_type = bert
[2022-08-11 22:06:43] - INFO: ### vocab_size = 30522
[2022-08-11 22:06:43] - INFO: ### hidden_size = 768
[2022-08-11 22:06:43] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:06:43] - INFO: ### num_attention_heads = 12
[2022-08-11 22:06:43] - INFO: ### hidden_act = gelu
[2022-08-11 22:06:43] - INFO: ### intermediate_size = 3072
[2022-08-11 22:06:43] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:06:43] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:06:43] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:06:43] - INFO: ### type_vocab_size = 2
[2022-08-11 22:06:43] - INFO: ### initializer_range = 0.02
[2022-08-11 22:06:43] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:06:43] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:06:43] - INFO: ### use_cache = True
[2022-08-11 22:06:43] - INFO: ### classifier_dropout = None
[2022-08-11 22:37:14] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:37:14] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:37:14] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:37:14] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:37:14] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:37:14] - INFO: ### device = cpu
[2022-08-11 22:37:14] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:37:14] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:37:14] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:37:14] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:37:14] - INFO: ### batch_size = 10
[2022-08-11 22:37:14] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:37:14] - INFO: ### epochs = 5
[2022-08-11 22:37:14] - INFO: ### nums_labels = 5
[2022-08-11 22:37:14] - INFO: ### return_dict = True
[2022-08-11 22:37:14] - INFO: ### output_hidden_states = False
[2022-08-11 22:37:14] - INFO: ### output_attentions = False
[2022-08-11 22:37:14] - INFO: ### torchscript = False
[2022-08-11 22:37:14] - INFO: ### torch_dtype = None
[2022-08-11 22:37:14] - INFO: ### use_bfloat16 = False
[2022-08-11 22:37:14] - INFO: ### pruned_heads = {}
[2022-08-11 22:37:14] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:37:14] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:37:14] - INFO: ### is_decoder = False
[2022-08-11 22:37:14] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:37:14] - INFO: ### add_cross_attention = False
[2022-08-11 22:37:14] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:37:14] - INFO: ### max_length = 20
[2022-08-11 22:37:14] - INFO: ### min_length = 0
[2022-08-11 22:37:14] - INFO: ### do_sample = False
[2022-08-11 22:37:14] - INFO: ### early_stopping = False
[2022-08-11 22:37:14] - INFO: ### num_beams = 1
[2022-08-11 22:37:14] - INFO: ### num_beam_groups = 1
[2022-08-11 22:37:14] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:37:14] - INFO: ### temperature = 1.0
[2022-08-11 22:37:14] - INFO: ### top_k = 50
[2022-08-11 22:37:14] - INFO: ### top_p = 1.0
[2022-08-11 22:37:14] - INFO: ### typical_p = 1.0
[2022-08-11 22:37:14] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:37:14] - INFO: ### length_penalty = 1.0
[2022-08-11 22:37:14] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:37:14] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:37:14] - INFO: ### bad_words_ids = None
[2022-08-11 22:37:14] - INFO: ### num_return_sequences = 1
[2022-08-11 22:37:14] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:37:14] - INFO: ### output_scores = False
[2022-08-11 22:37:14] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:37:14] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:37:14] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:37:14] - INFO: ### remove_invalid_values = False
[2022-08-11 22:37:14] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:37:14] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:37:14] - INFO: ### finetuning_task = None
[2022-08-11 22:37:14] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:37:14] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:37:14] - INFO: ### tokenizer_class = None
[2022-08-11 22:37:14] - INFO: ### prefix = None
[2022-08-11 22:37:14] - INFO: ### bos_token_id = None
[2022-08-11 22:37:14] - INFO: ### pad_token_id = 0
[2022-08-11 22:37:14] - INFO: ### eos_token_id = None
[2022-08-11 22:37:14] - INFO: ### sep_token_id = None
[2022-08-11 22:37:14] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:37:14] - INFO: ### task_specific_params = None
[2022-08-11 22:37:14] - INFO: ### problem_type = None
[2022-08-11 22:37:14] - INFO: ### _name_or_path = 
[2022-08-11 22:37:14] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:37:14] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:37:14] - INFO: ### model_type = bert
[2022-08-11 22:37:14] - INFO: ### vocab_size = 30522
[2022-08-11 22:37:14] - INFO: ### hidden_size = 768
[2022-08-11 22:37:14] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:37:14] - INFO: ### num_attention_heads = 12
[2022-08-11 22:37:14] - INFO: ### hidden_act = gelu
[2022-08-11 22:37:14] - INFO: ### intermediate_size = 3072
[2022-08-11 22:37:14] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:37:14] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:37:14] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:37:14] - INFO: ### type_vocab_size = 2
[2022-08-11 22:37:14] - INFO: ### initializer_range = 0.02
[2022-08-11 22:37:14] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:37:14] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:37:14] - INFO: ### use_cache = True
[2022-08-11 22:37:14] - INFO: ### classifier_dropout = None
[2022-08-11 22:38:40] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:38:40] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:38:40] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:38:40] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:38:40] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:38:40] - INFO: ### device = cpu
[2022-08-11 22:38:40] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:38:40] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:38:40] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:38:40] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:38:40] - INFO: ### batch_size = 10
[2022-08-11 22:38:40] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:38:40] - INFO: ### epochs = 5
[2022-08-11 22:38:40] - INFO: ### nums_labels = 5
[2022-08-11 22:38:40] - INFO: ### return_dict = True
[2022-08-11 22:38:40] - INFO: ### output_hidden_states = False
[2022-08-11 22:38:40] - INFO: ### output_attentions = False
[2022-08-11 22:38:40] - INFO: ### torchscript = False
[2022-08-11 22:38:40] - INFO: ### torch_dtype = None
[2022-08-11 22:38:40] - INFO: ### use_bfloat16 = False
[2022-08-11 22:38:40] - INFO: ### pruned_heads = {}
[2022-08-11 22:38:40] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:38:40] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:38:40] - INFO: ### is_decoder = False
[2022-08-11 22:38:40] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:38:40] - INFO: ### add_cross_attention = False
[2022-08-11 22:38:40] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:38:40] - INFO: ### max_length = 20
[2022-08-11 22:38:40] - INFO: ### min_length = 0
[2022-08-11 22:38:40] - INFO: ### do_sample = False
[2022-08-11 22:38:40] - INFO: ### early_stopping = False
[2022-08-11 22:38:40] - INFO: ### num_beams = 1
[2022-08-11 22:38:40] - INFO: ### num_beam_groups = 1
[2022-08-11 22:38:40] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:38:40] - INFO: ### temperature = 1.0
[2022-08-11 22:38:40] - INFO: ### top_k = 50
[2022-08-11 22:38:40] - INFO: ### top_p = 1.0
[2022-08-11 22:38:40] - INFO: ### typical_p = 1.0
[2022-08-11 22:38:40] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:38:40] - INFO: ### length_penalty = 1.0
[2022-08-11 22:38:40] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:38:40] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:38:40] - INFO: ### bad_words_ids = None
[2022-08-11 22:38:40] - INFO: ### num_return_sequences = 1
[2022-08-11 22:38:40] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:38:40] - INFO: ### output_scores = False
[2022-08-11 22:38:40] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:38:40] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:38:40] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:38:40] - INFO: ### remove_invalid_values = False
[2022-08-11 22:38:40] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:38:40] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:38:40] - INFO: ### finetuning_task = None
[2022-08-11 22:38:40] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:38:40] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:38:40] - INFO: ### tokenizer_class = None
[2022-08-11 22:38:40] - INFO: ### prefix = None
[2022-08-11 22:38:40] - INFO: ### bos_token_id = None
[2022-08-11 22:38:40] - INFO: ### pad_token_id = 0
[2022-08-11 22:38:40] - INFO: ### eos_token_id = None
[2022-08-11 22:38:40] - INFO: ### sep_token_id = None
[2022-08-11 22:38:40] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:38:40] - INFO: ### task_specific_params = None
[2022-08-11 22:38:40] - INFO: ### problem_type = None
[2022-08-11 22:38:40] - INFO: ### _name_or_path = 
[2022-08-11 22:38:40] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:38:40] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:38:40] - INFO: ### model_type = bert
[2022-08-11 22:38:40] - INFO: ### vocab_size = 30522
[2022-08-11 22:38:40] - INFO: ### hidden_size = 768
[2022-08-11 22:38:40] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:38:40] - INFO: ### num_attention_heads = 12
[2022-08-11 22:38:40] - INFO: ### hidden_act = gelu
[2022-08-11 22:38:40] - INFO: ### intermediate_size = 3072
[2022-08-11 22:38:40] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:38:40] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:38:40] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:38:40] - INFO: ### type_vocab_size = 2
[2022-08-11 22:38:40] - INFO: ### initializer_range = 0.02
[2022-08-11 22:38:40] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:38:40] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:38:40] - INFO: ### use_cache = True
[2022-08-11 22:38:40] - INFO: ### classifier_dropout = None
[2022-08-11 22:39:40] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:39:40] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:39:40] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:39:40] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:39:40] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:39:40] - INFO: ### device = cpu
[2022-08-11 22:39:40] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:39:40] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:39:40] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:39:40] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:39:40] - INFO: ### batch_size = 10
[2022-08-11 22:39:40] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:39:40] - INFO: ### epochs = 5
[2022-08-11 22:39:40] - INFO: ### nums_labels = 5
[2022-08-11 22:39:40] - INFO: ### return_dict = True
[2022-08-11 22:39:40] - INFO: ### output_hidden_states = False
[2022-08-11 22:39:40] - INFO: ### output_attentions = False
[2022-08-11 22:39:40] - INFO: ### torchscript = False
[2022-08-11 22:39:40] - INFO: ### torch_dtype = None
[2022-08-11 22:39:40] - INFO: ### use_bfloat16 = False
[2022-08-11 22:39:40] - INFO: ### pruned_heads = {}
[2022-08-11 22:39:40] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:39:40] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:39:40] - INFO: ### is_decoder = False
[2022-08-11 22:39:40] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:39:40] - INFO: ### add_cross_attention = False
[2022-08-11 22:39:40] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:39:40] - INFO: ### max_length = 20
[2022-08-11 22:39:40] - INFO: ### min_length = 0
[2022-08-11 22:39:40] - INFO: ### do_sample = False
[2022-08-11 22:39:40] - INFO: ### early_stopping = False
[2022-08-11 22:39:40] - INFO: ### num_beams = 1
[2022-08-11 22:39:40] - INFO: ### num_beam_groups = 1
[2022-08-11 22:39:40] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:39:40] - INFO: ### temperature = 1.0
[2022-08-11 22:39:40] - INFO: ### top_k = 50
[2022-08-11 22:39:40] - INFO: ### top_p = 1.0
[2022-08-11 22:39:40] - INFO: ### typical_p = 1.0
[2022-08-11 22:39:40] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:39:40] - INFO: ### length_penalty = 1.0
[2022-08-11 22:39:40] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:39:40] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:39:40] - INFO: ### bad_words_ids = None
[2022-08-11 22:39:40] - INFO: ### num_return_sequences = 1
[2022-08-11 22:39:40] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:39:40] - INFO: ### output_scores = False
[2022-08-11 22:39:40] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:39:40] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:39:40] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:39:40] - INFO: ### remove_invalid_values = False
[2022-08-11 22:39:40] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:39:40] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:39:40] - INFO: ### finetuning_task = None
[2022-08-11 22:39:40] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:39:40] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:39:40] - INFO: ### tokenizer_class = None
[2022-08-11 22:39:40] - INFO: ### prefix = None
[2022-08-11 22:39:40] - INFO: ### bos_token_id = None
[2022-08-11 22:39:40] - INFO: ### pad_token_id = 0
[2022-08-11 22:39:40] - INFO: ### eos_token_id = None
[2022-08-11 22:39:40] - INFO: ### sep_token_id = None
[2022-08-11 22:39:40] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:39:40] - INFO: ### task_specific_params = None
[2022-08-11 22:39:40] - INFO: ### problem_type = None
[2022-08-11 22:39:40] - INFO: ### _name_or_path = 
[2022-08-11 22:39:40] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:39:40] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:39:40] - INFO: ### model_type = bert
[2022-08-11 22:39:40] - INFO: ### vocab_size = 30522
[2022-08-11 22:39:40] - INFO: ### hidden_size = 768
[2022-08-11 22:39:40] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:39:40] - INFO: ### num_attention_heads = 12
[2022-08-11 22:39:40] - INFO: ### hidden_act = gelu
[2022-08-11 22:39:40] - INFO: ### intermediate_size = 3072
[2022-08-11 22:39:40] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:39:40] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:39:40] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:39:40] - INFO: ### type_vocab_size = 2
[2022-08-11 22:39:40] - INFO: ### initializer_range = 0.02
[2022-08-11 22:39:40] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:39:40] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:39:40] - INFO: ### use_cache = True
[2022-08-11 22:39:40] - INFO: ### classifier_dropout = None
[2022-08-11 22:41:45] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:41:45] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:41:45] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:41:45] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:41:45] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:41:45] - INFO: ### device = cpu
[2022-08-11 22:41:45] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:41:45] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:41:45] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:41:45] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:41:45] - INFO: ### batch_size = 10
[2022-08-11 22:41:45] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:41:45] - INFO: ### epochs = 5
[2022-08-11 22:41:45] - INFO: ### nums_labels = 5
[2022-08-11 22:41:45] - INFO: ### return_dict = True
[2022-08-11 22:41:45] - INFO: ### output_hidden_states = False
[2022-08-11 22:41:45] - INFO: ### output_attentions = False
[2022-08-11 22:41:45] - INFO: ### torchscript = False
[2022-08-11 22:41:45] - INFO: ### torch_dtype = None
[2022-08-11 22:41:45] - INFO: ### use_bfloat16 = False
[2022-08-11 22:41:45] - INFO: ### pruned_heads = {}
[2022-08-11 22:41:45] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:41:45] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:41:45] - INFO: ### is_decoder = False
[2022-08-11 22:41:45] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:41:45] - INFO: ### add_cross_attention = False
[2022-08-11 22:41:45] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:41:45] - INFO: ### max_length = 20
[2022-08-11 22:41:45] - INFO: ### min_length = 0
[2022-08-11 22:41:45] - INFO: ### do_sample = False
[2022-08-11 22:41:45] - INFO: ### early_stopping = False
[2022-08-11 22:41:45] - INFO: ### num_beams = 1
[2022-08-11 22:41:45] - INFO: ### num_beam_groups = 1
[2022-08-11 22:41:45] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:41:45] - INFO: ### temperature = 1.0
[2022-08-11 22:41:45] - INFO: ### top_k = 50
[2022-08-11 22:41:45] - INFO: ### top_p = 1.0
[2022-08-11 22:41:45] - INFO: ### typical_p = 1.0
[2022-08-11 22:41:45] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:41:45] - INFO: ### length_penalty = 1.0
[2022-08-11 22:41:45] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:41:45] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:41:45] - INFO: ### bad_words_ids = None
[2022-08-11 22:41:45] - INFO: ### num_return_sequences = 1
[2022-08-11 22:41:45] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:41:45] - INFO: ### output_scores = False
[2022-08-11 22:41:45] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:41:45] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:41:45] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:41:45] - INFO: ### remove_invalid_values = False
[2022-08-11 22:41:45] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:41:45] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:41:45] - INFO: ### finetuning_task = None
[2022-08-11 22:41:45] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:41:45] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:41:45] - INFO: ### tokenizer_class = None
[2022-08-11 22:41:45] - INFO: ### prefix = None
[2022-08-11 22:41:45] - INFO: ### bos_token_id = None
[2022-08-11 22:41:45] - INFO: ### pad_token_id = 0
[2022-08-11 22:41:45] - INFO: ### eos_token_id = None
[2022-08-11 22:41:45] - INFO: ### sep_token_id = None
[2022-08-11 22:41:45] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:41:45] - INFO: ### task_specific_params = None
[2022-08-11 22:41:45] - INFO: ### problem_type = None
[2022-08-11 22:41:45] - INFO: ### _name_or_path = 
[2022-08-11 22:41:45] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:41:45] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:41:45] - INFO: ### model_type = bert
[2022-08-11 22:41:45] - INFO: ### vocab_size = 30522
[2022-08-11 22:41:45] - INFO: ### hidden_size = 768
[2022-08-11 22:41:45] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:41:45] - INFO: ### num_attention_heads = 12
[2022-08-11 22:41:45] - INFO: ### hidden_act = gelu
[2022-08-11 22:41:45] - INFO: ### intermediate_size = 3072
[2022-08-11 22:41:45] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:41:45] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:41:45] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:41:45] - INFO: ### type_vocab_size = 2
[2022-08-11 22:41:45] - INFO: ### initializer_range = 0.02
[2022-08-11 22:41:45] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:41:45] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:41:45] - INFO: ### use_cache = True
[2022-08-11 22:41:45] - INFO: ### classifier_dropout = None
[2022-08-11 22:45:52] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:45:52] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:45:52] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:45:52] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:45:52] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:45:52] - INFO: ### device = cpu
[2022-08-11 22:45:52] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:45:52] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:45:52] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:45:52] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:45:52] - INFO: ### batch_size = 10
[2022-08-11 22:45:52] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:45:52] - INFO: ### epochs = 5
[2022-08-11 22:45:52] - INFO: ### nums_labels = 5
[2022-08-11 22:45:52] - INFO: ### return_dict = True
[2022-08-11 22:45:52] - INFO: ### output_hidden_states = False
[2022-08-11 22:45:52] - INFO: ### output_attentions = False
[2022-08-11 22:45:52] - INFO: ### torchscript = False
[2022-08-11 22:45:52] - INFO: ### torch_dtype = None
[2022-08-11 22:45:52] - INFO: ### use_bfloat16 = False
[2022-08-11 22:45:52] - INFO: ### pruned_heads = {}
[2022-08-11 22:45:52] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:45:52] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:45:52] - INFO: ### is_decoder = False
[2022-08-11 22:45:52] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:45:52] - INFO: ### add_cross_attention = False
[2022-08-11 22:45:52] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:45:52] - INFO: ### max_length = 20
[2022-08-11 22:45:52] - INFO: ### min_length = 0
[2022-08-11 22:45:52] - INFO: ### do_sample = False
[2022-08-11 22:45:52] - INFO: ### early_stopping = False
[2022-08-11 22:45:52] - INFO: ### num_beams = 1
[2022-08-11 22:45:52] - INFO: ### num_beam_groups = 1
[2022-08-11 22:45:52] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:45:52] - INFO: ### temperature = 1.0
[2022-08-11 22:45:52] - INFO: ### top_k = 50
[2022-08-11 22:45:52] - INFO: ### top_p = 1.0
[2022-08-11 22:45:52] - INFO: ### typical_p = 1.0
[2022-08-11 22:45:52] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:45:52] - INFO: ### length_penalty = 1.0
[2022-08-11 22:45:52] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:45:52] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:45:52] - INFO: ### bad_words_ids = None
[2022-08-11 22:45:52] - INFO: ### num_return_sequences = 1
[2022-08-11 22:45:52] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:45:52] - INFO: ### output_scores = False
[2022-08-11 22:45:52] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:45:52] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:45:52] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:45:52] - INFO: ### remove_invalid_values = False
[2022-08-11 22:45:52] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:45:52] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:45:52] - INFO: ### finetuning_task = None
[2022-08-11 22:45:52] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:45:52] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:45:52] - INFO: ### tokenizer_class = None
[2022-08-11 22:45:52] - INFO: ### prefix = None
[2022-08-11 22:45:52] - INFO: ### bos_token_id = None
[2022-08-11 22:45:52] - INFO: ### pad_token_id = 0
[2022-08-11 22:45:52] - INFO: ### eos_token_id = None
[2022-08-11 22:45:52] - INFO: ### sep_token_id = None
[2022-08-11 22:45:52] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:45:52] - INFO: ### task_specific_params = None
[2022-08-11 22:45:52] - INFO: ### problem_type = None
[2022-08-11 22:45:52] - INFO: ### _name_or_path = 
[2022-08-11 22:45:52] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:45:52] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:45:52] - INFO: ### model_type = bert
[2022-08-11 22:45:52] - INFO: ### vocab_size = 30522
[2022-08-11 22:45:52] - INFO: ### hidden_size = 768
[2022-08-11 22:45:52] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:45:52] - INFO: ### num_attention_heads = 12
[2022-08-11 22:45:52] - INFO: ### hidden_act = gelu
[2022-08-11 22:45:52] - INFO: ### intermediate_size = 3072
[2022-08-11 22:45:52] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:45:52] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:45:52] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:45:52] - INFO: ### type_vocab_size = 2
[2022-08-11 22:45:52] - INFO: ### initializer_range = 0.02
[2022-08-11 22:45:52] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:45:52] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:45:52] - INFO: ### use_cache = True
[2022-08-11 22:45:52] - INFO: ### classifier_dropout = None
[2022-08-11 22:46:28] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:46:28] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:46:28] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:46:28] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:46:28] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:46:28] - INFO: ### device = cpu
[2022-08-11 22:46:28] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:46:28] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:46:28] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:46:28] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:46:28] - INFO: ### batch_size = 10
[2022-08-11 22:46:28] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:46:28] - INFO: ### epochs = 5
[2022-08-11 22:46:28] - INFO: ### nums_labels = 5
[2022-08-11 22:46:28] - INFO: ### return_dict = True
[2022-08-11 22:46:28] - INFO: ### output_hidden_states = False
[2022-08-11 22:46:28] - INFO: ### output_attentions = False
[2022-08-11 22:46:28] - INFO: ### torchscript = False
[2022-08-11 22:46:28] - INFO: ### torch_dtype = None
[2022-08-11 22:46:28] - INFO: ### use_bfloat16 = False
[2022-08-11 22:46:28] - INFO: ### pruned_heads = {}
[2022-08-11 22:46:28] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:46:28] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:46:28] - INFO: ### is_decoder = False
[2022-08-11 22:46:28] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:46:28] - INFO: ### add_cross_attention = False
[2022-08-11 22:46:28] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:46:28] - INFO: ### max_length = 20
[2022-08-11 22:46:28] - INFO: ### min_length = 0
[2022-08-11 22:46:28] - INFO: ### do_sample = False
[2022-08-11 22:46:28] - INFO: ### early_stopping = False
[2022-08-11 22:46:28] - INFO: ### num_beams = 1
[2022-08-11 22:46:28] - INFO: ### num_beam_groups = 1
[2022-08-11 22:46:28] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:46:28] - INFO: ### temperature = 1.0
[2022-08-11 22:46:28] - INFO: ### top_k = 50
[2022-08-11 22:46:28] - INFO: ### top_p = 1.0
[2022-08-11 22:46:28] - INFO: ### typical_p = 1.0
[2022-08-11 22:46:28] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:46:28] - INFO: ### length_penalty = 1.0
[2022-08-11 22:46:28] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:46:28] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:46:28] - INFO: ### bad_words_ids = None
[2022-08-11 22:46:28] - INFO: ### num_return_sequences = 1
[2022-08-11 22:46:28] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:46:28] - INFO: ### output_scores = False
[2022-08-11 22:46:28] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:46:28] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:46:28] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:46:28] - INFO: ### remove_invalid_values = False
[2022-08-11 22:46:28] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:46:28] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:46:28] - INFO: ### finetuning_task = None
[2022-08-11 22:46:28] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:46:28] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:46:28] - INFO: ### tokenizer_class = None
[2022-08-11 22:46:28] - INFO: ### prefix = None
[2022-08-11 22:46:28] - INFO: ### bos_token_id = None
[2022-08-11 22:46:28] - INFO: ### pad_token_id = 0
[2022-08-11 22:46:28] - INFO: ### eos_token_id = None
[2022-08-11 22:46:28] - INFO: ### sep_token_id = None
[2022-08-11 22:46:28] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:46:28] - INFO: ### task_specific_params = None
[2022-08-11 22:46:28] - INFO: ### problem_type = None
[2022-08-11 22:46:28] - INFO: ### _name_or_path = 
[2022-08-11 22:46:28] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:46:28] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:46:28] - INFO: ### model_type = bert
[2022-08-11 22:46:28] - INFO: ### vocab_size = 30522
[2022-08-11 22:46:28] - INFO: ### hidden_size = 768
[2022-08-11 22:46:28] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:46:28] - INFO: ### num_attention_heads = 12
[2022-08-11 22:46:28] - INFO: ### hidden_act = gelu
[2022-08-11 22:46:28] - INFO: ### intermediate_size = 3072
[2022-08-11 22:46:28] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:46:28] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:46:28] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:46:28] - INFO: ### type_vocab_size = 2
[2022-08-11 22:46:28] - INFO: ### initializer_range = 0.02
[2022-08-11 22:46:28] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:46:28] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:46:28] - INFO: ### use_cache = True
[2022-08-11 22:46:28] - INFO: ### classifier_dropout = None
[2022-08-11 22:47:16] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-11 22:47:16] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-11 22:47:16] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-11 22:47:16] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-11 22:47:16] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-11 22:47:16] - INFO: ### device = cpu
[2022-08-11 22:47:16] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-11 22:47:16] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-11 22:47:16] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-11 22:47:16] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-11 22:47:16] - INFO: ### batch_size = 10
[2022-08-11 22:47:16] - INFO: ### learning_rate = 3.5e-05
[2022-08-11 22:47:16] - INFO: ### epochs = 5
[2022-08-11 22:47:16] - INFO: ### nums_labels = 5
[2022-08-11 22:47:16] - INFO: ### return_dict = True
[2022-08-11 22:47:16] - INFO: ### output_hidden_states = False
[2022-08-11 22:47:16] - INFO: ### output_attentions = False
[2022-08-11 22:47:16] - INFO: ### torchscript = False
[2022-08-11 22:47:16] - INFO: ### torch_dtype = None
[2022-08-11 22:47:16] - INFO: ### use_bfloat16 = False
[2022-08-11 22:47:16] - INFO: ### pruned_heads = {}
[2022-08-11 22:47:16] - INFO: ### tie_word_embeddings = True
[2022-08-11 22:47:16] - INFO: ### is_encoder_decoder = False
[2022-08-11 22:47:16] - INFO: ### is_decoder = False
[2022-08-11 22:47:16] - INFO: ### cross_attention_hidden_size = None
[2022-08-11 22:47:16] - INFO: ### add_cross_attention = False
[2022-08-11 22:47:16] - INFO: ### tie_encoder_decoder = False
[2022-08-11 22:47:16] - INFO: ### max_length = 20
[2022-08-11 22:47:16] - INFO: ### min_length = 0
[2022-08-11 22:47:16] - INFO: ### do_sample = False
[2022-08-11 22:47:16] - INFO: ### early_stopping = False
[2022-08-11 22:47:16] - INFO: ### num_beams = 1
[2022-08-11 22:47:16] - INFO: ### num_beam_groups = 1
[2022-08-11 22:47:16] - INFO: ### diversity_penalty = 0.0
[2022-08-11 22:47:16] - INFO: ### temperature = 1.0
[2022-08-11 22:47:16] - INFO: ### top_k = 50
[2022-08-11 22:47:16] - INFO: ### top_p = 1.0
[2022-08-11 22:47:16] - INFO: ### typical_p = 1.0
[2022-08-11 22:47:16] - INFO: ### repetition_penalty = 1.0
[2022-08-11 22:47:16] - INFO: ### length_penalty = 1.0
[2022-08-11 22:47:16] - INFO: ### no_repeat_ngram_size = 0
[2022-08-11 22:47:16] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-11 22:47:16] - INFO: ### bad_words_ids = None
[2022-08-11 22:47:16] - INFO: ### num_return_sequences = 1
[2022-08-11 22:47:16] - INFO: ### chunk_size_feed_forward = 0
[2022-08-11 22:47:16] - INFO: ### output_scores = False
[2022-08-11 22:47:16] - INFO: ### return_dict_in_generate = False
[2022-08-11 22:47:16] - INFO: ### forced_bos_token_id = None
[2022-08-11 22:47:16] - INFO: ### forced_eos_token_id = None
[2022-08-11 22:47:16] - INFO: ### remove_invalid_values = False
[2022-08-11 22:47:16] - INFO: ### exponential_decay_length_penalty = None
[2022-08-11 22:47:16] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-11 22:47:16] - INFO: ### finetuning_task = None
[2022-08-11 22:47:16] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-11 22:47:16] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-11 22:47:16] - INFO: ### tokenizer_class = None
[2022-08-11 22:47:16] - INFO: ### prefix = None
[2022-08-11 22:47:16] - INFO: ### bos_token_id = None
[2022-08-11 22:47:16] - INFO: ### pad_token_id = 0
[2022-08-11 22:47:16] - INFO: ### eos_token_id = None
[2022-08-11 22:47:16] - INFO: ### sep_token_id = None
[2022-08-11 22:47:16] - INFO: ### decoder_start_token_id = None
[2022-08-11 22:47:16] - INFO: ### task_specific_params = None
[2022-08-11 22:47:16] - INFO: ### problem_type = None
[2022-08-11 22:47:16] - INFO: ### _name_or_path = 
[2022-08-11 22:47:16] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-11 22:47:16] - INFO: ### gradient_checkpointing = False
[2022-08-11 22:47:16] - INFO: ### model_type = bert
[2022-08-11 22:47:16] - INFO: ### vocab_size = 30522
[2022-08-11 22:47:16] - INFO: ### hidden_size = 768
[2022-08-11 22:47:16] - INFO: ### num_hidden_layers = 12
[2022-08-11 22:47:16] - INFO: ### num_attention_heads = 12
[2022-08-11 22:47:16] - INFO: ### hidden_act = gelu
[2022-08-11 22:47:16] - INFO: ### intermediate_size = 3072
[2022-08-11 22:47:16] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-11 22:47:16] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-11 22:47:16] - INFO: ### max_position_embeddings = 512
[2022-08-11 22:47:16] - INFO: ### type_vocab_size = 2
[2022-08-11 22:47:16] - INFO: ### initializer_range = 0.02
[2022-08-11 22:47:16] - INFO: ### layer_norm_eps = 1e-12
[2022-08-11 22:47:16] - INFO: ### position_embedding_type = absolute
[2022-08-11 22:47:16] - INFO: ### use_cache = True
[2022-08-11 22:47:16] - INFO: ### classifier_dropout = None
