[2022-08-12 11:19:50] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:19:50] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:19:50] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:19:50] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:19:50] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:19:50] - INFO: ### device = cpu
[2022-08-12 11:19:50] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:19:50] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:19:50] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:19:50] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:19:50] - INFO: ### batch_size = 10
[2022-08-12 11:19:50] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:19:50] - INFO: ### epochs = 5
[2022-08-12 11:19:50] - INFO: ### nums_labels = 5
[2022-08-12 11:19:50] - INFO: ### labels = {'business': 0, 'entertainment': 1, 'sport': 2, 'tech': 3, 'politics': 4}
[2022-08-12 11:19:50] - INFO: ### return_dict = True
[2022-08-12 11:19:50] - INFO: ### output_hidden_states = False
[2022-08-12 11:19:50] - INFO: ### output_attentions = False
[2022-08-12 11:19:50] - INFO: ### torchscript = False
[2022-08-12 11:19:50] - INFO: ### torch_dtype = None
[2022-08-12 11:19:50] - INFO: ### use_bfloat16 = False
[2022-08-12 11:19:50] - INFO: ### pruned_heads = {}
[2022-08-12 11:19:50] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:19:50] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:19:50] - INFO: ### is_decoder = False
[2022-08-12 11:19:50] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:19:50] - INFO: ### add_cross_attention = False
[2022-08-12 11:19:50] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:19:50] - INFO: ### max_length = 20
[2022-08-12 11:19:50] - INFO: ### min_length = 0
[2022-08-12 11:19:50] - INFO: ### do_sample = False
[2022-08-12 11:19:50] - INFO: ### early_stopping = False
[2022-08-12 11:19:50] - INFO: ### num_beams = 1
[2022-08-12 11:19:50] - INFO: ### num_beam_groups = 1
[2022-08-12 11:19:50] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:19:50] - INFO: ### temperature = 1.0
[2022-08-12 11:19:50] - INFO: ### top_k = 50
[2022-08-12 11:19:50] - INFO: ### top_p = 1.0
[2022-08-12 11:19:50] - INFO: ### typical_p = 1.0
[2022-08-12 11:19:50] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:19:50] - INFO: ### length_penalty = 1.0
[2022-08-12 11:19:50] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:19:50] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:19:50] - INFO: ### bad_words_ids = None
[2022-08-12 11:19:50] - INFO: ### num_return_sequences = 1
[2022-08-12 11:19:50] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:19:50] - INFO: ### output_scores = False
[2022-08-12 11:19:50] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:19:50] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:19:50] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:19:50] - INFO: ### remove_invalid_values = False
[2022-08-12 11:19:50] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:19:50] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:19:50] - INFO: ### finetuning_task = None
[2022-08-12 11:19:50] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:19:50] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:19:50] - INFO: ### tokenizer_class = None
[2022-08-12 11:19:50] - INFO: ### prefix = None
[2022-08-12 11:19:50] - INFO: ### bos_token_id = None
[2022-08-12 11:19:50] - INFO: ### pad_token_id = 0
[2022-08-12 11:19:50] - INFO: ### eos_token_id = None
[2022-08-12 11:19:50] - INFO: ### sep_token_id = None
[2022-08-12 11:19:50] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:19:50] - INFO: ### task_specific_params = None
[2022-08-12 11:19:50] - INFO: ### problem_type = None
[2022-08-12 11:19:50] - INFO: ### _name_or_path = 
[2022-08-12 11:19:50] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:19:50] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:19:50] - INFO: ### model_type = bert
[2022-08-12 11:19:50] - INFO: ### vocab_size = 30522
[2022-08-12 11:19:50] - INFO: ### hidden_size = 768
[2022-08-12 11:19:50] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:19:50] - INFO: ### num_attention_heads = 12
[2022-08-12 11:19:50] - INFO: ### hidden_act = gelu
[2022-08-12 11:19:50] - INFO: ### intermediate_size = 3072
[2022-08-12 11:19:50] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:19:50] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:19:50] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:19:50] - INFO: ### type_vocab_size = 2
[2022-08-12 11:19:50] - INFO: ### initializer_range = 0.02
[2022-08-12 11:19:50] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:19:50] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:19:50] - INFO: ### use_cache = True
[2022-08-12 11:19:50] - INFO: ### classifier_dropout = None
[2022-08-12 11:21:06] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:21:06] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:21:06] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:21:06] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:21:06] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:21:06] - INFO: ### device = cpu
[2022-08-12 11:21:06] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:21:06] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:21:06] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:21:06] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:21:06] - INFO: ### batch_size = 10
[2022-08-12 11:21:06] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:21:06] - INFO: ### epochs = 5
[2022-08-12 11:21:06] - INFO: ### nums_labels = 5
[2022-08-12 11:21:06] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:21:06] - INFO: ### return_dict = True
[2022-08-12 11:21:06] - INFO: ### output_hidden_states = False
[2022-08-12 11:21:06] - INFO: ### output_attentions = False
[2022-08-12 11:21:06] - INFO: ### torchscript = False
[2022-08-12 11:21:06] - INFO: ### torch_dtype = None
[2022-08-12 11:21:06] - INFO: ### use_bfloat16 = False
[2022-08-12 11:21:06] - INFO: ### pruned_heads = {}
[2022-08-12 11:21:06] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:21:06] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:21:06] - INFO: ### is_decoder = False
[2022-08-12 11:21:06] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:21:06] - INFO: ### add_cross_attention = False
[2022-08-12 11:21:06] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:21:06] - INFO: ### max_length = 20
[2022-08-12 11:21:06] - INFO: ### min_length = 0
[2022-08-12 11:21:06] - INFO: ### do_sample = False
[2022-08-12 11:21:06] - INFO: ### early_stopping = False
[2022-08-12 11:21:06] - INFO: ### num_beams = 1
[2022-08-12 11:21:06] - INFO: ### num_beam_groups = 1
[2022-08-12 11:21:06] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:21:06] - INFO: ### temperature = 1.0
[2022-08-12 11:21:06] - INFO: ### top_k = 50
[2022-08-12 11:21:06] - INFO: ### top_p = 1.0
[2022-08-12 11:21:06] - INFO: ### typical_p = 1.0
[2022-08-12 11:21:06] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:21:06] - INFO: ### length_penalty = 1.0
[2022-08-12 11:21:06] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:21:06] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:21:06] - INFO: ### bad_words_ids = None
[2022-08-12 11:21:06] - INFO: ### num_return_sequences = 1
[2022-08-12 11:21:06] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:21:06] - INFO: ### output_scores = False
[2022-08-12 11:21:06] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:21:06] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:21:06] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:21:06] - INFO: ### remove_invalid_values = False
[2022-08-12 11:21:06] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:21:06] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:21:06] - INFO: ### finetuning_task = None
[2022-08-12 11:21:06] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:21:06] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:21:06] - INFO: ### tokenizer_class = None
[2022-08-12 11:21:06] - INFO: ### prefix = None
[2022-08-12 11:21:06] - INFO: ### bos_token_id = None
[2022-08-12 11:21:06] - INFO: ### pad_token_id = 0
[2022-08-12 11:21:06] - INFO: ### eos_token_id = None
[2022-08-12 11:21:06] - INFO: ### sep_token_id = None
[2022-08-12 11:21:06] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:21:06] - INFO: ### task_specific_params = None
[2022-08-12 11:21:06] - INFO: ### problem_type = None
[2022-08-12 11:21:06] - INFO: ### _name_or_path = 
[2022-08-12 11:21:06] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:21:06] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:21:06] - INFO: ### model_type = bert
[2022-08-12 11:21:06] - INFO: ### vocab_size = 30522
[2022-08-12 11:21:06] - INFO: ### hidden_size = 768
[2022-08-12 11:21:06] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:21:06] - INFO: ### num_attention_heads = 12
[2022-08-12 11:21:06] - INFO: ### hidden_act = gelu
[2022-08-12 11:21:06] - INFO: ### intermediate_size = 3072
[2022-08-12 11:21:06] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:21:06] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:21:06] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:21:06] - INFO: ### type_vocab_size = 2
[2022-08-12 11:21:06] - INFO: ### initializer_range = 0.02
[2022-08-12 11:21:06] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:21:06] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:21:06] - INFO: ### use_cache = True
[2022-08-12 11:21:06] - INFO: ### classifier_dropout = None
[2022-08-12 11:24:25] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:24:25] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:24:25] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:24:25] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:24:25] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:24:25] - INFO: ### device = cpu
[2022-08-12 11:24:25] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:24:25] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:24:25] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:24:25] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:24:25] - INFO: ### batch_size = 10
[2022-08-12 11:24:25] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:24:25] - INFO: ### epochs = 5
[2022-08-12 11:24:25] - INFO: ### nums_labels = 5
[2022-08-12 11:24:25] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:24:25] - INFO: ### return_dict = True
[2022-08-12 11:24:25] - INFO: ### output_hidden_states = False
[2022-08-12 11:24:25] - INFO: ### output_attentions = False
[2022-08-12 11:24:25] - INFO: ### torchscript = False
[2022-08-12 11:24:25] - INFO: ### torch_dtype = None
[2022-08-12 11:24:25] - INFO: ### use_bfloat16 = False
[2022-08-12 11:24:25] - INFO: ### pruned_heads = {}
[2022-08-12 11:24:25] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:24:25] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:24:25] - INFO: ### is_decoder = False
[2022-08-12 11:24:25] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:24:25] - INFO: ### add_cross_attention = False
[2022-08-12 11:24:25] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:24:25] - INFO: ### max_length = 20
[2022-08-12 11:24:25] - INFO: ### min_length = 0
[2022-08-12 11:24:25] - INFO: ### do_sample = False
[2022-08-12 11:24:25] - INFO: ### early_stopping = False
[2022-08-12 11:24:25] - INFO: ### num_beams = 1
[2022-08-12 11:24:25] - INFO: ### num_beam_groups = 1
[2022-08-12 11:24:25] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:24:25] - INFO: ### temperature = 1.0
[2022-08-12 11:24:25] - INFO: ### top_k = 50
[2022-08-12 11:24:25] - INFO: ### top_p = 1.0
[2022-08-12 11:24:25] - INFO: ### typical_p = 1.0
[2022-08-12 11:24:25] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:24:25] - INFO: ### length_penalty = 1.0
[2022-08-12 11:24:25] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:24:25] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:24:25] - INFO: ### bad_words_ids = None
[2022-08-12 11:24:25] - INFO: ### num_return_sequences = 1
[2022-08-12 11:24:25] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:24:25] - INFO: ### output_scores = False
[2022-08-12 11:24:25] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:24:25] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:24:25] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:24:25] - INFO: ### remove_invalid_values = False
[2022-08-12 11:24:25] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:24:25] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:24:25] - INFO: ### finetuning_task = None
[2022-08-12 11:24:25] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:24:25] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:24:25] - INFO: ### tokenizer_class = None
[2022-08-12 11:24:25] - INFO: ### prefix = None
[2022-08-12 11:24:25] - INFO: ### bos_token_id = None
[2022-08-12 11:24:25] - INFO: ### pad_token_id = 0
[2022-08-12 11:24:25] - INFO: ### eos_token_id = None
[2022-08-12 11:24:25] - INFO: ### sep_token_id = None
[2022-08-12 11:24:25] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:24:25] - INFO: ### task_specific_params = None
[2022-08-12 11:24:25] - INFO: ### problem_type = None
[2022-08-12 11:24:25] - INFO: ### _name_or_path = 
[2022-08-12 11:24:25] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:24:25] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:24:25] - INFO: ### model_type = bert
[2022-08-12 11:24:25] - INFO: ### vocab_size = 30522
[2022-08-12 11:24:25] - INFO: ### hidden_size = 768
[2022-08-12 11:24:25] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:24:25] - INFO: ### num_attention_heads = 12
[2022-08-12 11:24:25] - INFO: ### hidden_act = gelu
[2022-08-12 11:24:25] - INFO: ### intermediate_size = 3072
[2022-08-12 11:24:25] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:24:25] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:24:25] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:24:25] - INFO: ### type_vocab_size = 2
[2022-08-12 11:24:25] - INFO: ### initializer_range = 0.02
[2022-08-12 11:24:25] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:24:25] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:24:25] - INFO: ### use_cache = True
[2022-08-12 11:24:25] - INFO: ### classifier_dropout = None
[2022-08-12 11:25:04] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:25:04] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:25:04] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:25:04] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:25:04] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:25:04] - INFO: ### device = cpu
[2022-08-12 11:25:04] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:25:04] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:25:04] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:25:04] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:25:04] - INFO: ### batch_size = 10
[2022-08-12 11:25:04] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:25:04] - INFO: ### epochs = 5
[2022-08-12 11:25:04] - INFO: ### nums_labels = 5
[2022-08-12 11:25:04] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:25:04] - INFO: ### return_dict = True
[2022-08-12 11:25:04] - INFO: ### output_hidden_states = False
[2022-08-12 11:25:04] - INFO: ### output_attentions = False
[2022-08-12 11:25:04] - INFO: ### torchscript = False
[2022-08-12 11:25:04] - INFO: ### torch_dtype = None
[2022-08-12 11:25:04] - INFO: ### use_bfloat16 = False
[2022-08-12 11:25:04] - INFO: ### pruned_heads = {}
[2022-08-12 11:25:04] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:25:04] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:25:04] - INFO: ### is_decoder = False
[2022-08-12 11:25:04] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:25:04] - INFO: ### add_cross_attention = False
[2022-08-12 11:25:04] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:25:04] - INFO: ### max_length = 20
[2022-08-12 11:25:04] - INFO: ### min_length = 0
[2022-08-12 11:25:04] - INFO: ### do_sample = False
[2022-08-12 11:25:04] - INFO: ### early_stopping = False
[2022-08-12 11:25:04] - INFO: ### num_beams = 1
[2022-08-12 11:25:04] - INFO: ### num_beam_groups = 1
[2022-08-12 11:25:04] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:25:04] - INFO: ### temperature = 1.0
[2022-08-12 11:25:04] - INFO: ### top_k = 50
[2022-08-12 11:25:04] - INFO: ### top_p = 1.0
[2022-08-12 11:25:04] - INFO: ### typical_p = 1.0
[2022-08-12 11:25:04] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:25:04] - INFO: ### length_penalty = 1.0
[2022-08-12 11:25:04] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:25:04] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:25:04] - INFO: ### bad_words_ids = None
[2022-08-12 11:25:04] - INFO: ### num_return_sequences = 1
[2022-08-12 11:25:04] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:25:04] - INFO: ### output_scores = False
[2022-08-12 11:25:04] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:25:04] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:25:04] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:25:04] - INFO: ### remove_invalid_values = False
[2022-08-12 11:25:04] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:25:04] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:25:04] - INFO: ### finetuning_task = None
[2022-08-12 11:25:04] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:25:04] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:25:04] - INFO: ### tokenizer_class = None
[2022-08-12 11:25:04] - INFO: ### prefix = None
[2022-08-12 11:25:04] - INFO: ### bos_token_id = None
[2022-08-12 11:25:04] - INFO: ### pad_token_id = 0
[2022-08-12 11:25:04] - INFO: ### eos_token_id = None
[2022-08-12 11:25:04] - INFO: ### sep_token_id = None
[2022-08-12 11:25:04] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:25:04] - INFO: ### task_specific_params = None
[2022-08-12 11:25:04] - INFO: ### problem_type = None
[2022-08-12 11:25:04] - INFO: ### _name_or_path = 
[2022-08-12 11:25:04] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:25:04] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:25:04] - INFO: ### model_type = bert
[2022-08-12 11:25:04] - INFO: ### vocab_size = 30522
[2022-08-12 11:25:04] - INFO: ### hidden_size = 768
[2022-08-12 11:25:04] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:25:04] - INFO: ### num_attention_heads = 12
[2022-08-12 11:25:04] - INFO: ### hidden_act = gelu
[2022-08-12 11:25:04] - INFO: ### intermediate_size = 3072
[2022-08-12 11:25:04] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:25:04] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:25:04] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:25:04] - INFO: ### type_vocab_size = 2
[2022-08-12 11:25:04] - INFO: ### initializer_range = 0.02
[2022-08-12 11:25:04] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:25:04] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:25:04] - INFO: ### use_cache = True
[2022-08-12 11:25:04] - INFO: ### classifier_dropout = None
[2022-08-12 11:29:05] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:29:05] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:29:05] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:29:05] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:29:05] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:29:05] - INFO: ### device = cpu
[2022-08-12 11:29:05] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:29:05] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:29:05] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:29:05] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:29:05] - INFO: ### batch_size = 10
[2022-08-12 11:29:05] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:29:05] - INFO: ### epochs = 5
[2022-08-12 11:29:05] - INFO: ### nums_labels = 5
[2022-08-12 11:29:05] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:29:05] - INFO: ### return_dict = True
[2022-08-12 11:29:05] - INFO: ### output_hidden_states = False
[2022-08-12 11:29:05] - INFO: ### output_attentions = False
[2022-08-12 11:29:05] - INFO: ### torchscript = False
[2022-08-12 11:29:05] - INFO: ### torch_dtype = None
[2022-08-12 11:29:05] - INFO: ### use_bfloat16 = False
[2022-08-12 11:29:05] - INFO: ### pruned_heads = {}
[2022-08-12 11:29:05] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:29:05] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:29:05] - INFO: ### is_decoder = False
[2022-08-12 11:29:05] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:29:05] - INFO: ### add_cross_attention = False
[2022-08-12 11:29:05] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:29:05] - INFO: ### max_length = 20
[2022-08-12 11:29:05] - INFO: ### min_length = 0
[2022-08-12 11:29:05] - INFO: ### do_sample = False
[2022-08-12 11:29:05] - INFO: ### early_stopping = False
[2022-08-12 11:29:05] - INFO: ### num_beams = 1
[2022-08-12 11:29:05] - INFO: ### num_beam_groups = 1
[2022-08-12 11:29:05] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:29:05] - INFO: ### temperature = 1.0
[2022-08-12 11:29:05] - INFO: ### top_k = 50
[2022-08-12 11:29:05] - INFO: ### top_p = 1.0
[2022-08-12 11:29:05] - INFO: ### typical_p = 1.0
[2022-08-12 11:29:05] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:29:05] - INFO: ### length_penalty = 1.0
[2022-08-12 11:29:05] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:29:05] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:29:05] - INFO: ### bad_words_ids = None
[2022-08-12 11:29:05] - INFO: ### num_return_sequences = 1
[2022-08-12 11:29:05] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:29:05] - INFO: ### output_scores = False
[2022-08-12 11:29:05] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:29:05] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:29:05] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:29:05] - INFO: ### remove_invalid_values = False
[2022-08-12 11:29:05] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:29:05] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:29:05] - INFO: ### finetuning_task = None
[2022-08-12 11:29:05] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:29:05] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:29:05] - INFO: ### tokenizer_class = None
[2022-08-12 11:29:05] - INFO: ### prefix = None
[2022-08-12 11:29:05] - INFO: ### bos_token_id = None
[2022-08-12 11:29:05] - INFO: ### pad_token_id = 0
[2022-08-12 11:29:05] - INFO: ### eos_token_id = None
[2022-08-12 11:29:05] - INFO: ### sep_token_id = None
[2022-08-12 11:29:05] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:29:05] - INFO: ### task_specific_params = None
[2022-08-12 11:29:05] - INFO: ### problem_type = None
[2022-08-12 11:29:05] - INFO: ### _name_or_path = 
[2022-08-12 11:29:05] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:29:05] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:29:05] - INFO: ### model_type = bert
[2022-08-12 11:29:05] - INFO: ### vocab_size = 30522
[2022-08-12 11:29:05] - INFO: ### hidden_size = 768
[2022-08-12 11:29:05] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:29:05] - INFO: ### num_attention_heads = 12
[2022-08-12 11:29:05] - INFO: ### hidden_act = gelu
[2022-08-12 11:29:05] - INFO: ### intermediate_size = 3072
[2022-08-12 11:29:05] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:29:05] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:29:05] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:29:05] - INFO: ### type_vocab_size = 2
[2022-08-12 11:29:05] - INFO: ### initializer_range = 0.02
[2022-08-12 11:29:05] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:29:05] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:29:05] - INFO: ### use_cache = True
[2022-08-12 11:29:05] - INFO: ### classifier_dropout = None
[2022-08-12 11:32:58] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:32:58] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:32:58] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:32:58] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:32:58] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:32:58] - INFO: ### device = cpu
[2022-08-12 11:32:58] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:32:58] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:32:58] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:32:58] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:32:58] - INFO: ### batch_size = 10
[2022-08-12 11:32:58] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:32:58] - INFO: ### epochs = 5
[2022-08-12 11:32:58] - INFO: ### nums_labels = 5
[2022-08-12 11:32:58] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:32:58] - INFO: ### return_dict = True
[2022-08-12 11:32:58] - INFO: ### output_hidden_states = False
[2022-08-12 11:32:58] - INFO: ### output_attentions = False
[2022-08-12 11:32:58] - INFO: ### torchscript = False
[2022-08-12 11:32:58] - INFO: ### torch_dtype = None
[2022-08-12 11:32:58] - INFO: ### use_bfloat16 = False
[2022-08-12 11:32:58] - INFO: ### pruned_heads = {}
[2022-08-12 11:32:58] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:32:58] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:32:58] - INFO: ### is_decoder = False
[2022-08-12 11:32:58] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:32:58] - INFO: ### add_cross_attention = False
[2022-08-12 11:32:58] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:32:58] - INFO: ### max_length = 20
[2022-08-12 11:32:58] - INFO: ### min_length = 0
[2022-08-12 11:32:58] - INFO: ### do_sample = False
[2022-08-12 11:32:58] - INFO: ### early_stopping = False
[2022-08-12 11:32:58] - INFO: ### num_beams = 1
[2022-08-12 11:32:58] - INFO: ### num_beam_groups = 1
[2022-08-12 11:32:58] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:32:58] - INFO: ### temperature = 1.0
[2022-08-12 11:32:58] - INFO: ### top_k = 50
[2022-08-12 11:32:58] - INFO: ### top_p = 1.0
[2022-08-12 11:32:58] - INFO: ### typical_p = 1.0
[2022-08-12 11:32:58] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:32:58] - INFO: ### length_penalty = 1.0
[2022-08-12 11:32:58] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:32:58] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:32:58] - INFO: ### bad_words_ids = None
[2022-08-12 11:32:58] - INFO: ### num_return_sequences = 1
[2022-08-12 11:32:58] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:32:58] - INFO: ### output_scores = False
[2022-08-12 11:32:58] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:32:58] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:32:58] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:32:58] - INFO: ### remove_invalid_values = False
[2022-08-12 11:32:58] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:32:58] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:32:58] - INFO: ### finetuning_task = None
[2022-08-12 11:32:58] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:32:58] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:32:58] - INFO: ### tokenizer_class = None
[2022-08-12 11:32:58] - INFO: ### prefix = None
[2022-08-12 11:32:58] - INFO: ### bos_token_id = None
[2022-08-12 11:32:58] - INFO: ### pad_token_id = 0
[2022-08-12 11:32:58] - INFO: ### eos_token_id = None
[2022-08-12 11:32:58] - INFO: ### sep_token_id = None
[2022-08-12 11:32:58] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:32:58] - INFO: ### task_specific_params = None
[2022-08-12 11:32:58] - INFO: ### problem_type = None
[2022-08-12 11:32:58] - INFO: ### _name_or_path = 
[2022-08-12 11:32:58] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:32:58] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:32:58] - INFO: ### model_type = bert
[2022-08-12 11:32:58] - INFO: ### vocab_size = 30522
[2022-08-12 11:32:58] - INFO: ### hidden_size = 768
[2022-08-12 11:32:58] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:32:58] - INFO: ### num_attention_heads = 12
[2022-08-12 11:32:58] - INFO: ### hidden_act = gelu
[2022-08-12 11:32:58] - INFO: ### intermediate_size = 3072
[2022-08-12 11:32:58] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:32:58] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:32:58] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:32:58] - INFO: ### type_vocab_size = 2
[2022-08-12 11:32:58] - INFO: ### initializer_range = 0.02
[2022-08-12 11:32:58] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:32:58] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:32:58] - INFO: ### use_cache = True
[2022-08-12 11:32:58] - INFO: ### classifier_dropout = None
[2022-08-12 11:34:24] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:34:24] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:34:24] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:34:24] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:34:24] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:34:24] - INFO: ### device = cpu
[2022-08-12 11:34:24] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:34:24] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:34:24] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:34:24] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:34:24] - INFO: ### batch_size = 10
[2022-08-12 11:34:24] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:34:24] - INFO: ### epochs = 5
[2022-08-12 11:34:24] - INFO: ### nums_labels = 5
[2022-08-12 11:34:24] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:34:24] - INFO: ### return_dict = True
[2022-08-12 11:34:24] - INFO: ### output_hidden_states = False
[2022-08-12 11:34:24] - INFO: ### output_attentions = False
[2022-08-12 11:34:24] - INFO: ### torchscript = False
[2022-08-12 11:34:24] - INFO: ### torch_dtype = None
[2022-08-12 11:34:24] - INFO: ### use_bfloat16 = False
[2022-08-12 11:34:24] - INFO: ### pruned_heads = {}
[2022-08-12 11:34:24] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:34:24] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:34:24] - INFO: ### is_decoder = False
[2022-08-12 11:34:24] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:34:24] - INFO: ### add_cross_attention = False
[2022-08-12 11:34:24] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:34:24] - INFO: ### max_length = 20
[2022-08-12 11:34:24] - INFO: ### min_length = 0
[2022-08-12 11:34:24] - INFO: ### do_sample = False
[2022-08-12 11:34:24] - INFO: ### early_stopping = False
[2022-08-12 11:34:24] - INFO: ### num_beams = 1
[2022-08-12 11:34:24] - INFO: ### num_beam_groups = 1
[2022-08-12 11:34:24] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:34:24] - INFO: ### temperature = 1.0
[2022-08-12 11:34:24] - INFO: ### top_k = 50
[2022-08-12 11:34:24] - INFO: ### top_p = 1.0
[2022-08-12 11:34:24] - INFO: ### typical_p = 1.0
[2022-08-12 11:34:24] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:34:24] - INFO: ### length_penalty = 1.0
[2022-08-12 11:34:24] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:34:24] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:34:24] - INFO: ### bad_words_ids = None
[2022-08-12 11:34:24] - INFO: ### num_return_sequences = 1
[2022-08-12 11:34:24] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:34:24] - INFO: ### output_scores = False
[2022-08-12 11:34:24] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:34:24] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:34:24] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:34:24] - INFO: ### remove_invalid_values = False
[2022-08-12 11:34:24] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:34:24] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:34:24] - INFO: ### finetuning_task = None
[2022-08-12 11:34:24] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:34:24] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:34:24] - INFO: ### tokenizer_class = None
[2022-08-12 11:34:24] - INFO: ### prefix = None
[2022-08-12 11:34:24] - INFO: ### bos_token_id = None
[2022-08-12 11:34:24] - INFO: ### pad_token_id = 0
[2022-08-12 11:34:24] - INFO: ### eos_token_id = None
[2022-08-12 11:34:24] - INFO: ### sep_token_id = None
[2022-08-12 11:34:24] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:34:24] - INFO: ### task_specific_params = None
[2022-08-12 11:34:24] - INFO: ### problem_type = None
[2022-08-12 11:34:24] - INFO: ### _name_or_path = 
[2022-08-12 11:34:24] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:34:24] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:34:24] - INFO: ### model_type = bert
[2022-08-12 11:34:24] - INFO: ### vocab_size = 30522
[2022-08-12 11:34:24] - INFO: ### hidden_size = 768
[2022-08-12 11:34:24] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:34:24] - INFO: ### num_attention_heads = 12
[2022-08-12 11:34:24] - INFO: ### hidden_act = gelu
[2022-08-12 11:34:24] - INFO: ### intermediate_size = 3072
[2022-08-12 11:34:24] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:34:24] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:34:24] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:34:24] - INFO: ### type_vocab_size = 2
[2022-08-12 11:34:24] - INFO: ### initializer_range = 0.02
[2022-08-12 11:34:24] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:34:24] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:34:24] - INFO: ### use_cache = True
[2022-08-12 11:34:24] - INFO: ### classifier_dropout = None
[2022-08-12 11:38:24] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:38:24] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:38:24] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:38:24] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:38:24] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:38:24] - INFO: ### device = cpu
[2022-08-12 11:38:24] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:38:24] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:38:24] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:38:24] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:38:24] - INFO: ### batch_size = 10
[2022-08-12 11:38:24] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:38:24] - INFO: ### epochs = 5
[2022-08-12 11:38:24] - INFO: ### nums_labels = 5
[2022-08-12 11:38:24] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:38:24] - INFO: ### return_dict = True
[2022-08-12 11:38:24] - INFO: ### output_hidden_states = False
[2022-08-12 11:38:24] - INFO: ### output_attentions = False
[2022-08-12 11:38:24] - INFO: ### torchscript = False
[2022-08-12 11:38:24] - INFO: ### torch_dtype = None
[2022-08-12 11:38:24] - INFO: ### use_bfloat16 = False
[2022-08-12 11:38:24] - INFO: ### pruned_heads = {}
[2022-08-12 11:38:24] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:38:24] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:38:24] - INFO: ### is_decoder = False
[2022-08-12 11:38:24] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:38:24] - INFO: ### add_cross_attention = False
[2022-08-12 11:38:24] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:38:24] - INFO: ### max_length = 20
[2022-08-12 11:38:24] - INFO: ### min_length = 0
[2022-08-12 11:38:24] - INFO: ### do_sample = False
[2022-08-12 11:38:24] - INFO: ### early_stopping = False
[2022-08-12 11:38:24] - INFO: ### num_beams = 1
[2022-08-12 11:38:24] - INFO: ### num_beam_groups = 1
[2022-08-12 11:38:24] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:38:24] - INFO: ### temperature = 1.0
[2022-08-12 11:38:24] - INFO: ### top_k = 50
[2022-08-12 11:38:24] - INFO: ### top_p = 1.0
[2022-08-12 11:38:24] - INFO: ### typical_p = 1.0
[2022-08-12 11:38:24] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:38:24] - INFO: ### length_penalty = 1.0
[2022-08-12 11:38:24] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:38:24] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:38:24] - INFO: ### bad_words_ids = None
[2022-08-12 11:38:24] - INFO: ### num_return_sequences = 1
[2022-08-12 11:38:24] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:38:24] - INFO: ### output_scores = False
[2022-08-12 11:38:24] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:38:24] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:38:24] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:38:24] - INFO: ### remove_invalid_values = False
[2022-08-12 11:38:24] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:38:24] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:38:24] - INFO: ### finetuning_task = None
[2022-08-12 11:38:24] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:38:24] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:38:24] - INFO: ### tokenizer_class = None
[2022-08-12 11:38:24] - INFO: ### prefix = None
[2022-08-12 11:38:24] - INFO: ### bos_token_id = None
[2022-08-12 11:38:24] - INFO: ### pad_token_id = 0
[2022-08-12 11:38:24] - INFO: ### eos_token_id = None
[2022-08-12 11:38:24] - INFO: ### sep_token_id = None
[2022-08-12 11:38:24] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:38:24] - INFO: ### task_specific_params = None
[2022-08-12 11:38:24] - INFO: ### problem_type = None
[2022-08-12 11:38:24] - INFO: ### _name_or_path = 
[2022-08-12 11:38:24] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:38:24] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:38:24] - INFO: ### model_type = bert
[2022-08-12 11:38:24] - INFO: ### vocab_size = 30522
[2022-08-12 11:38:24] - INFO: ### hidden_size = 768
[2022-08-12 11:38:24] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:38:24] - INFO: ### num_attention_heads = 12
[2022-08-12 11:38:24] - INFO: ### hidden_act = gelu
[2022-08-12 11:38:24] - INFO: ### intermediate_size = 3072
[2022-08-12 11:38:24] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:38:24] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:38:24] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:38:24] - INFO: ### type_vocab_size = 2
[2022-08-12 11:38:24] - INFO: ### initializer_range = 0.02
[2022-08-12 11:38:24] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:38:24] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:38:24] - INFO: ### use_cache = True
[2022-08-12 11:38:24] - INFO: ### classifier_dropout = None
[2022-08-12 11:40:10] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:40:10] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:40:10] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:40:10] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:40:10] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:40:10] - INFO: ### device = cpu
[2022-08-12 11:40:10] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:40:10] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:40:10] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:40:10] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:40:10] - INFO: ### batch_size = 10
[2022-08-12 11:40:10] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:40:10] - INFO: ### epochs = 5
[2022-08-12 11:40:10] - INFO: ### nums_labels = 5
[2022-08-12 11:40:10] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:40:10] - INFO: ### return_dict = True
[2022-08-12 11:40:10] - INFO: ### output_hidden_states = False
[2022-08-12 11:40:10] - INFO: ### output_attentions = False
[2022-08-12 11:40:10] - INFO: ### torchscript = False
[2022-08-12 11:40:10] - INFO: ### torch_dtype = None
[2022-08-12 11:40:10] - INFO: ### use_bfloat16 = False
[2022-08-12 11:40:10] - INFO: ### pruned_heads = {}
[2022-08-12 11:40:10] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:40:10] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:40:10] - INFO: ### is_decoder = False
[2022-08-12 11:40:10] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:40:10] - INFO: ### add_cross_attention = False
[2022-08-12 11:40:10] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:40:10] - INFO: ### max_length = 20
[2022-08-12 11:40:10] - INFO: ### min_length = 0
[2022-08-12 11:40:10] - INFO: ### do_sample = False
[2022-08-12 11:40:10] - INFO: ### early_stopping = False
[2022-08-12 11:40:10] - INFO: ### num_beams = 1
[2022-08-12 11:40:10] - INFO: ### num_beam_groups = 1
[2022-08-12 11:40:10] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:40:10] - INFO: ### temperature = 1.0
[2022-08-12 11:40:10] - INFO: ### top_k = 50
[2022-08-12 11:40:10] - INFO: ### top_p = 1.0
[2022-08-12 11:40:10] - INFO: ### typical_p = 1.0
[2022-08-12 11:40:10] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:40:10] - INFO: ### length_penalty = 1.0
[2022-08-12 11:40:10] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:40:10] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:40:10] - INFO: ### bad_words_ids = None
[2022-08-12 11:40:10] - INFO: ### num_return_sequences = 1
[2022-08-12 11:40:10] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:40:10] - INFO: ### output_scores = False
[2022-08-12 11:40:10] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:40:10] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:40:10] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:40:10] - INFO: ### remove_invalid_values = False
[2022-08-12 11:40:10] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:40:10] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:40:10] - INFO: ### finetuning_task = None
[2022-08-12 11:40:10] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:40:10] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:40:10] - INFO: ### tokenizer_class = None
[2022-08-12 11:40:10] - INFO: ### prefix = None
[2022-08-12 11:40:10] - INFO: ### bos_token_id = None
[2022-08-12 11:40:10] - INFO: ### pad_token_id = 0
[2022-08-12 11:40:10] - INFO: ### eos_token_id = None
[2022-08-12 11:40:10] - INFO: ### sep_token_id = None
[2022-08-12 11:40:10] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:40:10] - INFO: ### task_specific_params = None
[2022-08-12 11:40:10] - INFO: ### problem_type = None
[2022-08-12 11:40:10] - INFO: ### _name_or_path = 
[2022-08-12 11:40:10] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:40:10] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:40:10] - INFO: ### model_type = bert
[2022-08-12 11:40:10] - INFO: ### vocab_size = 30522
[2022-08-12 11:40:10] - INFO: ### hidden_size = 768
[2022-08-12 11:40:10] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:40:10] - INFO: ### num_attention_heads = 12
[2022-08-12 11:40:10] - INFO: ### hidden_act = gelu
[2022-08-12 11:40:10] - INFO: ### intermediate_size = 3072
[2022-08-12 11:40:10] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:40:10] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:40:10] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:40:10] - INFO: ### type_vocab_size = 2
[2022-08-12 11:40:10] - INFO: ### initializer_range = 0.02
[2022-08-12 11:40:10] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:40:10] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:40:10] - INFO: ### use_cache = True
[2022-08-12 11:40:10] - INFO: ### classifier_dropout = None
[2022-08-12 11:41:05] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:41:05] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:41:05] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:41:05] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:41:05] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:41:05] - INFO: ### device = cpu
[2022-08-12 11:41:05] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:41:05] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:41:05] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:41:05] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:41:05] - INFO: ### batch_size = 10
[2022-08-12 11:41:05] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:41:05] - INFO: ### epochs = 5
[2022-08-12 11:41:05] - INFO: ### nums_labels = 5
[2022-08-12 11:41:05] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:41:05] - INFO: ### return_dict = True
[2022-08-12 11:41:05] - INFO: ### output_hidden_states = False
[2022-08-12 11:41:05] - INFO: ### output_attentions = False
[2022-08-12 11:41:05] - INFO: ### torchscript = False
[2022-08-12 11:41:05] - INFO: ### torch_dtype = None
[2022-08-12 11:41:05] - INFO: ### use_bfloat16 = False
[2022-08-12 11:41:05] - INFO: ### pruned_heads = {}
[2022-08-12 11:41:05] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:41:05] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:41:05] - INFO: ### is_decoder = False
[2022-08-12 11:41:05] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:41:05] - INFO: ### add_cross_attention = False
[2022-08-12 11:41:05] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:41:05] - INFO: ### max_length = 20
[2022-08-12 11:41:05] - INFO: ### min_length = 0
[2022-08-12 11:41:05] - INFO: ### do_sample = False
[2022-08-12 11:41:05] - INFO: ### early_stopping = False
[2022-08-12 11:41:05] - INFO: ### num_beams = 1
[2022-08-12 11:41:05] - INFO: ### num_beam_groups = 1
[2022-08-12 11:41:05] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:41:05] - INFO: ### temperature = 1.0
[2022-08-12 11:41:05] - INFO: ### top_k = 50
[2022-08-12 11:41:05] - INFO: ### top_p = 1.0
[2022-08-12 11:41:05] - INFO: ### typical_p = 1.0
[2022-08-12 11:41:05] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:41:05] - INFO: ### length_penalty = 1.0
[2022-08-12 11:41:05] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:41:05] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:41:05] - INFO: ### bad_words_ids = None
[2022-08-12 11:41:05] - INFO: ### num_return_sequences = 1
[2022-08-12 11:41:05] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:41:05] - INFO: ### output_scores = False
[2022-08-12 11:41:05] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:41:05] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:41:05] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:41:05] - INFO: ### remove_invalid_values = False
[2022-08-12 11:41:05] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:41:05] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:41:05] - INFO: ### finetuning_task = None
[2022-08-12 11:41:05] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:41:05] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:41:05] - INFO: ### tokenizer_class = None
[2022-08-12 11:41:05] - INFO: ### prefix = None
[2022-08-12 11:41:05] - INFO: ### bos_token_id = None
[2022-08-12 11:41:05] - INFO: ### pad_token_id = 0
[2022-08-12 11:41:05] - INFO: ### eos_token_id = None
[2022-08-12 11:41:05] - INFO: ### sep_token_id = None
[2022-08-12 11:41:05] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:41:05] - INFO: ### task_specific_params = None
[2022-08-12 11:41:05] - INFO: ### problem_type = None
[2022-08-12 11:41:05] - INFO: ### _name_or_path = 
[2022-08-12 11:41:05] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:41:05] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:41:05] - INFO: ### model_type = bert
[2022-08-12 11:41:05] - INFO: ### vocab_size = 30522
[2022-08-12 11:41:05] - INFO: ### hidden_size = 768
[2022-08-12 11:41:05] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:41:05] - INFO: ### num_attention_heads = 12
[2022-08-12 11:41:05] - INFO: ### hidden_act = gelu
[2022-08-12 11:41:05] - INFO: ### intermediate_size = 3072
[2022-08-12 11:41:05] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:41:05] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:41:05] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:41:05] - INFO: ### type_vocab_size = 2
[2022-08-12 11:41:05] - INFO: ### initializer_range = 0.02
[2022-08-12 11:41:05] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:41:05] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:41:05] - INFO: ### use_cache = True
[2022-08-12 11:41:05] - INFO: ### classifier_dropout = None
[2022-08-12 11:42:17] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:42:17] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:42:17] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:42:17] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:42:17] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:42:17] - INFO: ### device = cpu
[2022-08-12 11:42:17] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:42:17] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:42:17] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:42:17] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:42:17] - INFO: ### batch_size = 10
[2022-08-12 11:42:17] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:42:17] - INFO: ### epochs = 5
[2022-08-12 11:42:17] - INFO: ### nums_labels = 5
[2022-08-12 11:42:17] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:42:17] - INFO: ### return_dict = True
[2022-08-12 11:42:17] - INFO: ### output_hidden_states = False
[2022-08-12 11:42:17] - INFO: ### output_attentions = False
[2022-08-12 11:42:17] - INFO: ### torchscript = False
[2022-08-12 11:42:17] - INFO: ### torch_dtype = None
[2022-08-12 11:42:17] - INFO: ### use_bfloat16 = False
[2022-08-12 11:42:17] - INFO: ### pruned_heads = {}
[2022-08-12 11:42:17] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:42:17] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:42:17] - INFO: ### is_decoder = False
[2022-08-12 11:42:17] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:42:17] - INFO: ### add_cross_attention = False
[2022-08-12 11:42:17] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:42:17] - INFO: ### max_length = 20
[2022-08-12 11:42:17] - INFO: ### min_length = 0
[2022-08-12 11:42:17] - INFO: ### do_sample = False
[2022-08-12 11:42:17] - INFO: ### early_stopping = False
[2022-08-12 11:42:17] - INFO: ### num_beams = 1
[2022-08-12 11:42:17] - INFO: ### num_beam_groups = 1
[2022-08-12 11:42:17] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:42:17] - INFO: ### temperature = 1.0
[2022-08-12 11:42:17] - INFO: ### top_k = 50
[2022-08-12 11:42:17] - INFO: ### top_p = 1.0
[2022-08-12 11:42:17] - INFO: ### typical_p = 1.0
[2022-08-12 11:42:17] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:42:17] - INFO: ### length_penalty = 1.0
[2022-08-12 11:42:17] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:42:17] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:42:17] - INFO: ### bad_words_ids = None
[2022-08-12 11:42:17] - INFO: ### num_return_sequences = 1
[2022-08-12 11:42:17] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:42:17] - INFO: ### output_scores = False
[2022-08-12 11:42:17] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:42:17] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:42:17] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:42:17] - INFO: ### remove_invalid_values = False
[2022-08-12 11:42:17] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:42:17] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:42:17] - INFO: ### finetuning_task = None
[2022-08-12 11:42:17] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:42:17] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:42:17] - INFO: ### tokenizer_class = None
[2022-08-12 11:42:17] - INFO: ### prefix = None
[2022-08-12 11:42:17] - INFO: ### bos_token_id = None
[2022-08-12 11:42:17] - INFO: ### pad_token_id = 0
[2022-08-12 11:42:17] - INFO: ### eos_token_id = None
[2022-08-12 11:42:17] - INFO: ### sep_token_id = None
[2022-08-12 11:42:17] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:42:17] - INFO: ### task_specific_params = None
[2022-08-12 11:42:17] - INFO: ### problem_type = None
[2022-08-12 11:42:17] - INFO: ### _name_or_path = 
[2022-08-12 11:42:17] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:42:17] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:42:17] - INFO: ### model_type = bert
[2022-08-12 11:42:17] - INFO: ### vocab_size = 30522
[2022-08-12 11:42:17] - INFO: ### hidden_size = 768
[2022-08-12 11:42:17] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:42:17] - INFO: ### num_attention_heads = 12
[2022-08-12 11:42:17] - INFO: ### hidden_act = gelu
[2022-08-12 11:42:17] - INFO: ### intermediate_size = 3072
[2022-08-12 11:42:17] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:42:17] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:42:17] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:42:17] - INFO: ### type_vocab_size = 2
[2022-08-12 11:42:17] - INFO: ### initializer_range = 0.02
[2022-08-12 11:42:17] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:42:17] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:42:17] - INFO: ### use_cache = True
[2022-08-12 11:42:17] - INFO: ### classifier_dropout = None
[2022-08-12 11:49:03] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:49:03] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:49:03] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:49:03] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:49:03] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:49:03] - INFO: ### device = cpu
[2022-08-12 11:49:03] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:49:03] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:49:03] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:49:03] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:49:03] - INFO: ### batch_size = 10
[2022-08-12 11:49:03] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:49:03] - INFO: ### epochs = 5
[2022-08-12 11:49:03] - INFO: ### nums_labels = 5
[2022-08-12 11:49:03] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:49:03] - INFO: ### return_dict = True
[2022-08-12 11:49:03] - INFO: ### output_hidden_states = False
[2022-08-12 11:49:03] - INFO: ### output_attentions = False
[2022-08-12 11:49:03] - INFO: ### torchscript = False
[2022-08-12 11:49:03] - INFO: ### torch_dtype = None
[2022-08-12 11:49:03] - INFO: ### use_bfloat16 = False
[2022-08-12 11:49:03] - INFO: ### pruned_heads = {}
[2022-08-12 11:49:03] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:49:03] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:49:03] - INFO: ### is_decoder = False
[2022-08-12 11:49:03] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:49:03] - INFO: ### add_cross_attention = False
[2022-08-12 11:49:03] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:49:03] - INFO: ### max_length = 20
[2022-08-12 11:49:03] - INFO: ### min_length = 0
[2022-08-12 11:49:03] - INFO: ### do_sample = False
[2022-08-12 11:49:03] - INFO: ### early_stopping = False
[2022-08-12 11:49:03] - INFO: ### num_beams = 1
[2022-08-12 11:49:03] - INFO: ### num_beam_groups = 1
[2022-08-12 11:49:03] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:49:03] - INFO: ### temperature = 1.0
[2022-08-12 11:49:03] - INFO: ### top_k = 50
[2022-08-12 11:49:03] - INFO: ### top_p = 1.0
[2022-08-12 11:49:03] - INFO: ### typical_p = 1.0
[2022-08-12 11:49:03] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:49:03] - INFO: ### length_penalty = 1.0
[2022-08-12 11:49:03] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:49:03] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:49:03] - INFO: ### bad_words_ids = None
[2022-08-12 11:49:03] - INFO: ### num_return_sequences = 1
[2022-08-12 11:49:03] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:49:03] - INFO: ### output_scores = False
[2022-08-12 11:49:03] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:49:03] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:49:03] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:49:03] - INFO: ### remove_invalid_values = False
[2022-08-12 11:49:03] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:49:03] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:49:03] - INFO: ### finetuning_task = None
[2022-08-12 11:49:03] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:49:03] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:49:03] - INFO: ### tokenizer_class = None
[2022-08-12 11:49:03] - INFO: ### prefix = None
[2022-08-12 11:49:03] - INFO: ### bos_token_id = None
[2022-08-12 11:49:03] - INFO: ### pad_token_id = 0
[2022-08-12 11:49:03] - INFO: ### eos_token_id = None
[2022-08-12 11:49:03] - INFO: ### sep_token_id = None
[2022-08-12 11:49:03] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:49:03] - INFO: ### task_specific_params = None
[2022-08-12 11:49:03] - INFO: ### problem_type = None
[2022-08-12 11:49:03] - INFO: ### _name_or_path = 
[2022-08-12 11:49:03] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:49:03] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:49:03] - INFO: ### model_type = bert
[2022-08-12 11:49:03] - INFO: ### vocab_size = 30522
[2022-08-12 11:49:03] - INFO: ### hidden_size = 768
[2022-08-12 11:49:03] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:49:03] - INFO: ### num_attention_heads = 12
[2022-08-12 11:49:03] - INFO: ### hidden_act = gelu
[2022-08-12 11:49:03] - INFO: ### intermediate_size = 3072
[2022-08-12 11:49:03] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:49:03] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:49:03] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:49:03] - INFO: ### type_vocab_size = 2
[2022-08-12 11:49:03] - INFO: ### initializer_range = 0.02
[2022-08-12 11:49:03] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:49:03] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:49:03] - INFO: ### use_cache = True
[2022-08-12 11:49:03] - INFO: ### classifier_dropout = None
[2022-08-12 11:52:43] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:52:43] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:52:43] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:52:43] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:52:43] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:52:43] - INFO: ### device = cpu
[2022-08-12 11:52:43] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:52:43] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:52:43] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:52:43] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:52:43] - INFO: ### batch_size = 10
[2022-08-12 11:52:43] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:52:43] - INFO: ### epochs = 5
[2022-08-12 11:52:43] - INFO: ### nums_labels = 5
[2022-08-12 11:52:43] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:52:43] - INFO: ### return_dict = True
[2022-08-12 11:52:43] - INFO: ### output_hidden_states = False
[2022-08-12 11:52:43] - INFO: ### output_attentions = False
[2022-08-12 11:52:43] - INFO: ### torchscript = False
[2022-08-12 11:52:43] - INFO: ### torch_dtype = None
[2022-08-12 11:52:43] - INFO: ### use_bfloat16 = False
[2022-08-12 11:52:43] - INFO: ### pruned_heads = {}
[2022-08-12 11:52:43] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:52:43] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:52:43] - INFO: ### is_decoder = False
[2022-08-12 11:52:43] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:52:43] - INFO: ### add_cross_attention = False
[2022-08-12 11:52:43] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:52:43] - INFO: ### max_length = 20
[2022-08-12 11:52:43] - INFO: ### min_length = 0
[2022-08-12 11:52:43] - INFO: ### do_sample = False
[2022-08-12 11:52:43] - INFO: ### early_stopping = False
[2022-08-12 11:52:43] - INFO: ### num_beams = 1
[2022-08-12 11:52:43] - INFO: ### num_beam_groups = 1
[2022-08-12 11:52:43] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:52:43] - INFO: ### temperature = 1.0
[2022-08-12 11:52:43] - INFO: ### top_k = 50
[2022-08-12 11:52:43] - INFO: ### top_p = 1.0
[2022-08-12 11:52:43] - INFO: ### typical_p = 1.0
[2022-08-12 11:52:43] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:52:43] - INFO: ### length_penalty = 1.0
[2022-08-12 11:52:43] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:52:43] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:52:43] - INFO: ### bad_words_ids = None
[2022-08-12 11:52:43] - INFO: ### num_return_sequences = 1
[2022-08-12 11:52:43] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:52:43] - INFO: ### output_scores = False
[2022-08-12 11:52:43] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:52:43] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:52:43] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:52:43] - INFO: ### remove_invalid_values = False
[2022-08-12 11:52:43] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:52:43] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:52:43] - INFO: ### finetuning_task = None
[2022-08-12 11:52:43] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:52:43] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:52:43] - INFO: ### tokenizer_class = None
[2022-08-12 11:52:43] - INFO: ### prefix = None
[2022-08-12 11:52:43] - INFO: ### bos_token_id = None
[2022-08-12 11:52:43] - INFO: ### pad_token_id = 0
[2022-08-12 11:52:43] - INFO: ### eos_token_id = None
[2022-08-12 11:52:43] - INFO: ### sep_token_id = None
[2022-08-12 11:52:43] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:52:43] - INFO: ### task_specific_params = None
[2022-08-12 11:52:43] - INFO: ### problem_type = None
[2022-08-12 11:52:43] - INFO: ### _name_or_path = 
[2022-08-12 11:52:43] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:52:43] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:52:43] - INFO: ### model_type = bert
[2022-08-12 11:52:43] - INFO: ### vocab_size = 30522
[2022-08-12 11:52:43] - INFO: ### hidden_size = 768
[2022-08-12 11:52:43] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:52:43] - INFO: ### num_attention_heads = 12
[2022-08-12 11:52:43] - INFO: ### hidden_act = gelu
[2022-08-12 11:52:43] - INFO: ### intermediate_size = 3072
[2022-08-12 11:52:43] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:52:43] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:52:43] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:52:43] - INFO: ### type_vocab_size = 2
[2022-08-12 11:52:43] - INFO: ### initializer_range = 0.02
[2022-08-12 11:52:43] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:52:43] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:52:43] - INFO: ### use_cache = True
[2022-08-12 11:52:43] - INFO: ### classifier_dropout = None
[2022-08-12 11:54:20] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 11:54:20] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 11:54:20] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 11:54:20] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 11:54:20] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 11:54:20] - INFO: ### device = cpu
[2022-08-12 11:54:20] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 11:54:20] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 11:54:20] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 11:54:20] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 11:54:20] - INFO: ### batch_size = 10
[2022-08-12 11:54:20] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 11:54:20] - INFO: ### epochs = 5
[2022-08-12 11:54:20] - INFO: ### nums_labels = 5
[2022-08-12 11:54:20] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 11:54:20] - INFO: ### return_dict = True
[2022-08-12 11:54:20] - INFO: ### output_hidden_states = False
[2022-08-12 11:54:20] - INFO: ### output_attentions = False
[2022-08-12 11:54:20] - INFO: ### torchscript = False
[2022-08-12 11:54:20] - INFO: ### torch_dtype = None
[2022-08-12 11:54:20] - INFO: ### use_bfloat16 = False
[2022-08-12 11:54:20] - INFO: ### pruned_heads = {}
[2022-08-12 11:54:20] - INFO: ### tie_word_embeddings = True
[2022-08-12 11:54:20] - INFO: ### is_encoder_decoder = False
[2022-08-12 11:54:20] - INFO: ### is_decoder = False
[2022-08-12 11:54:20] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 11:54:20] - INFO: ### add_cross_attention = False
[2022-08-12 11:54:20] - INFO: ### tie_encoder_decoder = False
[2022-08-12 11:54:20] - INFO: ### max_length = 20
[2022-08-12 11:54:20] - INFO: ### min_length = 0
[2022-08-12 11:54:20] - INFO: ### do_sample = False
[2022-08-12 11:54:20] - INFO: ### early_stopping = False
[2022-08-12 11:54:20] - INFO: ### num_beams = 1
[2022-08-12 11:54:20] - INFO: ### num_beam_groups = 1
[2022-08-12 11:54:20] - INFO: ### diversity_penalty = 0.0
[2022-08-12 11:54:20] - INFO: ### temperature = 1.0
[2022-08-12 11:54:20] - INFO: ### top_k = 50
[2022-08-12 11:54:20] - INFO: ### top_p = 1.0
[2022-08-12 11:54:20] - INFO: ### typical_p = 1.0
[2022-08-12 11:54:20] - INFO: ### repetition_penalty = 1.0
[2022-08-12 11:54:20] - INFO: ### length_penalty = 1.0
[2022-08-12 11:54:20] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 11:54:20] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 11:54:20] - INFO: ### bad_words_ids = None
[2022-08-12 11:54:20] - INFO: ### num_return_sequences = 1
[2022-08-12 11:54:20] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 11:54:20] - INFO: ### output_scores = False
[2022-08-12 11:54:20] - INFO: ### return_dict_in_generate = False
[2022-08-12 11:54:20] - INFO: ### forced_bos_token_id = None
[2022-08-12 11:54:20] - INFO: ### forced_eos_token_id = None
[2022-08-12 11:54:20] - INFO: ### remove_invalid_values = False
[2022-08-12 11:54:20] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 11:54:20] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 11:54:20] - INFO: ### finetuning_task = None
[2022-08-12 11:54:20] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 11:54:20] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 11:54:20] - INFO: ### tokenizer_class = None
[2022-08-12 11:54:20] - INFO: ### prefix = None
[2022-08-12 11:54:20] - INFO: ### bos_token_id = None
[2022-08-12 11:54:20] - INFO: ### pad_token_id = 0
[2022-08-12 11:54:20] - INFO: ### eos_token_id = None
[2022-08-12 11:54:20] - INFO: ### sep_token_id = None
[2022-08-12 11:54:20] - INFO: ### decoder_start_token_id = None
[2022-08-12 11:54:20] - INFO: ### task_specific_params = None
[2022-08-12 11:54:20] - INFO: ### problem_type = None
[2022-08-12 11:54:20] - INFO: ### _name_or_path = 
[2022-08-12 11:54:20] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 11:54:20] - INFO: ### gradient_checkpointing = False
[2022-08-12 11:54:20] - INFO: ### model_type = bert
[2022-08-12 11:54:20] - INFO: ### vocab_size = 30522
[2022-08-12 11:54:20] - INFO: ### hidden_size = 768
[2022-08-12 11:54:20] - INFO: ### num_hidden_layers = 12
[2022-08-12 11:54:20] - INFO: ### num_attention_heads = 12
[2022-08-12 11:54:20] - INFO: ### hidden_act = gelu
[2022-08-12 11:54:20] - INFO: ### intermediate_size = 3072
[2022-08-12 11:54:20] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 11:54:20] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 11:54:20] - INFO: ### max_position_embeddings = 512
[2022-08-12 11:54:20] - INFO: ### type_vocab_size = 2
[2022-08-12 11:54:20] - INFO: ### initializer_range = 0.02
[2022-08-12 11:54:20] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 11:54:20] - INFO: ### position_embedding_type = absolute
[2022-08-12 11:54:20] - INFO: ### use_cache = True
[2022-08-12 11:54:20] - INFO: ### classifier_dropout = None
[2022-08-12 12:25:53] - INFO:  ### 将当前配置打印到日志文件中 
[2022-08-12 12:25:53] - INFO: ### project_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification
[2022-08-12 12:25:53] - INFO: ### dataset_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/data
[2022-08-12 12:25:53] - INFO: ### pretrained_model_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased
[2022-08-12 12:25:53] - INFO: ### vocab_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/bert_base_uncased/vocab.txt
[2022-08-12 12:25:53] - INFO: ### device = cpu
[2022-08-12 12:25:53] - INFO: ### train_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Train.csv
[2022-08-12 12:25:53] - INFO: ### test_file_path = /Users/liangyan/PycharmProjects/BBCNewsClassification/data/BBC News Test.csv
[2022-08-12 12:25:53] - INFO: ### model_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/cache
[2022-08-12 12:25:53] - INFO: ### logs_save_dir = /Users/liangyan/PycharmProjects/BBCNewsClassification/logs
[2022-08-12 12:25:53] - INFO: ### batch_size = 10
[2022-08-12 12:25:53] - INFO: ### learning_rate = 3.5e-05
[2022-08-12 12:25:53] - INFO: ### epochs = 5
[2022-08-12 12:25:53] - INFO: ### nums_labels = 5
[2022-08-12 12:25:53] - INFO: ### labels = ['business', 'entertainment', 'sport', 'tech', 'politics']
[2022-08-12 12:25:53] - INFO: ### return_dict = True
[2022-08-12 12:25:53] - INFO: ### output_hidden_states = False
[2022-08-12 12:25:53] - INFO: ### output_attentions = False
[2022-08-12 12:25:53] - INFO: ### torchscript = False
[2022-08-12 12:25:53] - INFO: ### torch_dtype = None
[2022-08-12 12:25:53] - INFO: ### use_bfloat16 = False
[2022-08-12 12:25:53] - INFO: ### pruned_heads = {}
[2022-08-12 12:25:53] - INFO: ### tie_word_embeddings = True
[2022-08-12 12:25:53] - INFO: ### is_encoder_decoder = False
[2022-08-12 12:25:53] - INFO: ### is_decoder = False
[2022-08-12 12:25:53] - INFO: ### cross_attention_hidden_size = None
[2022-08-12 12:25:53] - INFO: ### add_cross_attention = False
[2022-08-12 12:25:53] - INFO: ### tie_encoder_decoder = False
[2022-08-12 12:25:53] - INFO: ### max_length = 20
[2022-08-12 12:25:53] - INFO: ### min_length = 0
[2022-08-12 12:25:53] - INFO: ### do_sample = False
[2022-08-12 12:25:53] - INFO: ### early_stopping = False
[2022-08-12 12:25:53] - INFO: ### num_beams = 1
[2022-08-12 12:25:53] - INFO: ### num_beam_groups = 1
[2022-08-12 12:25:53] - INFO: ### diversity_penalty = 0.0
[2022-08-12 12:25:53] - INFO: ### temperature = 1.0
[2022-08-12 12:25:53] - INFO: ### top_k = 50
[2022-08-12 12:25:53] - INFO: ### top_p = 1.0
[2022-08-12 12:25:53] - INFO: ### typical_p = 1.0
[2022-08-12 12:25:53] - INFO: ### repetition_penalty = 1.0
[2022-08-12 12:25:53] - INFO: ### length_penalty = 1.0
[2022-08-12 12:25:53] - INFO: ### no_repeat_ngram_size = 0
[2022-08-12 12:25:53] - INFO: ### encoder_no_repeat_ngram_size = 0
[2022-08-12 12:25:53] - INFO: ### bad_words_ids = None
[2022-08-12 12:25:53] - INFO: ### num_return_sequences = 1
[2022-08-12 12:25:53] - INFO: ### chunk_size_feed_forward = 0
[2022-08-12 12:25:53] - INFO: ### output_scores = False
[2022-08-12 12:25:53] - INFO: ### return_dict_in_generate = False
[2022-08-12 12:25:53] - INFO: ### forced_bos_token_id = None
[2022-08-12 12:25:53] - INFO: ### forced_eos_token_id = None
[2022-08-12 12:25:53] - INFO: ### remove_invalid_values = False
[2022-08-12 12:25:53] - INFO: ### exponential_decay_length_penalty = None
[2022-08-12 12:25:53] - INFO: ### architectures = ['BertForMaskedLM']
[2022-08-12 12:25:53] - INFO: ### finetuning_task = None
[2022-08-12 12:25:53] - INFO: ### id2label = {0: 'LABEL_0', 1: 'LABEL_1'}
[2022-08-12 12:25:53] - INFO: ### label2id = {'LABEL_0': 0, 'LABEL_1': 1}
[2022-08-12 12:25:53] - INFO: ### tokenizer_class = None
[2022-08-12 12:25:53] - INFO: ### prefix = None
[2022-08-12 12:25:53] - INFO: ### bos_token_id = None
[2022-08-12 12:25:53] - INFO: ### pad_token_id = 0
[2022-08-12 12:25:53] - INFO: ### eos_token_id = None
[2022-08-12 12:25:53] - INFO: ### sep_token_id = None
[2022-08-12 12:25:53] - INFO: ### decoder_start_token_id = None
[2022-08-12 12:25:53] - INFO: ### task_specific_params = None
[2022-08-12 12:25:53] - INFO: ### problem_type = None
[2022-08-12 12:25:53] - INFO: ### _name_or_path = 
[2022-08-12 12:25:53] - INFO: ### transformers_version = 4.6.0.dev0
[2022-08-12 12:25:53] - INFO: ### gradient_checkpointing = False
[2022-08-12 12:25:53] - INFO: ### model_type = bert
[2022-08-12 12:25:53] - INFO: ### vocab_size = 30522
[2022-08-12 12:25:53] - INFO: ### hidden_size = 768
[2022-08-12 12:25:53] - INFO: ### num_hidden_layers = 12
[2022-08-12 12:25:53] - INFO: ### num_attention_heads = 12
[2022-08-12 12:25:53] - INFO: ### hidden_act = gelu
[2022-08-12 12:25:53] - INFO: ### intermediate_size = 3072
[2022-08-12 12:25:53] - INFO: ### hidden_dropout_prob = 0.1
[2022-08-12 12:25:53] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-08-12 12:25:53] - INFO: ### max_position_embeddings = 512
[2022-08-12 12:25:53] - INFO: ### type_vocab_size = 2
[2022-08-12 12:25:53] - INFO: ### initializer_range = 0.02
[2022-08-12 12:25:53] - INFO: ### layer_norm_eps = 1e-12
[2022-08-12 12:25:53] - INFO: ### position_embedding_type = absolute
[2022-08-12 12:25:53] - INFO: ### use_cache = True
[2022-08-12 12:25:53] - INFO: ### classifier_dropout = None
